{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs.shape: (210, 160, 3)\n",
      "env.action_space: Discrete(6)\n",
      "[0.11849965 0.00589975 0.8756006 ]\n",
      "test_softmax: [0.13103449 0.13103449 0.13824064 0.13103449 0.33762142 0.13103449]\n",
      "multinomial_action_array: [0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "\n",
    "# To plot pretty figures and animations\n",
    "%matplotlib nbagg\n",
    "import matplotlib\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "####### Space Invaders\n",
    "load_model           = True\n",
    "perform_learning     = True\n",
    "environment_name     = \"SpaceInvadersNoFrameskip-v4\"\n",
    "discrete_actions     = 6\n",
    "saver_path           = \"./models/\"\n",
    "saver_file_name      = \"space_invaders_three_layers_q_rl\"\n",
    "height               = 210\n",
    "width                = 160\n",
    "channels             = 1\n",
    "frames_captured      = 4\n",
    "max_learning_rate    = .00000001    # 2 x 10^-7   .0000001 seems to be the point where it will stop forming a bias to only do one thing\n",
    "min_learning_rate    = .000000003  # 5 x 10^-9   .0000001 seems to be the point where it will stop forming a bias to only do one thing\n",
    "dropout_keep_prob    = 1.0\n",
    "negative_retrain_attempts = 10\n",
    "\n",
    "max_steps_until_done = 2000000  #1000*3000\n",
    "n_epochs             = 3\n",
    "use_random_every_x_epoch = 5\n",
    "discount_decay_rate_range = [0.97, 0.99]\n",
    "frame_limit          = 2001\n",
    "max_score            = 5.0\n",
    "death_reward_range   = [-24.0, -18.0]\n",
    "death_reward_frames_delay = 44 #24 when capturing every fifth frame in the buffer.   45 when capturing every third\n",
    "maximum_negative_training_batches = 350   #150 works when capturing every fifth frame - maybe use 250 for every third\n",
    "\n",
    "\n",
    "####### Pitfall\n",
    "# environment_name     = \"Pitfall-v0\"\n",
    "# discrete_actions     = 18\n",
    "# load_model           = False\n",
    "# saver_file           = \"./models/pitfall_rl\"\n",
    "# height               = 210\n",
    "# width                = 160\n",
    "# channels             = 1\n",
    "# frames_captured      = 5\n",
    "# learning_rate        =.00001\n",
    "# n_epochs             = 11\n",
    "# use_random_every_x_epoch = 5\n",
    "# discount_decay_rate  = 0.95\n",
    "# frame_limit          = 1000\n",
    "\n",
    "####### River Raid\n",
    "# environment_name     = \"Riverraid-v0\"\n",
    "# discrete_actions     = 18\n",
    "# load_model           = True\n",
    "# saver_file           = \"./models/pitfall_rl\"\n",
    "# height               = 210\n",
    "# width                = 160\n",
    "# channels             = 1\n",
    "# frames_captured      = 5\n",
    "# learning_rate        =.00001\n",
    "# n_epochs             = 501\n",
    "# use_random_every_x_epoch = 5\n",
    "# discount_decay_rate  = 0.95\n",
    "# frame_limit          = 1000\n",
    "\n",
    "\n",
    "def preprocess_observation(obs):\n",
    "    img = obs\n",
    "    img = img.mean(axis=2) # to greyscale\n",
    "    #img = (img - 128) / 128 - 1 # normalize from -1. to 1.\n",
    "    img = img / 256.0  # normalize from 0 to 1.\n",
    "    return img\n",
    "\n",
    "def show_observation(image, title=\"Image\"):\n",
    "    plt.figure(figsize=(11, 7))\n",
    "    plt.subplot(121)\n",
    "    plt.title(title)\n",
    "    plt.imshow(image, cmap=\"gray\") #cmap=\"gray\"\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def softmax(x):\n",
    "    ex = np.exp(x)\n",
    "    sum_ex = np.sum( np.exp(x))\n",
    "    return ex/sum_ex\n",
    "    \n",
    "env = gym.make(environment_name)\n",
    "observation = env.reset()\n",
    "print(\"obs.shape: {}\".format(observation.shape)) #obs.shape: (210, 160, 3)\n",
    "print(\"env.action_space: {}\".format(env.action_space)) #env.action_space: Discrete(9)\n",
    "\n",
    "for step_counter in range(102):\n",
    "    observation, reward_float, done_bool, info_dict = env.step(1)\n",
    "    obs_greyscale = preprocess_observation(observation)\n",
    "\n",
    "#show_observation(observation)\n",
    "#show_observation(obs_greyscale)\n",
    "    \n",
    "print (softmax([1,-2,3]))\n",
    "\n",
    "test_softmax = softmax([4.3210541e-25, 5.4929095e-33, 5.3535387e-02, 1.2303401e-42, 9.4646466e-01, 1.9473004e-27])\n",
    "print (\"test_softmax: {}\".format(test_softmax))\n",
    "\n",
    "multinomial_action_array = np.random.multinomial(1, test_softmax)\n",
    "print (\"multinomial_action_array: {}\".format(multinomial_action_array))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "eps_min = 0.00\n",
    "eps_max = 0.5\n",
    "eps_decay_steps = 25000\n",
    "\n",
    "def helper_discount_rewards(rewards, discount_rate, begin_index, end_index):\n",
    "    '''\n",
    "    Takes in rewards and applies discount rate\n",
    "    '''\n",
    "    discounted_rewards = np.zeros(len(rewards))\n",
    "    cumulative_rewards = 0\n",
    "    for step_counter in reversed(range(len(rewards))):\n",
    "        cumulative_rewards = rewards[step_counter] + cumulative_rewards * discount_rate\n",
    "        discounted_rewards[step_counter] = cumulative_rewards\n",
    "    \n",
    "    reward_mean = discounted_rewards.mean()\n",
    "    reward_std = discounted_rewards.std()\n",
    "        \n",
    "    #return discounted_rewards\n",
    "    return [(discounted_reward - reward_mean)/reward_std for discounted_reward in discounted_rewards]\n",
    "    #return [(discounted_reward - reward_mean)/(reward_mean*.75) for discounted_reward in discounted_rewards]\n",
    "\n",
    "def action_to_one_hot(action, possible_action_count):\n",
    "    return_array = np.zeros(possible_action_count)\n",
    "    action_int = int(action)\n",
    "    return_array[action_int] = 1.0\n",
    "    return return_array\n",
    "\n",
    "def getRewardArrays(actions, discounted_rewards, possible_action_count):\n",
    "    reward_arrays = []   \n",
    "    for this_action, this_reward in zip(actions, discounted_rewards):\n",
    "        this_value = action_to_one_hot(this_action, possible_action_count)\n",
    "        this_value = this_value * this_reward\n",
    "        reward_arrays.append(this_value)\n",
    "        \n",
    "    return reward_arrays\n",
    "\n",
    "def getRewardAverages(actions, discounted_rewards, possible_action_count):\n",
    "    reward_arrays = getRewardArrays(actions, discounted_rewards, possible_action_count)     \n",
    "    return np.mean(reward_arrays, axis=0)\n",
    "\n",
    "def weightRewardAveragesToAverageZero(actions, rewardArrays, possible_action_count):\n",
    "    positive_sums = np.zeros(possible_action_count)\n",
    "    negative_sums = np.zeros(possible_action_count)\n",
    "    \n",
    "    positive_counts = np.zeros(possible_action_count)\n",
    "    negative_counts = np.zeros(possible_action_count)\n",
    "    \n",
    "    for i in range(0, possible_action_count):\n",
    "        positiveSum = 0\n",
    "        negativeSum = 0\n",
    "        positiveCount = 0\n",
    "        negativeCount = 0\n",
    "        for rewardArray in rewardArrays:\n",
    "            if rewardArray[i] >= 0:\n",
    "                positiveSum = positiveSum + rewardArray[i]\n",
    "                positiveCount = positiveCount + 1\n",
    "            else:\n",
    "                negativeSum = negativeSum + rewardArray[i]\n",
    "                negativeCount = negativeCount + 1\n",
    "    \n",
    "        positive_sums[i] = positiveSum\n",
    "        negative_sums[i] = negativeSum\n",
    "        positive_counts[i] = positiveCount\n",
    "        negative_counts[i] = negativeCount\n",
    "        \n",
    "#     print(\"positive_sums: {}\".format(positive_sums));\n",
    "#     print(\"negative_sums: {}\".format(negative_sums));\n",
    "#     print(\"positive_counts: {}\".format(positive_counts));\n",
    "#     print(\"negative_counts: {}\".format(negative_counts));\n",
    "\n",
    "    for i in range(0, possible_action_count):\n",
    "        makeupTotal = positive_sums[i] + negative_sums[i]\n",
    "        for rewardArray in rewardArrays:\n",
    "            if makeupTotal > 0 and rewardArray[i] < 0:\n",
    "                rewardArray[i] = rewardArray[i] - makeupTotal/negative_counts[i]\n",
    "            elif makeupTotal < 0 and rewardArray[i] > 0:\n",
    "                rewardArray[i] = rewardArray[i] - makeupTotal/positive_counts[i]\n",
    "                \n",
    "    return rewardArrays\n",
    "\n",
    "\n",
    "def get_average_logits (logits_list, discounted_rewards):\n",
    "    logit_sums = np.zeros(len(logits_list[0][0]))\n",
    "    logit_sums_counter = np.ones(len(logits_list[0][0]))\n",
    "\n",
    "    for this_logit, this_reward in zip(logits_list, discounted_rewards):\n",
    "        temp_array = np.zeros(len(logits_list[0][0]))\n",
    "        temp_counter_array = np.zeros(len(logits_list[0][0]))\n",
    "        \n",
    "        action = np.argmax(this_logit)\n",
    "        temp_array[action] = this_logit[0][action]\n",
    "        logit_sums = logit_sums + temp_array*this_reward\n",
    "        temp_counter_array[action] = 1\n",
    "        logit_sums_counter = logit_sums_counter + temp_counter_array\n",
    "        \n",
    "    return (logit_sums/logit_sums_counter)\n",
    "\n",
    "# print(\"action_to_one_hot(3, 9): \" + str(action_to_one_hot(3.0, 9)))\n",
    "# print(\"action_to_one_hot(9, 9): \" + str(action_to_one_hot(8, 9)))\n",
    "#print(get_average_logits(all_logits, discounted_rewards))\n",
    "#print(all_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs  = discrete_actions\n",
    "n_outputs = discrete_actions\n",
    "n_hidden1 = 512\n",
    "n_hidden2 = 256\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "#with tf.name_scope(\"inputs\"):\n",
    "tf_input_frame = tf.placeholder(tf.float32, shape=(None, height*frames_captured, width, channels))\n",
    "tf_input_value = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
    "tf_train_index = tf.placeholder(tf.int32)\n",
    "tf_input_learning_rate = tf.placeholder(tf.float32)\n",
    "tf_dropout_keep_prob = tf.placeholder(tf.float32)\n",
    "tf_reward = tf.placeholder(tf.float32)\n",
    "tf_q_input = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "    \n",
    "initializer = tf.contrib.slim.variance_scaling_initializer(factor=1.0 / np.sqrt(3.0), mode='FAN_IN', uniform=True)\n",
    "\n",
    "convs   = [32,64,64]\n",
    "kerns   = [8,4,3]\n",
    "strides = [4,2,1]\n",
    "\n",
    "pads    = 'valid'\n",
    "activ   = tf.nn.elu\n",
    "\n",
    "# Policy Network\n",
    "conv1 = tf.layers.conv2d(\n",
    "        inputs = tf_input_frame,\n",
    "        filters = convs[0],\n",
    "        kernel_size = kerns[0],\n",
    "        strides = strides[0],\n",
    "        padding = pads,\n",
    "        activation = activ,\n",
    "        name='conv1')\n",
    "\n",
    "conv2 = tf.layers.conv2d(\n",
    "        inputs=conv1,\n",
    "        filters = convs[1],\n",
    "        kernel_size = kerns[1],\n",
    "        strides = strides[1],\n",
    "        padding = pads,\n",
    "        activation = activ,\n",
    "        name='conv2')\n",
    "\n",
    "conv3 = tf.layers.conv2d(\n",
    "        inputs=conv2,\n",
    "        filters = convs[2],\n",
    "        kernel_size = kerns[2],\n",
    "        strides = strides[2],\n",
    "        padding = pads,\n",
    "        activation = activ,\n",
    "        name='conv3')\n",
    "\n",
    "flat = tf.layers.flatten(conv3)\n",
    "\n",
    "hidden1 = tf.layers.dense(flat,    n_hidden1, activation=activ, name=\"hidden1\", kernel_initializer=initializer)\n",
    "hidden1_drop = tf.nn.dropout(hidden1, tf_dropout_keep_prob)\n",
    "hidden2 = tf.layers.dense(hidden1_drop, n_hidden2, activation=activ, name=\"hidden2\", kernel_initializer=initializer)\n",
    "\n",
    "q_predicted = tf.layers.dense(inputs=hidden2, units=1, name=\"output_q\", activation=None)\n",
    "logits = tf.layers.dense(inputs=hidden2, units=n_outputs, name=\"output\", activation=None)\n",
    "\n",
    "# only train on the action taken.  Ignore the rest since we really don't have insightful advice for the other actions.\n",
    "single_logit = logits[:,tf_train_index]\n",
    "\n",
    "#loss = tf.reduce_mean(tf.square(logits-tf_input_value))\n",
    "loss = tf.reduce_sum(tf.square(single_logit-tf_reward))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(tf_input_learning_rate)\n",
    "training_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(max_to_keep=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model before training: space_invaders_three_layers_q_rl\n",
      "INFO:tensorflow:Restoring parameters from ./models/space_invaders_three_layers_q_rl-1540974\n",
      "Death at frame 222. Score: 35.0. Total Rewards: 20.0\n",
      "Death at frame 488. Score: 65.0. Total Rewards: 40.0\n",
      "Death at frame 713. Score: 115.0. Total Rewards: 60.0\n",
      "original_len: 714\n",
      "original punish_frames: [178, 444, 669]\n",
      "Death reward at frame 178: -19.008016728857598\n",
      "Death reward at frame 444: -19.008016728857598\n",
      "Death reward at frame 669: -19.008016728857598\n",
      "Epoch: 0, frames: 714, score: 115.0, avg loss: 1.2777961909408524, learning_rate: 5.3442545e-09, step: 1330213, discount_decay_rate: 0.9775019685853136, death_penalty: -19.008016728857598, skipped_negative_training_batches: 0\n",
      "actions trained (positive):   [ 64.  36.  24.  35. 237. 121.]\n",
      "actions trained (negative):   [12. 17. 10.  8. 96. 52.]\n",
      "actions trained (total):      [ 76.  53.  34.  43. 333. 173.]\n",
      "actions out while training:   [ 43.   0.   0.   0. 472. 197.]\n",
      "training disagreements with runthrough:   8\n",
      "\n",
      "Using strict AI actions\n",
      "Death at frame 774. Score: 280.0. Total Rewards: 105.0\n",
      "Death at frame 968. Score: 350.0. Total Rewards: 120.0\n",
      "Death at frame 1098. Score: 385.0. Total Rewards: 130.0\n",
      "original_len: 1099\n",
      "original punish_frames: [730, 924, 1054]\n",
      "Death reward at frame 431: -22.533529296098884\n",
      "Death reward at frame 625: -22.533529296098884\n",
      "Death reward at frame 755: -22.533529296098884\n",
      "Epoch: 1, frames: 800, score: 385.0, avg loss: 1.077681643590154, learning_rate: 5.340415e-09, step: 1331310, discount_decay_rate: 0.9750364737134686, death_penalty: -22.533529296098884, skipped_negative_training_batches: 0\n",
      "actions trained (positive):   [  0.   0.   0.   0. 305. 155.]\n",
      "actions trained (negative):   [ 77.  15.   0.   0. 124. 122.]\n",
      "actions trained (total):      [ 77.  15.   0.   0. 429. 277.]\n",
      "actions out while training:   [ 76.  14.   0.   0. 432. 276.]\n",
      "training disagreements with runthrough:   8\n",
      "\n",
      "Using strict AI actions\n",
      "Death at frame 660. Score: 280.0. Total Rewards: 105.0\n",
      "Death at frame 1016. Score: 440.0. Total Rewards: 145.0\n",
      "Death at frame 1105. Score: 440.0. Total Rewards: 145.0\n",
      "original_len: 1106\n",
      "original punish_frames: [616, 972, 1061]\n",
      "Death reward at frame 310: -20.96371202698316\n",
      "Death reward at frame 666: -20.96371202698316\n",
      "Death reward at frame 755: -20.96371202698316\n",
      "Epoch: 2, frames: 800, score: 440.0, avg loss: 1.0202277144363796, learning_rate: 5.336551e-09, step: 1332414, discount_decay_rate: 0.9770267931099337, death_penalty: -20.96371202698316, skipped_negative_training_batches: 0\n",
      "actions trained (positive):   [ 12.  10.   0.   0. 277. 156.]\n",
      "actions trained (negative):   [ 57.  91.   0.   1.  52. 142.]\n",
      "actions trained (total):      [ 69. 101.   0.   1. 329. 298.]\n",
      "actions out while training:   [ 61.  95.   0.   0. 347. 295.]\n",
      "training disagreements with runthrough:   32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(environment_name)\n",
    "\n",
    "def get_concatenated_frames(frames, end_index, num_frames_to_concatenate):\n",
    "    concatenated_frames = frames[:,:,end_index-1]\n",
    "\n",
    "    for j in range(1,num_frames_to_concatenate,1):\n",
    "        if end_index-j <= 1:\n",
    "            this_frame = frames[:,:,0]\n",
    "        elif j >= num_frames:\n",
    "            this_frame = frames[:,:,end_index-1]\n",
    "        else:\n",
    "            this_frame = frames[:,:,end_index-1-j]\n",
    "            \n",
    "        concatenated_frames = np.append(concatenated_frames, this_frame, axis=0)\n",
    "    return concatenated_frames\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if load_model:\n",
    "        print(\"Loading existing model before training: {}\".format(saver_file_name))\n",
    "        #saver.restore(sess, tf.train.latest_checkpoint(saver_file))\n",
    "        \n",
    "        ckpt = tf.train.get_checkpoint_state(saver_path)\n",
    "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess, os.path.join(saver_path, ckpt_name))\n",
    "    else:\n",
    "        print(\"Creating new model before training: {}\".format(saver_file_name))\n",
    "        sess.run(init)\n",
    "    \n",
    "    step = global_step.eval(session=sess)\n",
    "    \n",
    "    for epoch in range(n_epochs):  #play n_epochs games\n",
    "        if step > max_steps_until_done:\n",
    "            print(\"Max Steps reached: step: {}, max steps: {}\".format(step, max_steps_until_done))\n",
    "            break\n",
    "                \n",
    "        observation = env.reset()\n",
    "        temp_lives = 3\n",
    "        score = 0.0\n",
    "        total_rewards = 0.0\n",
    "        frames = np.empty([height, width, 0])\n",
    "        actions = np.empty([0])\n",
    "        rewards = np.empty([0])\n",
    "        all_logits = []\n",
    "        all_training_logits = []\n",
    "        punish_frames = []\n",
    "        default_input_q = np.reshape([0.0], (1,1))\n",
    "            \n",
    "        #get the first frame\n",
    "        input_value = 0  #set an initial input value\n",
    "        observation, reward_float, done_bool, info_dict = env.step(input_value)  #run one to get frames that show enemy fire\n",
    "        \n",
    "        obs_greyscale = preprocess_observation(observation)\n",
    "        obs_greyscale_reshape = np.reshape(obs_greyscale, (height,width,1))\n",
    "        frames = np.append(frames, obs_greyscale_reshape, axis=2)\n",
    "        actions = np.append(actions, input_value)\n",
    "        last_action_step = 0\n",
    "        decision_step_counter = 0\n",
    "\n",
    "        game_step_counter = 0\n",
    "        action_from_ai_epsilon_greedy = 0\n",
    "        points_at_death = []\n",
    "        \n",
    "        gc.disable()\n",
    "        while True:\n",
    "            num_frames = np.ma.size(frames, axis=2)                     \n",
    "            concatenated_frames = get_concatenated_frames(frames, num_frames, frames_captured)\n",
    "            concatenated_frames_reshaped = np.reshape(concatenated_frames, (1, height*frames_captured, width, 1))\n",
    "            \n",
    "            #use the input value from the AI\n",
    "            temp_input = np.zeros(discrete_actions) #[0, 0, 0, ...]\n",
    "            temp_input[action_from_ai_epsilon_greedy] = 1\n",
    "            temp_input_reshaped = np.reshape(temp_input, (1, len(temp_input)))\n",
    "            \n",
    "            \n",
    "            #tf_dropout_keep_prob: 1.0,\n",
    "            feed_dict = {tf_input_frame : concatenated_frames_reshaped, \n",
    "                         tf_input_value : temp_input_reshaped,\n",
    "                         tf_input_learning_rate: 0.0,\n",
    "                         tf_dropout_keep_prob: 1.0,\n",
    "                         tf_reward: 0.0,\n",
    "                         tf_q_input: default_input_q}\n",
    "            logits_out = sess.run([logits], feed_dict=feed_dict)\n",
    "\n",
    "            all_logits.append(logits_out[0][0])\n",
    "            \n",
    "            #if global_step % 5 == 0:  #only allow a change of direction every 5 steps.  \n",
    "            action_from_ai_logits_argmax = np.argmax(logits_out[0])\n",
    "    \n",
    "            positive_logits = logits_out[0] + abs(np.amin(logits_out[0]))\n",
    "            softmax_logits = softmax(positive_logits / np.amax(positive_logits))\n",
    "\n",
    "            try:\n",
    "                multinomial_action_array = np.random.multinomial(1, softmax_logits[0])\n",
    "                action_from_multinomial_action = np.argmax(multinomial_action_array)\n",
    "#                print (\"multinomial_action_array: {}\".format(multinomial_action_array))\n",
    "            except ValueError:\n",
    "                #I have no idea why this occassionally errors out.\n",
    "                action_from_multinomial_action = np.argmax(softmax_logits)\n",
    "                print (\"multinomial error, using action {}\".format(action_from_multinomial_action))\n",
    "                continue\n",
    "                \n",
    "#            print (\"action_from_multinomial_action: {}\".format(action_from_multinomial_action))\n",
    "        \n",
    "            # decide which action to use\n",
    "            #only train even frames for consistency between frames with enemy vs friendly fire.\n",
    "            #perform logic here for consistency between what is trained and what actions are taken\n",
    "#            if i % 2 != 0:\n",
    "            if epoch % use_random_every_x_epoch != 0:\n",
    "                if game_step_counter == 0:\n",
    "                    print(\"Using strict AI actions\")\n",
    "                action_from_ai_epsilon_greedy = action_from_ai_logits_argmax  #do what the AI says\n",
    "            else:\n",
    "#                print(\"Using probability-based actions\")\n",
    "                if step % 2 == 0:\n",
    "                    action_from_ai_epsilon_greedy = action_from_multinomial_action  #use probability-based action\n",
    "                else:\n",
    "                    action_from_ai_epsilon_greedy = action_from_ai_logits_argmax \n",
    "            \n",
    "            this_reward_for_set = 0\n",
    "            \n",
    "            #run the next step given the input from the logits\n",
    "            observation, reward_float, done_bool, info_dict = env.step(action_from_ai_epsilon_greedy)\n",
    "            score = score + reward_float\n",
    "            if reward_float > max_score:\n",
    "                this_reward_for_set = this_reward_for_set + max_score\n",
    "                #rewards = np.append(rewards, max_score)\n",
    "                total_rewards = total_rewards + max_score\n",
    "            else:\n",
    "                this_reward_for_set = this_reward_for_set + reward_float\n",
    "                #rewards = np.append(rewards, reward_float)\n",
    "                total_rewards = total_rewards + reward_float\n",
    "                \n",
    "            observation, reward_float, done_bool, info_dict = env.step(action_from_ai_epsilon_greedy)\n",
    "            score = score + reward_float\n",
    "            if reward_float > max_score:\n",
    "                this_reward_for_set = this_reward_for_set + max_score\n",
    "                #rewards = np.append(rewards, max_score)\n",
    "                total_rewards = total_rewards + max_score\n",
    "            else:\n",
    "                this_reward_for_set = this_reward_for_set + reward_float\n",
    "                #rewards = np.append(rewards, reward_float)\n",
    "                total_rewards = total_rewards + reward_float\n",
    "            \n",
    "            observation, reward_float, done_bool, info_dict = env.step(action_from_ai_epsilon_greedy)\n",
    "            score = score + reward_float\n",
    "            if reward_float > max_score:\n",
    "                this_reward_for_set = this_reward_for_set + max_score\n",
    "                #rewards = np.append(rewards, max_score)\n",
    "                total_rewards = total_rewards + max_score\n",
    "            else:\n",
    "                this_reward_for_set = this_reward_for_set + reward_float\n",
    "                #rewards = np.append(rewards, reward_float)\n",
    "                total_rewards = total_rewards + reward_float\n",
    "            \n",
    "#             observation, reward_float, done_bool, info_dict = env.step(action_from_ai_epsilon_greedy)\n",
    "#             score = score + reward_float\n",
    "#             if reward_float > max_score:\n",
    "#                 this_reward_for_set = this_reward_for_set + max_score\n",
    "#                 #rewards = np.append(rewards, max_score)\n",
    "#                 total_rewards = total_rewards + max_score\n",
    "#             else:\n",
    "#                 this_reward_for_set = this_reward_for_set + reward_float\n",
    "#                 #rewards = np.append(rewards, reward_float)\n",
    "#                 total_rewards = total_rewards + reward_float\n",
    "                \n",
    "#             observation, reward_float, done_bool, info_dict = env.step(action_from_ai_epsilon_greedy)\n",
    "#             score = score + reward_float\n",
    "#             if reward_float > max_score:\n",
    "#                 this_reward_for_set = this_reward_for_set + max_score\n",
    "#                 #rewards = np.append(rewards, max_score)\n",
    "#                 total_rewards = total_rewards + max_score\n",
    "#             else:\n",
    "#                 this_reward_for_set = this_reward_for_set + reward_float\n",
    "#                 #rewards = np.append(rewards, reward_float)\n",
    "#                 total_rewards = total_rewards + reward_float\n",
    "                \n",
    "            rewards = np.append(rewards, this_reward_for_set)\n",
    "            \n",
    "#            if step % 2 != 0:\n",
    "            env.render()  #display the current frame.\n",
    "                \n",
    "            #add this frame to our frame buffer\n",
    "            obs_greyscale = preprocess_observation(observation)\n",
    "            obs_greyscale_reshape = np.reshape(obs_greyscale, (height,width,1))\n",
    "            frames = np.append(frames, obs_greyscale_reshape, axis=2)\n",
    "            \n",
    "            actions = np.append(actions, action_from_ai_epsilon_greedy)\n",
    "            \n",
    "            lives = info_dict['ale.lives']\n",
    "\n",
    "            if done_bool:\n",
    "                punish_frames.append(len(rewards) - death_reward_frames_delay)\n",
    "                print(\"Death at frame {}. Score: {}. Total Rewards: {}\".format(len(rewards), score, total_rewards))\n",
    "                points_at_death.append(total_rewards)\n",
    "                break\n",
    "                \n",
    "            if game_step_counter > frame_limit:\n",
    "                break\n",
    "                \n",
    "            if lives != temp_lives:  #we lost a life.  consider this game over.\n",
    "                #print(\"Lost a life.  Current lives: {}\".format(lives))\n",
    "                temp_lives = lives\n",
    "                if len(rewards) > death_reward_frames_delay:\n",
    "                    punish_frames.append(len(rewards) - death_reward_frames_delay)\n",
    "                    print(\"Death at frame {}. Score: {}. Total Rewards: {}\".format(len(rewards), score, total_rewards))\n",
    "                    points_at_death.append(total_rewards)\n",
    "\n",
    "            decision_step_counter += 1\n",
    "            game_step_counter += 1\n",
    "            step += 1\n",
    "        gc.enable()\n",
    "        \n",
    "        # only train that last 700 frames\n",
    "        original_len = len(actions)\n",
    "        print(\"original_len: {}\".format(original_len))\n",
    "        print(\"original punish_frames: {}\".format(punish_frames))\n",
    "        \n",
    "        if original_len > 800:\n",
    "            frames = frames[:,:,-800:]\n",
    "            rewards = rewards[-800:]\n",
    "            actions = actions[-800:]\n",
    "            all_logits = all_logits[-800:]\n",
    "            #punish_frames = punish_frames - (original_len-700)\n",
    "            punish_frames[:] = [x - (original_len-800) for x in punish_frames]\n",
    "        \n",
    "        if perform_learning:\n",
    "            if epoch % 20 == 0 and epoch > 0:\n",
    "                print(\"Saving model at epoch {}. score: {}, file: {}\".format(epoch, score, saver_file_name))\n",
    "                saver.save(sess, os.path.join(saver_path, saver_file_name), global_step=step)\n",
    "\n",
    "            num_frames = np.ma.size(frames, axis=2)\n",
    "            frames_to_skip_begin = 0\n",
    "            frames_to_skip_end  = 0  #number of frames between pacman being eaten and game reset\n",
    "\n",
    "            #train three times using different (random) values for discounted rewards and death punishments\n",
    "            for x in range(1,2):\n",
    "                #punish death\n",
    "                temp_points = 0\n",
    "\n",
    "                death_penalty = random.uniform(death_reward_range[0], death_reward_range[1])\n",
    "\n",
    "                for this_frame, this_points in zip(punish_frames, points_at_death):\n",
    "                    if this_frame < 0 or this_frame > len(rewards):\n",
    "                        continue\n",
    "                    rewards[this_frame] = death_penalty\n",
    "                    print(\"Death reward at frame {}: {}\".format(this_frame, rewards[this_frame]))\n",
    "\n",
    "                discount_decay_rate = random.uniform(discount_decay_rate_range[0], discount_decay_rate_range[1])\n",
    "                discounted_rewards = helper_discount_rewards(rewards, discount_decay_rate, frames_to_skip_begin, num_frames) #-1-frames_to_skip_end\n",
    "\n",
    "                positive_display_actions = np.zeros(discrete_actions)\n",
    "                negative_display_actions = np.zeros(discrete_actions)\n",
    "                ai_training_actions = np.zeros(discrete_actions)\n",
    "                loss_out_sum = 0.0\n",
    "                frames_taught = 0.000000001\n",
    "\n",
    "                reward_frame_counter = 0\n",
    "                punish_frame_counter = 0\n",
    "\n",
    "                frames_to_train = np.arange(num_frames-2-frames_to_skip_end)\n",
    "#                np.random.shuffle(frames_to_train)  ###########################\n",
    "\n",
    "                skipped_negative_training_batches = 0\n",
    "\n",
    "                disagreement_counter = 0\n",
    "                for i in range(frames_to_skip_begin, num_frames-2-frames_to_skip_end):   #skip the first frames\n",
    "                    this_random_frame_index = frames_to_train[i]\n",
    "\n",
    "                    concatenated_frames = get_concatenated_frames(frames, this_random_frame_index, frames_captured)\n",
    "                    concatenated_frames_reshaped = np.reshape(concatenated_frames, (1, height*frames_captured, width, 1))\n",
    "\n",
    "                    action_taken_one_hot = action_to_one_hot(actions[this_random_frame_index], n_outputs)\n",
    "\n",
    "                    reward_for_frame = discounted_rewards[this_random_frame_index]\n",
    "                    \n",
    "                    #print(\"reward for frame {} :{}. frame array: {}\".format(this_random_frame_index, reward_for_frame, reward_arrays[this_random_frame_index+1]) )\n",
    "                    max_logit                 = np.amax(all_logits[this_random_frame_index])\n",
    "                    second_max_logit_index = np.argsort(all_logits[this_random_frame_index])[len(all_logits[this_random_frame_index])-2]\n",
    "                    second_max_logit =                  all_logits[this_random_frame_index][second_max_logit_index]\n",
    "                    min_logit =                 np.amin(all_logits[this_random_frame_index])\n",
    "                    average_logit =          np.average(all_logits[this_random_frame_index])\n",
    "                    action_logit =                      all_logits[this_random_frame_index][int(actions[this_random_frame_index])]\n",
    "                    \n",
    "#                     print(\"original action: {}: original reward: {}, logits: {}\".format(actions[this_random_frame_index], reward_for_frame, all_logits[this_random_frame_index]))\n",
    "#                     print(\"second largest logit: {}\".format(second_max_logit))\n",
    "                    \n",
    "                    if reward_for_frame > 0.0:\n",
    "                        positive_display_actions = np.add(positive_display_actions, action_taken_one_hot)\n",
    "                        reward_for_frame = reward_for_frame + action_logit\n",
    "                        #The ai took a good action.  keep reward the same.\n",
    "                    else:\n",
    "                        negative_display_actions = np.add(negative_display_actions, action_taken_one_hot)\n",
    "                        #TODO - need to address action logit vs second max logit\n",
    "                        reward_for_frame = reward_for_frame + second_max_logit\n",
    "\n",
    "                    #add current reward to the average of the logits \n",
    "                    #reward_for_frame = reward_for_frame + average_logit\n",
    "#                    reward_for_frame = reward_for_frame + action_logit\n",
    "#                    print(\"reward for frame: {}, max_logit: {}, min_logit: {}\".format(reward_for_frame, max_logit, min_logit))\n",
    "            \n",
    "                    action_taken_one_hot_reshaped = np.reshape(action_taken_one_hot, (1, len(action_taken_one_hot)))\n",
    "\n",
    "                    learning_rate = max_learning_rate - step/max_steps_until_done*(max_learning_rate-min_learning_rate)\n",
    "\n",
    "                    input_q = np.reshape([reward_for_frame], (1,1))\n",
    "\n",
    "                    feed_dict = {tf_input_frame : concatenated_frames_reshaped, \n",
    "                                 tf_input_value : action_taken_one_hot_reshaped,\n",
    "                                 tf_input_learning_rate: learning_rate,\n",
    "                                 tf_dropout_keep_prob: 1.0,  ######################### \n",
    "                                 tf_reward: reward_for_frame,\n",
    "                                 tf_q_input: input_q,\n",
    "                                 tf_train_index: actions[this_random_frame_index]}\n",
    "                    loss_out, _, training_logits_out = sess.run([loss, training_op, logits], feed_dict=feed_dict)\n",
    "                    \n",
    "                    all_training_logits.append(training_logits_out[0])\n",
    "                    \n",
    "                    if np.argmax(all_training_logits[i]) != np.argmax(all_logits[i]):\n",
    "                        disagreement_counter += 1\n",
    "                        \n",
    "#                     force_change_counter = 0\n",
    "#                     if discounted_rewards[i] < -2.5:\n",
    "#                         print(\"forcing new decision.  frame: {}, action: {}: reward: {}\".format(i, actions[this_random_frame_index], round(discounted_rewards[i], 2) ))\n",
    "#                         while np.argmax(all_training_logits[i]) == np.argmax(all_logits[i]):\n",
    "#                             loss_out, _, training_logits_out = sess.run([loss, training_op, logits], feed_dict=feed_dict)\n",
    "#                             all_training_logits[len(all_training_logits)-1] = training_logits_out[0]\n",
    "#                             force_change_counter += 1\n",
    "#                             if force_change_counter >= negative_retrain_attempts:\n",
    "#                                 break\n",
    "#                         print(\"forced new decision in {} steps. New decision: {}\".format(force_change_counter, all_training_logits[i]))\n",
    "\n",
    "                    \n",
    "                    frames_taught = frames_taught + 1\n",
    "                    loss_out_sum += abs(loss_out)\n",
    "\n",
    "                    action_from_training = np.argmax(training_logits_out[0])\n",
    "                    action_from_training_one_hot = action_to_one_hot(action_from_training, n_outputs)\n",
    "                    ai_training_actions = np.add(ai_training_actions, action_from_training_one_hot)\n",
    "\n",
    "                print(\"Epoch: \" + str(epoch) + \", frames: \" + str(num_frames) + \", score: \" + str(score) + \", avg loss: \" + str(loss_out_sum/frames_taught) + \", learning_rate: \" + str(learning_rate) + \", step: \" + str(step) + \", discount_decay_rate: \" + str(discount_decay_rate) + \", death_penalty: \" + str(death_penalty) + \", skipped_negative_training_batches: \" + str(skipped_negative_training_batches))\n",
    "                print(\"actions trained (positive):   {}\".format(positive_display_actions))\n",
    "                print(\"actions trained (negative):   {}\".format(negative_display_actions))\n",
    "                print(\"actions trained (total):      {}\".format(positive_display_actions+negative_display_actions))\n",
    "                print(\"actions out while training:   {}\".format(ai_training_actions))\n",
    "                print(\"training disagreements with runthrough:   {}\".format(disagreement_counter))\n",
    "                \n",
    "                print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discounted reward at frame 501: 0.42\n",
      "original logits at frame 501: 4 [-0.59671634 -0.5815074  -0.80489016 -0.63032156 -0.2877932  -0.42995876]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"1100\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "frame_to_display = 501\n",
    "print(\"discounted reward at frame {}: {}\".format(frame_to_display, round(discounted_rewards[frame_to_display], 2)))\n",
    "print(\"original logits at frame {}: {} {}\".format(frame_to_display, np.argmax(all_logits[frame_to_display]), all_logits[frame_to_display]))\n",
    "\n",
    "# print(\"training logits at frame {}: {} {}\".format(frame_to_display, np.argmax(all_training_logits[frame_to_display]), all_training_logits[frame_to_display]))\n",
    "# print(\"action at frame {}: {}\".format(frame_to_display, actions[frame_to_display]))\n",
    "\n",
    "\n",
    "concatenated_frames = get_concatenated_frames(frames, frame_to_display, 1)\n",
    "\n",
    "\n",
    "show_observation(concatenated_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: action: 5, reward: 0.0048621843565114075, max_logit: -0.3856288492679596\n",
      "   [-0.83279103 -1.5346766  -0.55471987 -0.6039569  -1.5364798  -0.38562885]\n",
      "1: action: 5, reward: 0.01677601178773602, max_logit: -0.338278204202652\n",
      "   [-0.83193535 -1.5325146  -0.55192125 -0.59031963 -1.5110704  -0.3382782 ]\n",
      "2: action: 5, reward: 0.028952214224027436, max_logit: -0.23312075436115265\n",
      "   [-0.78073126 -1.4982094  -0.544135   -0.51853174 -1.4759617  -0.23312075]\n",
      "3: action: 5, reward: 0.04139656987928716, max_logit: -0.2656208872795105\n",
      "   [-0.79434454 -1.5164821  -0.5470319  -0.5372205  -1.4793471  -0.2656209 ]\n",
      "4: action: 5, reward: 0.05411498421946151, max_logit: -0.21401996910572052\n",
      "   [-0.77506155 -1.4926503  -0.5322798  -0.5096706  -1.4693686  -0.21401997]\n",
      "5: action: 5, reward: 0.06711349276497908, max_logit: -0.23481632769107819\n",
      "   [-0.7806994  -1.506119   -0.53544307 -0.5190232  -1.476238   -0.23481633]\n",
      "6: action: 5, reward: 0.08039826395490529, max_logit: -0.21264906227588654\n",
      "   [-0.77072877 -1.4898657  -0.52830994 -0.49635077 -1.465871   -0.21264906]\n",
      "7: action: 5, reward: 0.09397560207417378, max_logit: -0.2271893173456192\n",
      "   [-0.774347   -1.4968723  -0.5266106  -0.5060023  -1.4638476  -0.22718932]\n",
      "8: action: 5, reward: 0.1078519502452834, max_logit: -0.23593755066394806\n",
      "   [-0.7814614  -1.5013182  -0.5218737  -0.51660496 -1.4576647  -0.23593755]\n",
      "9: action: 5, reward: 0.12203389348588019, max_logit: -0.24972699582576752\n",
      "   [-0.7692439 -1.5043786 -0.5144041 -0.5155244 -1.4433588 -0.249727 ]\n",
      "10: action: 5, reward: 0.13652816183367597, max_logit: -0.19462572038173676\n",
      "   [-0.74235123 -1.4961423  -0.4958003  -0.4736926  -1.4473903  -0.19462572]\n",
      "11: action: 5, reward: 0.1513416335401863, max_logit: -0.17322300374507904\n",
      "   [-0.689928   -1.5041251  -0.4711622  -0.42170483 -1.4031718  -0.173223  ]\n",
      "12: action: 5, reward: 0.16648133833480275, max_logit: -0.10430542379617691\n",
      "   [-0.64153355 -1.5043038  -0.43862316 -0.35429072 -1.3759797  -0.10430542]\n",
      "13: action: 5, reward: 0.18195446076074948, max_logit: -0.04860667511820793\n",
      "   [-0.5989931  -1.523712   -0.43200752 -0.2825547  -1.3631219  -0.04860668]\n",
      "14: action: 5, reward: 0.19776834358450643, max_logit: -0.06836218386888504\n",
      "   [-0.61509174 -1.5442922  -0.43783295 -0.29932445 -1.3560994  -0.06836218]\n",
      "15: action: 5, reward: 0.21393049128031733, max_logit: -0.04326791688799858\n",
      "   [-0.6007647  -1.5287441  -0.44704354 -0.27123725 -1.3619277  -0.04326792]\n",
      "16: action: 5, reward: 0.2304485735914362, max_logit: -0.07935536652803421\n",
      "   [-0.6177829  -1.5505542  -0.4428504  -0.2947011  -1.3524106  -0.07935537]\n",
      "17: action: 5, reward: 0.2473304291698021, max_logit: -0.05495293065905571\n",
      "   [-0.59654707 -1.5291882  -0.43823308 -0.26788458 -1.341207   -0.05495293]\n",
      "18: action: 5, reward: 0.2645840692958693, max_logit: -0.07445887476205826\n",
      "   [-0.61626565 -1.5447971  -0.45750454 -0.29376876 -1.3688986  -0.07445887]\n",
      "19: action: 5, reward: 0.282217681680359, max_logit: -0.054807525128126144\n",
      "   [-0.6030102  -1.5318838  -0.44682166 -0.27317363 -1.3534825  -0.05480753]\n",
      "20: action: 5, reward: 0.3002396343497348, max_logit: -0.04449300095438957\n",
      "   [-0.60386276 -1.5376303  -0.46362808 -0.26892394 -1.379398   -0.044493  ]\n",
      "21: action: 5, reward: 0.3186584796172481, max_logit: 0.03380580618977547\n",
      "   [-0.5713149  -1.5147744  -0.44394383 -0.2209354  -1.3323984   0.03380581]\n",
      "22: action: 5, reward: 0.33748295814143603, max_logit: 0.04237328842282295\n",
      "   [-0.6028053  -1.5351923  -0.46111938 -0.25807822 -1.3287187   0.04237329]\n",
      "23: action: 5, reward: 0.35672200307399904, max_logit: 0.0901058092713356\n",
      "   [-0.5870723  -1.529044   -0.452808   -0.2463076  -1.2899384   0.09010581]\n",
      "24: action: 5, reward: 0.3763847442990256, max_logit: 0.1372319459915161\n",
      "   [-0.6091922  -1.5538377  -0.46133354 -0.2652939  -1.2732258   0.13723195]\n",
      "25: action: 5, reward: 0.3964805127655768, max_logit: 0.137267604470253\n",
      "   [-0.61794263 -1.5424576  -0.4694557  -0.27332157 -1.2833585   0.1372676 ]\n",
      "26: action: 5, reward: 0.4170188449156856, max_logit: 0.12378393858671188\n",
      "   [-0.62503654 -1.5706708  -0.47428817 -0.28200686 -1.2828577   0.12378394]\n",
      "27: action: 5, reward: 0.4380094872098732, max_logit: 0.14678391814231873\n",
      "   [-0.62873703 -1.552496   -0.47383094 -0.2875803  -1.283902    0.14678392]\n",
      "28: action: 5, reward: 0.45946240075232975, max_logit: 0.15190955996513367\n",
      "   [-0.60779697 -1.5466324  -0.47127807 -0.25940698 -1.2754875   0.15190956]\n",
      "29: action: 5, reward: 0.4813877660179534, max_logit: 0.1771106868982315\n",
      "   [-0.60649854 -1.5353522  -0.4628955  -0.25565588 -1.2613788   0.17711069]\n",
      "30: action: 5, reward: 0.5037959876834929, max_logit: 0.1845216006040573\n",
      "   [-0.5998688  -1.5350163  -0.47059155 -0.24229433 -1.2758102   0.1845216 ]\n",
      "31: action: 5, reward: 0.5266976995650837, max_logit: 0.20811815559864044\n",
      "   [-0.58022565 -1.5578152  -0.4453833  -0.21199392 -1.2744329   0.20811816]\n",
      "32: action: 5, reward: 0.5501037696645232, max_logit: 0.2606048583984375\n",
      "   [-0.5398266  -1.5729798  -0.44210237 -0.15172741 -1.2725505   0.26060486]\n",
      "33: action: 5, reward: 0.5740253053266784, max_logit: 0.2746577858924866\n",
      "   [-0.5277476  -1.6071538  -0.43637285 -0.13891871 -1.2653924   0.2746578 ]\n",
      "34: action: 5, reward: 0.5984736585104735, max_logit: 0.3259877562522888\n",
      "   [-0.50842077 -1.642434   -0.42913386 -0.10044399 -1.2372267   0.32598776]\n",
      "35: action: 5, reward: 0.6234604311759594, max_logit: 0.311754047870636\n",
      "   [-0.51018584 -1.6362499  -0.4281092  -0.11063237 -1.2424958   0.31175405]\n",
      "36: action: 5, reward: 0.6489974807900205, max_logit: 0.29318398237228394\n",
      "   [-0.52738005 -1.6556937  -0.43405598 -0.12896621 -1.2459588   0.29318398]\n",
      "37: action: 5, reward: 0.6750969259533339, max_logit: 0.27122262120246887\n",
      "   [-0.52019346 -1.6553013  -0.43412513 -0.13837641 -1.238239    0.27122262]\n",
      "38: action: 5, reward: 0.7017711521512473, max_logit: 0.2795657515525818\n",
      "   [-0.5319051  -1.6633958  -0.4270335  -0.15057942 -1.258357    0.27956575]\n",
      "39: action: 5, reward: 0.7290328176313083, max_logit: 0.2733055651187897\n",
      "   [-0.5199168  -1.6550201  -0.4135157  -0.15756024 -1.2310554   0.27330557]\n",
      "40: action: 5, reward: 0.756894859410233, max_logit: 0.2825322449207306\n",
      "   [-0.5339961  -1.6691146  -0.4080739  -0.16131705 -1.2460142   0.28253224]\n",
      "41: action: 5, reward: 0.7853704994131641, max_logit: 0.2925761342048645\n",
      "   [-0.5079973  -1.6544721  -0.39764208 -0.149549   -1.2140634   0.29257613]\n",
      "42: action: 5, reward: 0.8144732507481316, max_logit: 0.33381810784339905\n",
      "   [-0.56127614 -1.7018423  -0.41902003 -0.20858537 -1.1933016   0.3338181 ]\n",
      "43: action: 5, reward: 0.8442169241186958, max_logit: 0.40877386927604675\n",
      "   [-0.5662472  -1.7030668  -0.43021807 -0.22980379 -1.1535728   0.40877387]\n",
      "44: action: 5, reward: 0.8746156343778129, max_logit: 0.40426701307296753\n",
      "   [-0.6474694  -1.7801244  -0.460856   -0.34134442 -1.1381359   0.404267  ]\n",
      "45: action: 5, reward: 0.9056838072260351, max_logit: 0.41529613733291626\n",
      "   [-0.6834242  -1.8280793  -0.5155069  -0.39838493 -1.1493165   0.41529614]\n",
      "46: action: 5, reward: 0.9374361860572232, max_logit: 0.409607470035553\n",
      "   [-0.7075346  -1.8337871  -0.5279001  -0.41604865 -1.1811442   0.40960747]\n",
      "47: action: 5, reward: 0.9698878389550207, max_logit: 0.4228338897228241\n",
      "   [-0.68761307 -1.8173195  -0.5160312  -0.39464098 -1.1625144   0.4228339 ]\n",
      "48: action: 5, reward: 1.0030541658434093, max_logit: 0.44968345761299133\n",
      "   [-0.6892949  -1.8126613  -0.5307458  -0.38836545 -1.1930056   0.44968346]\n",
      "49: action: 5, reward: 1.0369509057947386, max_logit: 0.4595816731452942\n",
      "   [-0.6696516  -1.8081983  -0.5129544  -0.3744666  -1.1703349   0.45958167]\n",
      "50: action: 5, reward: 1.0715941444986992, max_logit: 0.44344839453697205\n",
      "   [-0.6974332 -1.8173015 -0.5267108 -0.404     -1.1945585  0.4434484]\n",
      "51: action: 5, reward: 1.1070003218957838, max_logit: 0.4526951313018799\n",
      "   [-0.6752178  -1.8113226  -0.50456697 -0.38639235 -1.166483    0.45269513]\n",
      "52: action: 5, reward: 1.1431862399788553, max_logit: 0.45066216588020325\n",
      "   [-0.69844776 -1.823908   -0.5174739  -0.41509366 -1.1860244   0.45066217]\n",
      "53: action: 5, reward: 1.1801690707665298, max_logit: 0.4530862867832184\n",
      "   [-0.6878133  -1.8312796  -0.510515   -0.39000055 -1.1686987   0.4530863 ]\n",
      "54: action: 5, reward: 1.2179663644521534, max_logit: 0.4115632474422455\n",
      "   [-0.72376364 -1.8846959  -0.55801564 -0.42582077 -1.1896493   0.41156325]\n",
      "55: action: 5, reward: 0.36068841808254704, max_logit: 0.3610580563545227\n",
      "   [-0.7486118  -1.9432675  -0.5779523  -0.45354155 -1.2041467   0.36105806]\n",
      "56: action: 5, reward: 0.38043851059446887, max_logit: 0.2602352797985077\n",
      "   [-0.81350297 -2.0317252  -0.62397176 -0.5424378  -1.2231421   0.26023528]\n",
      "57: action: 5, reward: 0.40062355406172373, max_logit: 0.27770698070526123\n",
      "   [-0.8184809  -2.0346303  -0.62295    -0.5382283  -1.2403731   0.27770698]\n",
      "58: action: 5, reward: 0.4212531272917746, max_logit: 0.3318651616573334\n",
      "   [-0.7878018  -2.0013595  -0.61834466 -0.49674302 -1.2353488   0.33186516]\n",
      "59: action: 5, reward: 0.44233702004357484, max_logit: 0.37728217244148254\n",
      "   [-0.7735824  -1.9658691  -0.6074446  -0.45406595 -1.2230098   0.37728217]\n",
      "60: action: 5, reward: 0.46388523767329665, max_logit: 0.3601512014865875\n",
      "   [-0.78374285 -1.96372    -0.6469484  -0.45588177 -1.2514734   0.3601512 ]\n",
      "61: action: 5, reward: 0.4859080058823697, max_logit: 0.3212377727031708\n",
      "   [-0.8070514  -1.9668862  -0.6556985  -0.46914652 -1.2682865   0.32123777]\n",
      "62: action: 5, reward: 0.5084157755700855, max_logit: 0.2993336021900177\n",
      "   [-0.79196876 -1.9764755  -0.6540907  -0.46469045 -1.2528353   0.2993336 ]\n",
      "63: action: 5, reward: 0.5314192277930695, max_logit: 0.16006694734096527\n",
      "   [-0.8262077  -2.001099   -0.7700436  -0.5710051  -1.4083683   0.16006695]\n",
      "64: action: 5, reward: -0.3409783608157216, max_logit: -0.09363699704408646\n",
      "   [-0.8070913  -2.0689268  -0.84159386 -0.6377461  -1.5072384  -0.093637  ]\n",
      "65: action: 5, reward: -0.336680886342073, max_logit: -0.4315492510795593\n",
      "   [-0.8333424  -2.0962987  -0.9970904  -0.7711922  -1.7387015  -0.43154925]\n",
      "66: action: 5, reward: -0.3322887697483075, max_logit: -0.8694998621940613\n",
      "   [-0.8850532  -2.1141016  -1.184723   -0.88757795 -1.9445719  -0.86949986]\n",
      "67: action: 5, reward: -0.32779992675656494, max_logit: -0.7947003245353699\n",
      "   [-0.82157665 -2.0830266  -1.1324267  -0.83124614 -1.8794177  -0.7947003 ]\n",
      "68: action: 5, reward: -0.3232122271874964, max_logit: -0.804034948348999\n",
      "   [-0.8497899  -2.111635   -1.1553955  -0.8560538  -1.9090949  -0.80403495]\n",
      "69: action: 5, reward: -0.3185234939493885, max_logit: -0.7448024153709412\n",
      "   [-0.8056657 -2.0442247 -1.1518908 -0.8007828 -1.8894211 -0.7448024]\n",
      "70: action: 5, reward: -0.31373150200502464, max_logit: -0.6992934346199036\n",
      "   [-0.77859503 -2.0246406  -1.1569039  -0.75762737 -1.8808678  -0.69929343]\n",
      "71: action: 5, reward: -0.30883397731579426, max_logit: -0.6575437188148499\n",
      "   [-0.7333164  -1.9622086  -1.1603664  -0.70451593 -1.8658046  -0.6575437 ]\n",
      "72: action: 5, reward: -0.30382859576254867, max_logit: -0.6728988289833069\n",
      "   [-0.7260367 -1.9575604 -1.1884661 -0.6847677 -1.8905882 -0.6728988]\n",
      "73: action: 5, reward: -0.29871298204269026, max_logit: -0.7199191451072693\n",
      "   [-0.7521597  -1.9895796  -1.1844101  -0.7203398  -1.8896009  -0.71991915]\n",
      "74: action: 3, reward: -0.2934847085429739, max_logit: -0.6927297115325928\n",
      "   [-0.7395249  -2.0069559  -1.126093   -0.6927297  -1.8916506  -0.76942956]\n",
      "75: action: 3, reward: -0.2881412941874833, max_logit: -0.7364727258682251\n",
      "   [-0.7543406 -2.0589895 -1.0882344 -0.7364727 -1.8862329 -0.8318186]\n",
      "76: action: 3, reward: -0.282680203260237, max_logit: -0.6394345164299011\n",
      "   [-0.6941399  -2.027515   -0.9924941  -0.6394345  -1.8435724  -0.79662067]\n",
      "77: action: 3, reward: -0.2770988442018651, max_logit: -0.5783424973487854\n",
      "   [-0.6357612  -2.0175245  -0.9153783  -0.5783425  -1.806082   -0.78457206]\n",
      "78: action: 3, reward: -0.2713945683797853, max_logit: -0.5679771900177002\n",
      "   [-0.63317066 -2.0111053  -0.9126049  -0.5679772  -1.8030986  -0.7827634 ]\n",
      "79: action: 3, reward: -0.26556466883129515, max_logit: -0.5736294984817505\n",
      "   [-0.63099486 -2.0233684  -0.9080966  -0.5736295  -1.7928799  -0.78960735]\n",
      "80: action: 3, reward: -0.25960637897898337, max_logit: -0.5928872227668762\n",
      "   [-0.6474748 -2.0299206 -0.9140312 -0.5928872 -1.8031393 -0.8099512]\n",
      "81: action: 3, reward: -0.2535168713178511, max_logit: -0.5976060628890991\n",
      "   [-0.6371366  -2.0412886  -0.9051451  -0.59760606 -1.7795246  -0.8182581 ]\n",
      "82: action: 3, reward: -0.2472932560735206, max_logit: -0.5958790183067322\n",
      "   [-0.6420998  -2.0267782  -0.90203005 -0.595879   -1.8027539  -0.81592506]\n",
      "83: action: 3, reward: -0.24093257983089278, max_logit: -0.599530041217804\n",
      "   [-0.63545424 -2.0331593  -0.9043969  -0.59953004 -1.7823756  -0.8147432 ]\n",
      "84: action: 3, reward: -0.23443182413260547, max_logit: -0.6060768365859985\n",
      "   [-0.64384717 -2.0322301  -0.9047439  -0.60607684 -1.7887354  -0.814593  ]\n",
      "85: action: 3, reward: -0.22778790404662472, max_logit: -0.6521371603012085\n",
      "   [-0.6816016  -2.0575187  -0.9587721  -0.65213716 -1.8123441  -0.85814685]\n",
      "86: action: 3, reward: -0.22099766670229143, max_logit: -0.6856994032859802\n",
      "   [-0.70919317 -2.0574558  -0.96036375 -0.6856994  -1.7745308  -0.90135694]\n",
      "87: action: 3, reward: -0.2140578897941271, max_logit: -0.6843627691268921\n",
      "   [-0.7203825  -2.0316768  -0.9912497  -0.68436277 -1.7885964  -0.90966743]\n",
      "88: action: 3, reward: -0.20696528005268955, max_logit: -0.7167199850082397\n",
      "   [-0.7449854 -2.0298674 -0.998369  -0.71672   -1.7985345 -0.9463144]\n",
      "89: action: 3, reward: -0.19971647168175288, max_logit: -0.6864879131317139\n",
      "   [-0.7200988  -2.0122406  -0.98437965 -0.6864879  -1.7995758  -0.92732614]\n",
      "90: action: 3, reward: -0.19230802476106956, max_logit: -0.7031957507133484\n",
      "   [-0.7389423  -2.0172017  -1.0119815  -0.70319575 -1.8450112  -0.9272995 ]\n",
      "91: action: 3, reward: -0.18473642361395717, max_logit: -0.6640885472297668\n",
      "   [-0.71244997 -1.9953704  -0.99056983 -0.66408855 -1.8392812  -0.9010231 ]\n",
      "92: action: 3, reward: -0.17699807513893484, max_logit: -0.6629160642623901\n",
      "   [-0.71060914 -1.9974099  -0.9945585  -0.66291606 -1.8530757  -0.886403  ]\n",
      "93: action: 3, reward: -0.1690893071046178, max_logit: -0.6398820877075195\n",
      "   [-0.69667476 -1.9864737  -0.98144263 -0.6398821  -1.8489945  -0.8708599 ]\n",
      "94: action: 3, reward: -0.16100636640706098, max_logit: -0.6374384164810181\n",
      "   [-0.68946487 -1.9840733  -0.9768389  -0.6374384  -1.84012    -0.8651971 ]\n",
      "95: action: 3, reward: -0.1527454172887243, max_logit: -0.5417988300323486\n",
      "   [-0.613063   -1.9288291  -0.9205159  -0.54179883 -1.7850423  -0.8008781 ]\n",
      "96: action: 3, reward: -0.14430253951821492, max_logit: -0.423828661441803\n",
      "   [-0.51447374 -1.8702587  -0.8532334  -0.42382866 -1.7148944  -0.68904305]\n",
      "97: action: 3, reward: -0.13567372652994258, max_logit: -0.3101615309715271\n",
      "   [-0.4418674  -1.8134207  -0.801175   -0.31016153 -1.6734543  -0.5997599 ]\n",
      "98: action: 3, reward: -0.12685488352280455, max_logit: -0.22174163162708282\n",
      "   [-0.37009978 -1.7880062  -0.7575115  -0.22174163 -1.6467803  -0.5200934 ]\n",
      "99: action: 3, reward: -0.11784182551699895, max_logit: -0.20883849263191223\n",
      "   [-0.3597347  -1.7644631  -0.753905   -0.2088385  -1.6320096  -0.50928885]\n",
      "100: action: 3, reward: -0.1086302753680436, max_logit: -0.21782186627388\n",
      "   [-0.36529815 -1.7786902  -0.76805824 -0.21782187 -1.6424123  -0.52426016]\n",
      "101: action: 3, reward: -0.09921586173705808, max_logit: -0.22530783712863922\n",
      "   [-0.3661934  -1.7763668  -0.77865195 -0.22530784 -1.6589777  -0.52983826]\n",
      "102: action: 3, reward: -0.08959411701634597, max_logit: -0.23200556635856628\n",
      "   [-0.37486285 -1.7913561  -0.79310644 -0.23200557 -1.6700554  -0.5498361 ]\n",
      "103: action: 3, reward: -0.07976047520929265, max_logit: -0.2515923082828522\n",
      "   [-0.39028984 -1.7962681  -0.79875976 -0.2515923  -1.6904299  -0.54996943]\n",
      "104: action: 3, reward: -0.06971026976357288, max_logit: -0.26054081320762634\n",
      "   [-0.4011323 -1.8149123 -0.8077992 -0.2605408 -1.6974161 -0.560676 ]\n",
      "105: action: 3, reward: -0.05943873135663936, max_logit: -0.2889965772628784\n",
      "   [-0.42303264 -1.8188701  -0.8238785  -0.28899658 -1.7189815  -0.5648059 ]\n",
      "106: action: 3, reward: -0.048940985632441925, max_logit: -0.2850845456123352\n",
      "   [-0.41648638 -1.8140993  -0.83495045 -0.28508455 -1.6751777  -0.5354106 ]\n",
      "107: action: 3, reward: -0.03821205088830306, max_logit: -0.3472056984901428\n",
      "   [-0.45889342 -1.8241847  -0.8592865  -0.3472057  -1.6890466  -0.5418752 ]\n",
      "108: action: 3, reward: -0.027246835710852155, max_logit: -0.38233935832977295\n",
      "   [-0.4904524  -1.8527904  -0.87419987 -0.38233936 -1.689702   -0.5244437 ]\n",
      "109: action: 3, reward: -0.0160401365598965, max_logit: -0.3919707238674164\n",
      "   [-0.5008694  -1.8374102  -0.87846863 -0.39197072 -1.694302   -0.5144901 ]\n",
      "110: action: 3, reward: -0.004586635299082566, max_logit: -0.3995635509490967\n",
      "   [-0.513864   -1.8484902  -0.88036406 -0.39956355 -1.705703   -0.51526517]\n",
      "111: action: 3, reward: 0.007119103327824298, max_logit: -0.3907674252986908\n",
      "   [-0.5057605  -1.8324065  -0.8692233  -0.39076743 -1.6905382  -0.51442236]\n",
      "112: action: 3, reward: 0.019082634276239557, max_logit: -0.39897483587265015\n",
      "   [-0.5193843  -1.8373182  -0.87506706 -0.39897484 -1.7061381  -0.51638937]\n",
      "113: action: 3, reward: 0.03130963483686189, max_logit: -0.377508282661438\n",
      "   [-0.49948227 -1.8165996  -0.856561   -0.37750828 -1.6824496  -0.49908406]\n",
      "114: action: 3, reward: 0.04380590732983038, max_logit: -0.3900408148765564\n",
      "   [-0.5132764  -1.8195444  -0.86846286 -0.3900408  -1.7012163  -0.5097572 ]\n",
      "115: action: 3, reward: 0.056577381858214065, max_logit: -0.37295711040496826\n",
      "   [-0.49071386 -1.8097016  -0.85599023 -0.3729571  -1.6705341  -0.4995273 ]\n",
      "116: action: 3, reward: 0.06963011912214083, max_logit: -0.37900251150131226\n",
      "   [-0.49837595 -1.808556   -0.86356264 -0.3790025  -1.6873844  -0.503578  ]\n",
      "117: action: 3, reward: 0.08297031329490133, max_logit: -0.32823818922042847\n",
      "   [-0.4415837  -1.8061697  -0.8105182  -0.3282382  -1.642523   -0.44702265]\n",
      "118: action: 3, reward: 0.09660429496239223, max_logit: -0.23212553560733795\n",
      "   [-0.37817267 -1.7685174  -0.75070804 -0.23212554 -1.6140896  -0.3576748 ]\n",
      "119: action: 3, reward: 0.11053853412729427, max_logit: -0.17021861672401428\n",
      "   [-0.32799667 -1.739096   -0.6988114  -0.17021862 -1.5672615  -0.2784716 ]\n",
      "120: action: 3, reward: 0.12477964327941056, max_logit: -0.10914523899555206\n",
      "   [-0.28913757 -1.7179593  -0.65684855 -0.10914524 -1.5569448  -0.19448666]\n",
      "121: action: 3, reward: 0.13933438053362188, max_logit: -0.0850258618593216\n",
      "   [-0.26938516 -1.7048025  -0.6480278  -0.08502586 -1.5367429  -0.18231888]\n",
      "122: action: 3, reward: 0.15420965283694857, max_logit: -0.08934706449508667\n",
      "   [-0.27578214 -1.7099857  -0.6446358  -0.08934706 -1.538778   -0.18850543]\n",
      "123: action: 3, reward: 0.16941251924624037, max_logit: -0.10812847316265106\n",
      "   [-0.29078948 -1.721547   -0.6716941  -0.10812847 -1.5667007  -0.1997927 ]\n",
      "124: action: 3, reward: 0.1849501942780504, max_logit: -0.11590658128261566\n",
      "   [-0.29739472 -1.730128   -0.6608695  -0.11590658 -1.5583749  -0.21253203]\n",
      "125: action: 3, reward: 0.2008300513322819, max_logit: -0.1292315125465393\n",
      "   [-0.30599877 -1.7405963  -0.6781751  -0.12923151 -1.5847669  -0.20530663]\n",
      "126: action: 3, reward: 0.2170596261912335, max_logit: -0.1274055391550064\n",
      "   [-0.3021089  -1.7429057  -0.66909003 -0.12740554 -1.5711682  -0.20918201]\n",
      "127: action: 3, reward: 0.2336466205957033, max_logit: -0.13695400953292847\n",
      "   [-0.29678887 -1.7398157  -0.66624093 -0.13695401 -1.5468332  -0.17581458]\n",
      "128: action: 5, reward: 0.2505989058998472, max_logit: -0.13152895867824554\n",
      "   [-0.3275165  -1.7388057  -0.6703105  -0.19411303 -1.5195302  -0.13152896]\n",
      "129: action: 5, reward: 0.267924526806529, max_logit: -0.10457626730203629\n",
      "   [-0.31486958 -1.7291938  -0.65541923 -0.1871545  -1.4714485  -0.10457627]\n",
      "130: action: 5, reward: 0.28563170518493153, max_logit: -0.09244797378778458\n",
      "   [-0.37166846 -1.7409946  -0.67044675 -0.27793097 -1.4733608  -0.09244797]\n",
      "131: action: 5, reward: 0.30372884397224303, max_logit: -0.06530816107988358\n",
      "   [-0.34890652 -1.7136523  -0.6552803  -0.24860178 -1.4495625  -0.06530816]\n",
      "132: action: 5, reward: 0.3222245311612689, max_logit: -0.08066991716623306\n",
      "   [-0.3769694  -1.7306602  -0.6739776  -0.2845789  -1.4721816  -0.08066992]\n",
      "133: action: 5, reward: 0.3411275438758615, max_logit: -0.0727374330163002\n",
      "   [-0.3635983  -1.7314094  -0.668201   -0.27746192 -1.4574724  -0.07273743]\n",
      "134: action: 5, reward: 0.36044685253610204, max_logit: -0.07438380271196365\n",
      "   [-0.36654243 -1.7358615  -0.67328227 -0.2768318  -1.4543083  -0.0743838 ]\n",
      "135: action: 5, reward: 0.3801916251152115, max_logit: -0.10559607297182083\n",
      "   [-0.40198988 -1.7784336  -0.7053755  -0.32182676 -1.4947635  -0.10559607]\n",
      "136: action: 5, reward: 0.40037123149021, max_logit: -0.09736318141222\n",
      "   [-0.37404943 -1.7452147  -0.6997048  -0.2860487  -1.4760475  -0.09736318]\n",
      "137: action: 5, reward: 0.4209952478883894, max_logit: -0.10963816195726395\n",
      "   [-0.41278422 -1.7998248  -0.7153041  -0.32255328 -1.5136998  -0.10963816]\n",
      "138: action: 5, reward: 0.44207346143171034, max_logit: -0.006099472753703594\n",
      "   [-0.3143035  -1.7215382  -0.6507556  -0.19506659 -1.4443414  -0.00609947]\n",
      "139: action: 5, reward: 0.46361587478127764, max_logit: 0.06566571444272995\n",
      "   [-0.2832486  -1.7406822  -0.5989787  -0.1598018  -1.4104369   0.06566571]\n",
      "140: action: 5, reward: 0.48563271088410137, max_logit: 0.16638962924480438\n",
      "   [-0.22865368 -1.6920904  -0.56670797 -0.08085976 -1.3848078   0.16638963]\n",
      "141: action: 5, reward: 0.5081344178243934, max_logit: 0.2206496149301529\n",
      "   [-0.20681511 -1.6948088  -0.5343825  -0.05703164 -1.3776603   0.22064961]\n",
      "142: action: 5, reward: 0.531131673781704, max_logit: 0.21653549373149872\n",
      "   [-0.20409577 -1.6786479  -0.52492386 -0.04606678 -1.3639717   0.2165355 ]\n",
      "143: action: 5, reward: 0.5546353920982482, max_logit: 0.2218645066022873\n",
      "   [-0.2013158  -1.6692096  -0.52013123 -0.04859378 -1.3330113   0.2218645 ]\n",
      "144: action: 5, reward: 0.5786567264578305, max_logit: 0.20955047011375427\n",
      "   [-0.20756136 -1.6699669  -0.5124522  -0.06003304 -1.3219762   0.20955047]\n",
      "145: action: 5, reward: 0.603207076178823, max_logit: 0.19886712729930878\n",
      "   [-0.20258154 -1.6660886  -0.50601727 -0.06969818 -1.2898558   0.19886713]\n",
      "146: action: 5, reward: 0.6282980916237082, max_logit: 0.20162391662597656\n",
      "   [-0.2060811  -1.6555895  -0.4943587  -0.08185525 -1.2990324   0.20162392]\n",
      "147: action: 5, reward: 0.6539416797277566, max_logit: 0.18243126571178436\n",
      "   [-0.18981542 -1.6463014  -0.48978767 -0.07616589 -1.2861756   0.18243127]\n",
      "148: action: 5, reward: 0.6801500096494593, max_logit: 0.1719937026500702\n",
      "   [-0.20279436 -1.6546695  -0.48443526 -0.09379949 -1.3072659   0.1719937 ]\n",
      "149: action: 5, reward: 0.7069355185453995, max_logit: 0.19651369750499725\n",
      "   [-0.21964851 -1.6658107  -0.49800405 -0.14124437 -1.2825658   0.1965137 ]\n",
      "150: action: 5, reward: 0.7343109174723024, max_logit: 0.15631863474845886\n",
      "   [-0.28602868 -1.7326978  -0.51078737 -0.21087818 -1.2589209   0.15631863]\n",
      "151: action: 5, reward: 0.7622891974190634, max_logit: 0.15482701361179352\n",
      "   [-0.33262143 -1.7538112  -0.5328787  -0.28781486 -1.244785    0.15482701]\n",
      "152: action: 5, reward: 0.7908836354716194, max_logit: 0.11238133162260056\n",
      "   [-0.41054356 -1.8256987  -0.5452578  -0.40773052 -1.2285573   0.11238133]\n",
      "153: action: 5, reward: 0.8201078011135862, max_logit: 0.13626980781555176\n",
      "   [-0.38428742 -1.7943147  -0.5352195  -0.37447205 -1.2067249   0.13626981]\n",
      "154: action: 5, reward: 0.8499755626656537, max_logit: 0.1332487314939499\n",
      "   [-0.4086945  -1.8013239  -0.5579179  -0.40202287 -1.2535046   0.13324873]\n",
      "155: action: 5, reward: 0.8805010938667945, max_logit: 0.15516142547130585\n",
      "   [-0.38517654 -1.7894199  -0.54471827 -0.3756687  -1.229308    0.15516143]\n",
      "156: action: 5, reward: 0.9116988806004079, max_logit: 0.17668558657169342\n",
      "   [-0.38170743 -1.7817334  -0.55062574 -0.36641595 -1.2456423   0.17668559]\n",
      "157: action: 5, reward: 0.9435837277685928, max_logit: 0.16751877963542938\n",
      "   [-0.380899   -1.7973589  -0.55175763 -0.37019688 -1.2470522   0.16751878]\n",
      "158: action: 5, reward: 0.9761707663178093, max_logit: 0.13867701590061188\n",
      "   [-0.4151979  -1.8088018  -0.5663682  -0.40707114 -1.2726636   0.13867702]\n",
      "159: action: 5, reward: 1.0094754604192668, max_logit: 0.1252126544713974\n",
      "   [-0.38019565 -1.807589   -0.52510154 -0.37112838 -1.228657    0.12521265]\n",
      "160: action: 5, reward: 1.0435136148074426, max_logit: 0.06633865088224411\n",
      "   [-0.40740258 -1.8398525  -0.53226626 -0.41426966 -1.2258198   0.06633865]\n",
      "161: action: 5, reward: 1.0783013822802143, max_logit: 0.054741013795137405\n",
      "   [-0.38742566 -1.8470309  -0.47959128 -0.4023871  -1.1919167   0.05474101]\n",
      "162: action: 5, reward: 1.113855271364166, max_logit: -0.004118631593883038\n",
      "   [-0.41731024 -1.8850428  -0.50235075 -0.44928187 -1.1965508  -0.00411863]\n",
      "163: action: 5, reward: 1.150192154148706, max_logit: 0.005476881749927998\n",
      "   [-0.42383665 -1.8883226  -0.50111985 -0.4578728  -1.2058054   0.00547688]\n",
      "164: action: 5, reward: 1.1873292742927124, max_logit: 0.014789124019443989\n",
      "   [-0.39378953 -1.8552828  -0.50326455 -0.42103544 -1.1942188   0.01478912]\n",
      "165: action: 5, reward: 1.2252842552075078, max_logit: 0.032370854169130325\n",
      "   [-0.40082288 -1.8502797  -0.49790275 -0.41975915 -1.1854008   0.03237085]\n",
      "166: action: 5, reward: 1.2640751084200446, max_logit: 0.06458842009305954\n",
      "   [-0.3747431  -1.8172827  -0.5047378  -0.38602597 -1.1845267   0.06458842]\n",
      "167: action: 5, reward: 1.3037202421202696, max_logit: 0.06911296397447586\n",
      "   [-0.37597752 -1.8291979  -0.4934465  -0.39172235 -1.1646662   0.06911296]\n",
      "168: action: 5, reward: 0.4483308302470332, max_logit: -0.005229930393397808\n",
      "   [-0.4106536  -1.8742232  -0.49911636 -0.46279466 -1.1704712  -0.00522993]\n",
      "169: action: 5, reward: 0.470011047940679, max_logit: -0.04100922867655754\n",
      "   [-0.41638327 -1.9039327  -0.4779459  -0.47946003 -1.1599565  -0.04100923]\n",
      "170: action: 5, reward: 0.492168723215447, max_logit: -0.1521807461977005\n",
      "   [-0.49731123 -1.9514474  -0.48261848 -0.60813546 -1.1586739  -0.15218075]\n",
      "171: action: 5, reward: 0.514814370990744, max_logit: -0.18551887571811676\n",
      "   [-0.53433484 -1.97803    -0.45456675 -0.69191074 -1.096544   -0.18551888]\n",
      "172: action: 5, reward: 0.537958737753208, max_logit: -0.259098082780838\n",
      "   [-0.6393723  -2.0391612  -0.5165275  -0.82869923 -1.1266801  -0.25909808]\n",
      "173: action: 5, reward: 0.5616128066564511, max_logit: -0.20526714622974396\n",
      "   [-0.652072   -2.0190654  -0.4817433  -0.8553038  -1.0780313  -0.20526715]\n",
      "174: action: 5, reward: 0.5857878027331124, max_logit: -0.11857081204652786\n",
      "   [-0.6040686  -1.9638035  -0.4746123  -0.78304905 -1.0488867  -0.11857081]\n",
      "175: action: 5, reward: 0.6104951982216937, max_logit: -0.02356560155749321\n",
      "   [-0.56290895 -1.9314369  -0.46589804 -0.7137115  -1.0465703  -0.0235656 ]\n",
      "176: action: 5, reward: 0.6357467180107088, max_logit: -0.023202162235975266\n",
      "   [-0.52908933 -1.9041082  -0.49160182 -0.6646404  -1.0466051  -0.02320216]\n",
      "177: action: 5, reward: 0.6615543452027254, max_logit: -0.055477600544691086\n",
      "   [-0.5590419  -1.9395943  -0.49870095 -0.7042655  -1.0717384  -0.0554776 ]\n",
      "178: action: 5, reward: 0.687930326800944, max_logit: -0.18683554232120514\n",
      "   [-0.6106997  -2.0104868  -0.5145904  -0.78834605 -1.1071017  -0.18683554]\n",
      "179: action: 5, reward: 0.7148871795210102, max_logit: -0.32233926653862\n",
      "   [-0.69506276 -2.1037257  -0.53254724 -0.9134892  -1.1252985  -0.32233927]\n",
      "180: action: 5, reward: 0.742437695730819, max_logit: -0.3743264675140381\n",
      "   [-0.7221796  -2.124929   -0.5210639  -0.9574134  -1.1188513  -0.37432647]\n",
      "181: action: 5, reward: 0.7705949495211298, max_logit: -0.481227308511734\n",
      "   [-0.7549045  -2.1871097  -0.51224303 -1.0170727  -1.1386526  -0.4812273 ]\n",
      "182: action: 2, reward: 0.7993723029098733, max_logit: -0.5160406827926636\n",
      "   [-0.7483993 -2.2013857 -0.5160407 -1.0047945 -1.1617851 -0.5188393]\n",
      "183: action: 2, reward: 0.8287834121830936, max_logit: -0.5463542342185974\n",
      "   [-0.7722774  -2.2300823  -0.54635423 -1.0229113  -1.2181082  -0.6040768 ]\n",
      "184: action: 2, reward: 0.8588422343755355, max_logit: -0.5480383634567261\n",
      "   [-0.76851934 -2.242543   -0.54803836 -1.00027    -1.2396512  -0.62712795]\n",
      "185: action: 2, reward: -0.00634460575574295, max_logit: -0.6016414761543274\n",
      "   [-0.7856826 -2.2531314 -0.6016415 -1.0131896 -1.2722781 -0.6832116]\n",
      "186: action: 2, reward: 0.00532241756240729, max_logit: -0.6408351063728333\n",
      "   [-0.7904162  -2.2387738  -0.6408351  -1.000281   -1.2922841  -0.68655175]\n",
      "187: action: 2, reward: 0.01724638058527335, max_logit: -0.6900344491004944\n",
      "   [-0.7977862  -2.2297382  -0.69003445 -0.98336345 -1.3294104  -0.70182276]\n",
      "188: action: 5, reward: 0.029432941826604483, max_logit: -0.6936058402061462\n",
      "   [-0.81085765 -2.216679   -0.7212072  -0.988914   -1.3405983  -0.69360584]\n",
      "189: action: 5, reward: 0.04188788441607073, max_logit: -0.6347756385803223\n",
      "   [-0.77105564 -2.1598911  -0.7080296  -0.91855896 -1.3645734  -0.63477564]\n",
      "190: action: 5, reward: 0.054617118843645375, max_logit: -0.6100645065307617\n",
      "   [-0.752449  -2.138304  -0.6785455 -0.9012503 -1.3658934 -0.6100645]\n",
      "191: action: 5, reward: 0.06762668576442686, max_logit: -0.6136505007743835\n",
      "   [-0.7670563  -2.1417837  -0.6586064  -0.94730496 -1.3300545  -0.6136505 ]\n",
      "192: action: 2, reward: 0.08092275886522997, max_logit: -0.6745601296424866\n",
      "   [-0.84767133 -2.2497811  -0.6745601  -1.0798676  -1.3486677  -0.7404174 ]\n",
      "193: action: 2, reward: 0.09451164779430733, max_logit: -0.681049108505249\n",
      "   [-0.90377396 -2.317118   -0.6810491  -1.180262   -1.3228856  -0.7864251 ]\n",
      "194: action: 2, reward: 0.10839980115559184, max_logit: -0.7874454259872437\n",
      "   [-1.0320537  -2.4519587  -0.7874454  -1.3576999  -1.3558446  -0.91093165]\n",
      "195: action: 2, reward: 0.12259380956887952, max_logit: -0.8339478373527527\n",
      "   [-1.0607425  -2.4774718  -0.83394784 -1.3804029  -1.3243309  -0.9438111 ]\n",
      "196: action: 2, reward: 0.13710040879740715, max_logit: -0.9055703282356262\n",
      "   [-1.0982146 -2.4957812 -0.9055703 -1.4103547 -1.3586378 -0.9728978]\n",
      "197: action: 2, reward: 0.15192648294430658, max_logit: -0.9424337148666382\n",
      "   [-1.1132824 -2.5167964 -0.9424337 -1.424257  -1.3401535 -0.9877047]\n",
      "198: action: 2, reward: 0.1670790677194545, max_logit: -0.9434201717376709\n",
      "   [-1.1088384  -2.5108378  -0.9434202  -1.4079735  -1.3391688  -0.96784836]\n",
      "199: action: 2, reward: 0.18256535377826663, max_logit: -0.9345575571060181\n",
      "   [-1.1134466  -2.526981   -0.93455756 -1.4027847  -1.3497051  -0.9498334 ]\n",
      "200: action: 5, reward: 0.19839269013402183, max_logit: -0.917436957359314\n",
      "   [-1.0903883  -2.5096443  -0.9265059  -1.3660741  -1.3456984  -0.91743696]\n",
      "201: action: 5, reward: 0.21456858764533393, max_logit: -0.9233531355857849\n",
      "   [-1.1264999  -2.5397513  -0.9352581  -1.3937349  -1.3931967  -0.92335314]\n",
      "202: action: 5, reward: 0.2311007225804288, max_logit: -0.8939110636711121\n",
      "   [-1.1215202  -2.5501022  -0.95078003 -1.3939323  -1.4132303  -0.89391106]\n",
      "203: action: 5, reward: 0.24799694025991442, max_logit: -0.8734696507453918\n",
      "   [-1.1111276  -2.5545382  -0.95389336 -1.378999   -1.4356881  -0.87346965]\n",
      "204: action: 5, reward: 0.26526525877977697, max_logit: -0.846648633480072\n",
      "   [-1.1025239  -2.5377321  -0.95461696 -1.3741618  -1.4065701  -0.84664863]\n",
      "205: action: 5, reward: 0.28291387281636576, max_logit: -0.8455056548118591\n",
      "   [-1.1188762  -2.560668   -0.98444676 -1.3757508  -1.4519668  -0.84550565]\n",
      "206: action: 5, reward: 0.30095115751517465, max_logit: -0.8627814650535583\n",
      "   [-1.1141015  -2.5640934  -0.9672013  -1.3855904  -1.4210299  -0.86278147]\n",
      "207: action: 5, reward: 0.31938567246526606, max_logit: -0.9006559252738953\n",
      "   [-1.1608005  -2.6174567  -0.99638957 -1.4263277  -1.4495784  -0.9006559 ]\n",
      "208: action: 5, reward: 0.3382261657612211, max_logit: -0.9225234985351562\n",
      "   [-1.1789238 -2.6615314 -0.9609623 -1.4792724 -1.4204906 -0.9225235]\n",
      "209: action: 2, reward: 0.3574815781545463, max_logit: -0.9371646046638489\n",
      "   [-1.1969862 -2.7136834 -0.9371646 -1.5261874 -1.3983579 -0.9576773]\n",
      "210: action: 2, reward: 0.3771610472965045, max_logit: -0.9023082852363586\n",
      "   [-1.2016485  -2.7353535  -0.9023083  -1.5506082  -1.3799767  -0.97244257]\n",
      "211: action: 2, reward: 0.3972739120743857, max_logit: -0.8564051985740662\n",
      "   [-1.1796846  -2.728473   -0.8564052  -1.5480263  -1.3253193  -0.96717626]\n",
      "212: action: 2, reward: -0.47807792260642146, max_logit: -0.8882064819335938\n",
      "   [-1.2134026 -2.7124124 -0.8882065 -1.5849808 -1.3729572 -1.0022713]\n",
      "213: action: 2, reward: -0.47679975476845654, max_logit: -0.9311433434486389\n",
      "   [-1.3064198  -2.6885977  -0.93114334 -1.7293239  -1.3699143  -1.1294982 ]\n",
      "214: action: 2, reward: -0.4754934381852711, max_logit: -1.0681052207946777\n",
      "   [-1.5266694 -2.6842792 -1.0681052 -2.0077906 -1.4481976 -1.3650198]\n",
      "215: action: 2, reward: -0.47415835294464875, max_logit: -1.1919156312942505\n",
      "   [-1.6784112 -2.6492875 -1.1919156 -2.1530185 -1.5594065 -1.5799057]\n",
      "216: action: 2, reward: -0.4727938654822136, max_logit: -1.2337408065795898\n",
      "   [-1.7956573 -2.627879  -1.2337408 -2.3212755 -1.4831938 -1.8002145]\n",
      "217: action: 2, reward: -0.4713993282807724, max_logit: -1.234663724899292\n",
      "   [-1.787261  -2.6070685 -1.2346637 -2.2981727 -1.4943717 -1.7627329]\n",
      "218: action: 2, reward: -0.46997407956303594, max_logit: -1.2165029048919678\n",
      "   [-1.7958486 -2.6194103 -1.2165029 -2.3041549 -1.4823723 -1.7492297]\n",
      "219: action: 2, reward: -0.4685174429775721, max_logit: -1.2317734956741333\n",
      "   [-1.8117272 -2.6359415 -1.2317735 -2.3105812 -1.5204608 -1.7351131]\n",
      "220: action: 2, reward: -0.467028727277844, max_logit: -1.2239460945129395\n",
      "   [-1.82673   -2.655063  -1.2239461 -2.3212855 -1.5219024 -1.7322998]\n",
      "221: action: 2, reward: -0.46550722599417865, max_logit: -1.2206566333770752\n",
      "   [-1.8301796 -2.6662145 -1.2206566 -2.3265247 -1.5463107 -1.710026 ]\n",
      "222: action: 2, reward: -0.46395221709851253, max_logit: -1.2280869483947754\n",
      "   [-1.8384289 -2.6727622 -1.228087  -2.3387387 -1.5614569 -1.7140807]\n",
      "223: action: 2, reward: -0.4623629626617527, max_logit: -1.1870720386505127\n",
      "   [-1.7944354 -2.6593738 -1.187072  -2.2826455 -1.5711597 -1.6932335]\n",
      "224: action: 2, reward: -0.4607387085035931, max_logit: -1.157674789428711\n",
      "   [-1.7629942 -2.6365466 -1.1576748 -2.2454789 -1.5620599 -1.6824529]\n",
      "225: action: 2, reward: -0.45907868383461853, max_logit: -1.1035938262939453\n",
      "   [-1.7180355 -2.6369925 -1.1035938 -2.1767852 -1.5637805 -1.6604271]\n",
      "226: action: 2, reward: -0.45738210089052644, max_logit: -1.0632052421569824\n",
      "   [-1.6819962 -2.6115096 -1.0632052 -2.1209548 -1.5411829 -1.628769 ]\n",
      "227: action: 2, reward: -0.4556481545582938, max_logit: -1.0657943487167358\n",
      "   [-1.6684628 -2.6146145 -1.0657943 -2.0990512 -1.5524718 -1.6119859]\n",
      "228: action: 2, reward: -0.4538760219941108, max_logit: -1.0598084926605225\n",
      "   [-1.6716285 -2.6139183 -1.0598085 -2.1067822 -1.536566  -1.622092 ]\n",
      "229: action: 2, reward: -0.4520648622329007, max_logit: -1.0470449924468994\n",
      "   [-1.6382583 -2.5702298 -1.047045  -2.0528352 -1.5111827 -1.5750964]\n",
      "230: action: 2, reward: -0.45021381578923964, max_logit: -1.036326289176941\n",
      "   [-1.6502942 -2.5712538 -1.0363263 -2.0654774 -1.5008783 -1.5815768]\n",
      "231: action: 2, reward: -0.4483220042494885, max_logit: -1.0599851608276367\n",
      "   [-1.6440777 -2.5481803 -1.0599852 -2.0440881 -1.5084622 -1.5852609]\n",
      "232: action: 2, reward: -0.44638852985494165, max_logit: -1.0429009199142456\n",
      "   [-1.6455231 -2.537204  -1.0429009 -2.0457644 -1.4923878 -1.5920897]\n",
      "233: action: 2, reward: -0.44441247507579607, max_logit: -1.0737943649291992\n",
      "   [-1.6443232 -2.5272202 -1.0737944 -2.030312  -1.5317144 -1.598331 ]\n",
      "234: action: 2, reward: -0.4423929021757372, max_logit: -1.1073715686798096\n",
      "   [-1.69923   -2.518673  -1.1073716 -2.0898516 -1.4948381 -1.6489604]\n",
      "235: action: 2, reward: -0.4403288527669372, max_logit: -1.1424829959869385\n",
      "   [-1.7265303 -2.5341663 -1.142483  -2.0956593 -1.5342429 -1.682653 ]\n",
      "236: action: 2, reward: -0.4382193473552517, max_logit: -1.1638013124465942\n",
      "   [-1.7543228 -2.5261776 -1.1638013 -2.1300123 -1.4973401 -1.748645 ]\n",
      "237: action: 2, reward: -0.4360633848754011, max_logit: -1.1781460046768188\n",
      "   [-1.7664412 -2.5361195 -1.178146  -2.1192448 -1.5187799 -1.7725933]\n",
      "238: action: 2, reward: -0.43385994221591545, max_logit: -1.1749112606048584\n",
      "   [-1.7654053 -2.53861   -1.1749113 -2.1101105 -1.5223283 -1.7563459]\n",
      "239: action: 2, reward: -0.43160797373361737, max_logit: -1.1566517353057861\n",
      "   [-1.7344798 -2.548367  -1.1566517 -2.0673697 -1.5196834 -1.7242383]\n",
      "240: action: 2, reward: -0.4293064107574117, max_logit: -1.1310925483703613\n",
      "   [-1.7204407 -2.5562472 -1.1310925 -2.0543656 -1.5017301 -1.6923227]\n",
      "241: action: 2, reward: -0.4269541610811485, max_logit: -1.110912799835205\n",
      "   [-1.6946133 -2.565298  -1.1109128 -2.0249054 -1.484615  -1.670428 ]\n",
      "242: action: 2, reward: -0.42455010844531665, max_logit: -1.0850335359573364\n",
      "   [-1.676688  -2.563718  -1.0850335 -2.0123415 -1.4659135 -1.6466554]\n",
      "243: action: 2, reward: -0.42209311200732313, max_logit: -1.0757640600204468\n",
      "   [-1.657077  -2.5641117 -1.0757641 -2.0028093 -1.4405956 -1.6420168]\n",
      "244: action: 2, reward: -0.4195820058001064, max_logit: -1.065028190612793\n",
      "   [-1.659518  -2.569557  -1.0650282 -2.0175178 -1.4492131 -1.6373847]\n",
      "245: action: 2, reward: -0.41701559817882744, max_logit: -1.0129128694534302\n",
      "   [-1.5675713 -2.5375037 -1.0129129 -1.9366621 -1.3931022 -1.6386496]\n",
      "246: action: 2, reward: -0.4143926712553742, max_logit: -1.0030385255813599\n",
      "   [-1.555131  -2.5553784 -1.0030385 -1.9688298 -1.3940148 -1.6564622]\n",
      "247: action: 2, reward: -0.411711980320414, max_logit: -0.9279291033744812\n",
      "   [-1.4473559 -2.517859  -0.9279291 -1.8572044 -1.3147286 -1.628217 ]\n",
      "248: action: 2, reward: -0.4089722532527161, max_logit: -0.9128605127334595\n",
      "   [-1.4134462 -2.529318  -0.9128605 -1.8384283 -1.3116134 -1.6406388]\n",
      "249: action: 2, reward: -0.40617218991546766, max_logit: -0.9328869581222534\n",
      "   [-1.4228799  -2.544966   -0.93288696 -1.8356183  -1.314618   -1.6392039 ]\n",
      "250: action: 2, reward: -0.40331046153929384, max_logit: -0.971165657043457\n",
      "   [-1.457775   -2.5738742  -0.97116566 -1.8667707  -1.3332752  -1.6662562 ]\n",
      "251: action: 2, reward: -0.40038571009169033, max_logit: -1.001478672027588\n",
      "   [-1.488472  -2.598866  -1.0014787 -1.8861823 -1.3636756 -1.7004673]\n",
      "252: action: 2, reward: -0.3973965476325698, max_logit: -1.0349808931350708\n",
      "   [-1.5245413 -2.616308  -1.0349809 -1.9089507 -1.3800145 -1.730433 ]\n",
      "253: action: 2, reward: -0.3943415556556152, max_logit: -1.0609842538833618\n",
      "   [-1.5591551 -2.6472695 -1.0609843 -1.9411479 -1.406311  -1.7780797]\n",
      "254: action: 2, reward: -0.39121928441512743, max_logit: -1.079892635345459\n",
      "   [-1.5839938 -2.646974  -1.0798926 -1.9567544 -1.4225024 -1.8023152]\n",
      "255: action: 2, reward: -0.38802825223804976, max_logit: -1.1286442279815674\n",
      "   [-1.6649629 -2.6908424 -1.1286442 -2.0363295 -1.427301  -1.8868753]\n",
      "256: action: 2, reward: -0.38476694482083923, max_logit: -1.1684139966964722\n",
      "   [-1.714639  -2.6849031 -1.168414  -2.0761733 -1.3980525 -1.9629227]\n",
      "257: action: 2, reward: -0.38143381451085534, max_logit: -1.2305608987808228\n",
      "   [-1.7857054 -2.6883743 -1.2305609 -2.1275198 -1.4326707 -2.0309386]\n",
      "258: action: 2, reward: -0.37802727957192084, max_logit: -1.2828725576400757\n",
      "   [-1.8161798 -2.687255  -1.2828726 -2.1358202 -1.4366955 -2.0994847]\n",
      "259: action: 2, reward: -0.3745457234337099, max_logit: -1.333568811416626\n",
      "   [-1.8542365 -2.7277074 -1.3335688 -2.1684346 -1.4921908 -2.1271794]\n",
      "260: action: 2, reward: -0.3709874939246048, max_logit: -1.3918883800506592\n",
      "   [-1.889178  -2.7721953 -1.3918884 -2.1774216 -1.5521115 -2.146561 ]\n",
      "261: action: 2, reward: -0.3673509024876583, max_logit: -1.4314281940460205\n",
      "   [-1.9044677 -2.8099198 -1.4314282 -2.1917295 -1.584239  -2.1351597]\n",
      "262: action: 2, reward: -0.36363422337928947, max_logit: -1.5195914506912231\n",
      "   [-1.9643886 -2.890075  -1.5195915 -2.2167425 -1.6772068 -2.1582036]\n",
      "263: action: 2, reward: -0.3598356928503323, max_logit: -1.5564528703689575\n",
      "   [-1.9728963 -2.9160857 -1.5564529 -2.1972344 -1.7035733 -2.1370747]\n",
      "264: action: 2, reward: -0.35595350830904915, max_logit: -1.6326310634613037\n",
      "   [-2.0264587 -2.981032  -1.6326311 -2.224291  -1.7821419 -2.1623285]\n",
      "265: action: 2, reward: -0.3519858274657111, max_logit: -1.6213213205337524\n",
      "   [-2.0063581 -2.9750729 -1.6213213 -2.180649  -1.7767451 -2.13189  ]\n",
      "266: action: 2, reward: -0.3479307674583401, max_logit: -1.5712268352508545\n",
      "   [-1.9285512 -2.930515  -1.5712268 -2.0962384 -1.7243426 -2.0953672]\n",
      "267: action: 2, reward: -0.34378640395919685, max_logit: -1.502486228942871\n",
      "   [-1.8304062 -2.8793612 -1.5024862 -1.9819655 -1.6933149 -2.0312505]\n",
      "268: action: 2, reward: -0.3395507702615919, max_logit: -1.4393260478973389\n",
      "   [-1.7557019 -2.8328726 -1.439326  -1.8863525 -1.6391262 -1.9903829]\n",
      "269: action: 2, reward: -0.33522185634658536, max_logit: -1.3823446035385132\n",
      "   [-1.6819321 -2.8094208 -1.3823446 -1.7983719 -1.6340446 -1.9298806]\n",
      "270: action: 2, reward: -0.33079760792913276, max_logit: -1.3948575258255005\n",
      "   [-1.6964662 -2.8124454 -1.3948575 -1.802467  -1.6461028 -1.9420283]\n",
      "271: action: 2, reward: -0.32627592548322487, max_logit: -1.3883463144302368\n",
      "   [-1.6966848 -2.8223681 -1.3883463 -1.7987026 -1.6615975 -1.9299355]\n",
      "272: action: 2, reward: -0.3216546632455578, max_logit: -1.3984659910202026\n",
      "   [-1.7000272 -2.822691  -1.398466  -1.7907724 -1.6621853 -1.9337767]\n",
      "273: action: 2, reward: -0.316931628197262, max_logit: -1.4009599685668945\n",
      "   [-1.7148085 -2.8340821 -1.40096   -1.8075253 -1.6753689 -1.92541  ]\n",
      "274: action: 2, reward: -0.31210457902320504, max_logit: -1.4027636051177979\n",
      "   [-1.7124641 -2.8336217 -1.4027636 -1.8054992 -1.6682638 -1.9232309]\n",
      "275: action: 2, reward: -0.30717122504837674, max_logit: -1.408994197845459\n",
      "   [-1.7195119 -2.8329282 -1.4089942 -1.8237514 -1.6703229 -1.9129318]\n",
      "276: action: 2, reward: -0.3021292251508495, max_logit: -1.4183549880981445\n",
      "   [-1.7317159 -2.8449767 -1.418355  -1.8403561 -1.6779054 -1.9160717]\n",
      "277: action: 2, reward: -0.29697618665079945, max_logit: -1.4124159812927246\n",
      "   [-1.7180728 -2.8222888 -1.412416  -1.8406235 -1.5973623 -1.8962069]\n",
      "278: action: 2, reward: -0.2917096641750611, max_logit: -1.4556610584259033\n",
      "   [-1.7606937 -2.8534658 -1.455661  -1.8979107 -1.5992001 -1.9395864]\n",
      "279: action: 2, reward: -0.28632715849667584, max_logit: -1.446252465248108\n",
      "   [-1.7424939 -2.8260784 -1.4462525 -1.8904506 -1.5281736 -1.9341307]\n",
      "280: action: 2, reward: -0.2808261153488845, max_logit: -1.4483269453048706\n",
      "   [-1.7587992 -2.8289683 -1.448327  -1.9070147 -1.5113155 -1.9419823]\n",
      "281: action: 2, reward: -0.27520392421300066, max_logit: -1.4382346868515015\n",
      "   [-1.750786  -2.832269  -1.4382347 -1.8945067 -1.5072052 -1.9327915]\n",
      "282: action: 2, reward: -0.2694579170795896, max_logit: -1.4359480142593384\n",
      "   [-1.7516463 -2.8277838 -1.435948  -1.9002357 -1.5081178 -1.9383079]\n",
      "283: action: 2, reward: -0.26358536718236525, max_logit: -1.4318819046020508\n",
      "   [-1.7516878 -2.8289952 -1.4318819 -1.8924837 -1.5273927 -1.9311042]\n",
      "284: action: 2, reward: -0.2575834877042036, max_logit: -1.4295135736465454\n",
      "   [-1.7503546 -2.8249304 -1.4295136 -1.891209  -1.5251224 -1.9346054]\n",
      "285: action: 2, reward: -0.2514494304546596, max_logit: -1.426459789276123\n",
      "   [-1.7522352 -2.8187966 -1.4264598 -1.8871315 -1.5499078 -1.9359925]\n",
      "286: action: 2, reward: -0.24518028451835905, max_logit: -1.428352952003479\n",
      "   [-1.7519538 -2.8164241 -1.428353  -1.8835558 -1.5468472 -1.9329412]\n",
      "287: action: 2, reward: -0.23877307487362417, max_logit: -1.3602033853530884\n",
      "   [-1.6707461 -2.7750478 -1.3602034 -1.8005682 -1.4995784 -1.8564792]\n",
      "288: action: 2, reward: -0.2322247609806781, max_logit: -1.2659029960632324\n",
      "   [-1.5538595 -2.7204294 -1.265903  -1.6607362 -1.4206867 -1.7514918]\n",
      "289: action: 2, reward: -0.22553223533875724, max_logit: -1.2207316160202026\n",
      "   [-1.4795297 -2.6611104 -1.2207316 -1.5682501 -1.3854983 -1.6567554]\n",
      "290: action: 2, reward: -0.21869232201144767, max_logit: -1.1450154781341553\n",
      "   [-1.3716558 -2.610057  -1.1450155 -1.4535064 -1.3243243 -1.5632975]\n",
      "291: action: 2, reward: -0.2117017751195453, max_logit: -1.1238808631896973\n",
      "   [-1.3383518 -2.577462  -1.1238809 -1.4138219 -1.2955995 -1.5256195]\n",
      "292: action: 2, reward: -0.20455727730072457, max_logit: -1.1320621967315674\n",
      "   [-1.3499062 -2.5854661 -1.1320622 -1.4336338 -1.3034434 -1.5330417]\n",
      "293: action: 2, reward: -0.19725543813528507, max_logit: -1.1417067050933838\n",
      "   [-1.3551705 -2.5839252 -1.1417067 -1.4310129 -1.3074803 -1.5417707]\n",
      "294: action: 2, reward: -0.1897927925372286, max_logit: -1.1424587965011597\n",
      "   [-1.3600503 -2.579414  -1.1424588 -1.4365085 -1.3109212 -1.5418326]\n",
      "295: action: 2, reward: -0.18216579910990363, max_logit: -1.1676225662231445\n",
      "   [-1.385582  -2.5955794 -1.1676226 -1.4589683 -1.3350906 -1.5719656]\n",
      "296: action: 2, reward: -0.1743708384654362, max_logit: -1.1637623310089111\n",
      "   [-1.3865749 -2.5894763 -1.1637623 -1.4572518 -1.3307624 -1.5777653]\n",
      "297: action: 2, reward: -0.16640421150715032, max_logit: -1.1819322109222412\n",
      "   [-1.4061785 -2.6057382 -1.1819322 -1.4741145 -1.3460956 -1.5935527]\n",
      "298: action: 2, reward: -0.15826213767416264, max_logit: -1.198274850845337\n",
      "   [-1.4394431 -2.622422  -1.1982749 -1.5166323 -1.3563063 -1.6240458]\n",
      "299: action: 2, reward: -0.14994075314731806, max_logit: -1.2365285158157349\n",
      "   [-1.4804537 -2.6279917 -1.2365285 -1.5801371 -1.3510221 -1.630317 ]\n",
      "300: action: 2, reward: -0.14143610901561543, max_logit: -1.2341492176055908\n",
      "   [-1.4859896 -2.6163652 -1.2341492 -1.5917671 -1.3236363 -1.6616006]\n",
      "301: action: 2, reward: -0.13274416940225264, max_logit: -1.265866756439209\n",
      "   [-1.519633  -2.616586  -1.2658668 -1.639631  -1.2977693 -1.6846375]\n",
      "302: action: 2, reward: -0.1238608095494025, max_logit: -1.2584693431854248\n",
      "   [-1.5152526 -2.6164918 -1.2584693 -1.6374962 -1.2890726 -1.6886339]\n",
      "303: action: 2, reward: -0.11478181386080973, max_logit: -1.2614006996154785\n",
      "   [-1.5165298 -2.6194267 -1.2614007 -1.6376505 -1.2939751 -1.6864984]\n",
      "304: action: 2, reward: -0.10550287390128076, max_logit: -1.25729238986969\n",
      "   [-1.5154428 -2.6208625 -1.2572924 -1.640342  -1.2860317 -1.6912935]\n",
      "305: action: 2, reward: -0.09601958635211699, max_logit: -1.25053870677948\n",
      "   [-1.507622  -2.6204758 -1.2505387 -1.6375    -1.2798239 -1.6670897]\n",
      "306: action: 2, reward: -0.08632745092152093, max_logit: -1.2642264366149902\n",
      "   [-1.5200331 -2.62986   -1.2642264 -1.6482756 -1.2814472 -1.6843976]\n",
      "307: action: 2, reward: -0.07642186820898371, max_logit: -1.2504099607467651\n",
      "   [-1.5016509 -2.6213095 -1.25041   -1.635792  -1.265464  -1.6495283]\n",
      "308: action: 2, reward: -0.0662981375226409, max_logit: -1.2635694742202759\n",
      "   [-1.5165769 -2.6293192 -1.2635695 -1.6455501 -1.2657132 -1.6614826]\n",
      "309: action: 2, reward: -0.055951454648560134, max_logit: -1.1652520895004272\n",
      "   [-1.3801216 -2.5330515 -1.1652521 -1.5151043 -1.170304  -1.5333619]\n",
      "310: action: 2, reward: -0.04537690957090274, max_logit: -1.1399264335632324\n",
      "   [-1.3398433 -2.512471  -1.1399264 -1.4595112 -1.1612895 -1.4830983]\n",
      "311: action: 2, reward: -0.034569484141876695, max_logit: -1.0698142051696777\n",
      "   [-1.2322147 -2.4334567 -1.0698142 -1.3455384 -1.1046059 -1.3754503]\n",
      "312: action: 2, reward: -0.02352404970037593, max_logit: -1.0415457487106323\n",
      "   [-1.199465  -2.4052022 -1.0415457 -1.304192  -1.1019012 -1.3148437]\n",
      "313: action: 2, reward: -0.012235364638175553, max_logit: -1.0469391345977783\n",
      "   [-1.2099202 -2.4255743 -1.0469391 -1.3311508 -1.110846  -1.3321298]\n",
      "314: action: 2, reward: -0.00069807191252779, max_logit: -1.0538713932037354\n",
      "   [-1.2165588 -2.4240973 -1.0538714 -1.3379672 -1.1182761 -1.3405464]\n",
      "315: action: 2, reward: 0.01109330349602125, max_logit: -1.062991976737976\n",
      "   [-1.2328448 -2.4551508 -1.062992  -1.3580068 -1.1340617 -1.3401809]\n",
      "316: action: 2, reward: 0.023144357181800822, max_logit: -1.0704103708267212\n",
      "   [-1.2385817 -2.4515977 -1.0704104 -1.364989  -1.1369972 -1.3555192]\n",
      "317: action: 2, reward: 0.03546080796940335, max_logit: -1.0915018320083618\n",
      "   [-1.2611852 -2.4800906 -1.0915018 -1.3800706 -1.1660094 -1.3665097]\n",
      "318: action: 2, reward: 0.048048500627551394, max_logit: -1.1002154350280762\n",
      "   [-1.257974  -2.4743009 -1.1002154 -1.3728184 -1.1721203 -1.3746345]\n",
      "319: action: 2, reward: 0.06091340864273114, max_logit: -1.1774674654006958\n",
      "   [-1.3449901 -2.5213118 -1.1774675 -1.4732711 -1.226824  -1.4122298]\n",
      "320: action: 2, reward: 0.07406163705390885, max_logit: -1.2391819953918457\n",
      "   [-1.4024612 -2.5661795 -1.239182  -1.5170877 -1.2858143 -1.440505 ]\n",
      "321: action: 2, reward: 0.0874994253496758, max_logit: -1.3322378396987915\n",
      "   [-1.496396  -2.6293862 -1.3322378 -1.6292111 -1.3434683 -1.5009556]\n",
      "322: action: 4, reward: 0.10123315042919603, max_logit: -1.3795422315597534\n",
      "   [-1.5617613 -2.6671221 -1.3843527 -1.7034649 -1.3795422 -1.5305357]\n",
      "323: action: 4, reward: 0.11526932962836221, max_logit: -1.3876391649246216\n",
      "   [-1.5674354 -2.679941  -1.3943241 -1.7070595 -1.3876392 -1.5328045]\n",
      "324: action: 4, reward: 0.1296146238125959, max_logit: -1.4130452871322632\n",
      "   [-1.5768075 -2.7020795 -1.4145643 -1.7086453 -1.4130453 -1.5458684]\n",
      "325: action: 4, reward: 0.14427584053775938, max_logit: -1.3883352279663086\n",
      "   [-1.5492476 -2.6913452 -1.3939004 -1.6750968 -1.3883352 -1.5256438]\n",
      "326: action: 4, reward: 0.15925993728068005, max_logit: -1.3338630199432373\n",
      "   [-1.5080156 -2.68051   -1.3613826 -1.6385213 -1.333863  -1.511623 ]\n",
      "327: action: 4, reward: 0.17457402474081907, max_logit: -1.3289711475372314\n",
      "   [-1.4884429 -2.671368  -1.3473737 -1.6206853 -1.3289711 -1.4902277]\n",
      "328: action: 4, reward: 0.190225370214652, max_logit: -1.2879512310028076\n",
      "   [-1.4719889 -2.6607246 -1.33372   -1.6120064 -1.2879512 -1.5051945]\n",
      "329: action: 4, reward: 0.20622140104436268, max_logit: -1.288212776184082\n",
      "   [-1.4585693 -2.6459172 -1.3179448 -1.5969777 -1.2882128 -1.5035635]\n",
      "330: action: 4, reward: 0.22256970814248678, max_logit: -1.2407519817352295\n",
      "   [-1.3702348 -2.5614502 -1.2515873 -1.4982815 -1.240752  -1.4619284]\n",
      "331: action: 4, reward: 0.23927804959417742, max_logit: -1.182215690612793\n",
      "   [-1.3019542 -2.5241213 -1.1997031 -1.4303381 -1.1822157 -1.4406462]\n",
      "332: action: 2, reward: 0.25635435433880244, max_logit: -1.1560783386230469\n",
      "   [-1.2358973 -2.4621847 -1.1560783 -1.3674998 -1.1747123 -1.4040289]\n",
      "333: action: 2, reward: 0.2738067259326207, max_logit: -1.1546943187713623\n",
      "   [-1.2137055 -2.4491994 -1.1546943 -1.3279011 -1.1701235 -1.3888569]\n",
      "334: action: 2, reward: 0.29164344639432277, max_logit: -1.168801188468933\n",
      "   [-1.2158804 -2.4500198 -1.1688012 -1.3266847 -1.1962807 -1.3882563]\n",
      "335: action: 2, reward: 0.3098729801352611, max_logit: -1.1557101011276245\n",
      "   [-1.1872487 -2.44139   -1.1557101 -1.302612  -1.181463  -1.35449  ]\n",
      "336: action: 2, reward: 0.3285039779762339, max_logit: -1.1567262411117554\n",
      "   [-1.185851  -2.4351401 -1.1567262 -1.2946442 -1.1721157 -1.3543633]\n",
      "337: action: 2, reward: 0.34754528125273054, max_logit: -1.1501736640930176\n",
      "   [-1.1678073 -2.435783  -1.1501737 -1.2797407 -1.1634163 -1.3457595]\n",
      "338: action: 2, reward: 0.3670059260105848, max_logit: -1.1316652297973633\n",
      "   [-1.1393213 -2.4180896 -1.1316652 -1.2580464 -1.1381304 -1.3188491]\n",
      "339: action: 2, reward: 0.38689514729402824, max_logit: -1.1224209070205688\n",
      "   [-1.1340413 -2.4128127 -1.1224209 -1.2411274 -1.1465483 -1.3200579]\n",
      "340: action: 2, reward: 0.4072223835281787, max_logit: -1.107480525970459\n",
      "   [-1.1140919 -2.4146543 -1.1074805 -1.2290801 -1.1313125 -1.3117874]\n",
      "341: action: 2, reward: 0.42799728099804174, max_logit: -1.184573769569397\n",
      "   [-1.2233441 -2.4709551 -1.1845738 -1.3302537 -1.1895589 -1.4144695]\n",
      "342: action: 4, reward: 0.44922969842615346, max_logit: -1.2385598421096802\n",
      "   [-1.3194542 -2.511565  -1.2735537 -1.4213957 -1.2385598 -1.4803787]\n",
      "343: action: 4, reward: 0.47092971165103487, max_logit: -1.2638287544250488\n",
      "   [-1.4184761 -2.5538023 -1.3522029 -1.5434557 -1.2638288 -1.5685527]\n",
      "344: action: 4, reward: 0.49310761840867856, max_logit: -1.3689061403274536\n",
      "   [-1.5603744 -2.62645   -1.4422619 -1.6858637 -1.3689061 -1.680108 ]\n",
      "345: action: 4, reward: 0.5157739432193366, max_logit: -1.2731693983078003\n",
      "   [-1.4957492 -2.589542  -1.3937218 -1.6295264 -1.2731694 -1.6467383]\n",
      "346: action: 4, reward: 0.5389394423819291, max_logit: -1.3052350282669067\n",
      "   [-1.5317583 -2.6260839 -1.4075    -1.6772754 -1.305235  -1.6661484]\n",
      "347: action: 4, reward: 0.5626151090784436, max_logit: -1.317434310913086\n",
      "   [-1.5125892 -2.6060855 -1.4055136 -1.6493514 -1.3174343 -1.6413751]\n",
      "348: action: 4, reward: 0.5868121785907463, max_logit: -1.2954436540603638\n",
      "   [-1.5017726 -2.621482  -1.4072454 -1.6632593 -1.2954437 -1.6518141]\n",
      "349: action: 4, reward: 0.6115421336322832, max_logit: -1.3610419034957886\n",
      "   [-1.5119395 -2.6168365 -1.4331087 -1.6601744 -1.3610419 -1.6512291]\n",
      "350: action: 4, reward: 0.636816709797198, max_logit: -1.3758026361465454\n",
      "   [-1.5253586 -2.6444478 -1.4542266 -1.6778276 -1.3758026 -1.6720302]\n",
      "351: action: 4, reward: 0.662647901129456, max_logit: -0.6656794548034668\n",
      "   [-1.5906395  -2.6352167  -1.6287591  -2.0536704  -0.66567945 -1.6957605 ]\n",
      "352: action: 4, reward: 0.6890479658146148, max_logit: -0.4142184257507324\n",
      "   [-2.0270884  -2.9998264  -2.1966894  -2.7689424  -0.41421843 -2.084195  ]\n",
      "353: action: 4, reward: 0.7160294319969429, max_logit: -0.515831470489502\n",
      "   [-2.86418   -3.614987  -3.1978812 -3.9394662 -0.5158315 -2.9110522]\n",
      "354: action: 4, reward: 0.743605103724648, max_logit: -1.1117123365402222\n",
      "   [-3.9042728 -4.5045657 -4.469588  -5.241684  -1.1117123 -4.12691  ]\n",
      "355: action: 4, reward: 0.7717880670260345, max_logit: -1.0897107124328613\n",
      "   [-3.8940551 -4.5021605 -4.4817467 -5.2436466 -1.0897107 -4.117262 ]\n",
      "356: action: 4, reward: 0.8005916961194751, max_logit: -1.0831820964813232\n",
      "   [-3.915818  -4.5133367 -4.4908223 -5.2681117 -1.0831821 -4.1525507]\n",
      "357: action: 4, reward: -0.0658779798895515, max_logit: -1.2486019134521484\n",
      "   [-4.011504  -4.6253033 -4.5951633 -5.3650613 -1.2486019 -4.2607613]\n",
      "358: action: 4, reward: -0.055522043997349835, max_logit: -1.6616615056991577\n",
      "   [-4.2567406 -4.8382835 -4.862879  -5.5760994 -1.6616615 -4.4742913]\n",
      "359: action: 4, reward: -0.04493804212485148, max_logit: -1.7898733615875244\n",
      "   [-4.334083  -4.8975453 -4.9240227 -5.632184  -1.7898734 -4.56929  ]\n",
      "360: action: 4, reward: -0.03412095163654479, max_logit: -1.9331939220428467\n",
      "   [-4.4199066 -4.9617877 -5.0093126 -5.696599  -1.9331939 -4.6348825]\n",
      "361: action: 4, reward: -0.023065639284772264, max_logit: -2.0004143714904785\n",
      "   [-4.4498816 -4.964069  -5.0179524 -5.718913  -2.0004144 -4.6726956]\n",
      "362: action: 4, reward: -0.011766858773749014, max_logit: -1.6555553674697876\n",
      "   [-4.3203826 -4.850764  -4.8894057 -5.6193056 -1.6555554 -4.626312 ]\n",
      "363: action: 4, reward: -0.00021924826993450025, max_logit: -1.4671494960784912\n",
      "   [-4.240464  -4.7478657 -4.793008  -5.556065  -1.4671495 -4.5468287]\n",
      "364: action: 4, reward: 0.01158267214242431, max_logit: -1.2970269918441772\n",
      "   [-4.2137747 -4.6701174 -4.7531238 -5.5600405 -1.297027  -4.5508256]\n",
      "365: action: 4, reward: 0.023644503061785636, max_logit: -1.3313825130462646\n",
      "   [-4.27413   -4.7139544 -4.789585  -5.613925  -1.3313825 -4.6062884]\n",
      "366: action: 4, reward: 0.0359719684270756, max_logit: -1.514012098312378\n",
      "   [-4.3866997 -4.78873   -4.922814  -5.73547   -1.5140121 -4.724892 ]\n",
      "367: action: 4, reward: 0.04857091823398173, max_logit: -1.8453545570373535\n",
      "   [-4.628548  -4.9899735 -5.1806626 -5.928737  -1.8453546 -4.953314 ]\n",
      "368: action: 4, reward: 0.06144733131106752, max_logit: -2.2698729038238525\n",
      "   [-4.868975  -5.189668  -5.4496484 -6.1626053 -2.269873  -5.1762557]\n",
      "369: action: 4, reward: 0.07460731815702355, max_logit: -2.72778058052063\n",
      "   [-5.1789317 -5.47077   -5.7762184 -6.4222527 -2.7277806 -5.488084 ]\n",
      "370: action: 4, reward: 0.08805712384040348, max_logit: -2.9610719680786133\n",
      "   [-5.32572   -5.5386434 -5.911851  -6.5369773 -2.961072  -5.6123347]\n",
      "371: action: 4, reward: 0.1018031309632196, max_logit: -3.2318172454833984\n",
      "   [-5.518518  -5.6906824 -6.090135  -6.70333   -3.2318172 -5.8177295]\n",
      "372: action: 4, reward: 0.11585186268980537, max_logit: -3.2006523609161377\n",
      "   [-5.504728  -5.636452  -6.0545926 -6.688944  -3.2006524 -5.8084846]\n",
      "373: action: 4, reward: 0.13020998584238105, max_logit: -2.778269052505493\n",
      "   [-5.1999564 -5.359692  -5.7023096 -6.3879423 -2.778269  -5.5412946]\n",
      "374: action: 4, reward: 0.1448843140647929, max_logit: -2.471970558166504\n",
      "   [-4.9327674 -5.14588   -5.4279184 -6.1266766 -2.4719706 -5.318466 ]\n",
      "375: action: 4, reward: 0.159881811055926, max_logit: -2.095879316329956\n",
      "   [-4.6404066 -4.872782  -5.122256  -5.823939  -2.0958793 -5.0825496]\n",
      "376: action: 4, reward: 0.17520959387432605, max_logit: -1.8487553596496582\n",
      "   [-4.4012666 -4.6537967 -4.9022055 -5.5812135 -1.8487554 -4.886633 ]\n",
      "377: action: 4, reward: 0.19087493631559763, max_logit: -1.906759262084961\n",
      "   [-4.435678  -4.6761374 -4.934187  -5.606658  -1.9067593 -4.9102216]\n",
      "378: action: 4, reward: 0.20688527236418205, max_logit: -1.9928970336914062\n",
      "   [-4.4936204 -4.716903  -4.967888  -5.6335382 -1.992897  -4.9627995]\n",
      "379: action: 4, reward: 0.223248199721153, max_logit: -1.9162334203720093\n",
      "   [-4.4277143 -4.665432  -4.905435  -5.561963  -1.9162334 -4.881649 ]\n",
      "380: action: 4, reward: 0.23997148340970398, max_logit: -2.050072431564331\n",
      "   [-4.5302687 -4.733936  -4.965683  -5.6478763 -2.0500724 -4.960064 ]\n",
      "381: action: 4, reward: 0.2570630594600375, max_logit: -1.9025578498840332\n",
      "   [-4.411056  -4.616606  -4.8219233 -5.525192  -1.9025578 -4.796788 ]\n",
      "382: action: 4, reward: 0.2745310386754071, max_logit: -1.8506454229354858\n",
      "   [-4.3793254 -4.590348  -4.793806  -5.508356  -1.8506454 -4.7716064]\n",
      "383: action: 4, reward: 0.2923837104810963, max_logit: -1.6963776350021362\n",
      "   [-4.2768426 -4.4306364 -4.64833   -5.398251  -1.6963776 -4.6129203]\n",
      "384: action: 4, reward: 0.31062954685816385, max_logit: -1.6397337913513184\n",
      "   [-4.2978144 -4.4389844 -4.679747  -5.4562836 -1.6397338 -4.6563416]\n",
      "385: action: 4, reward: 0.3292772063638202, max_logit: -1.4634369611740112\n",
      "   [-4.1319385 -4.287397  -4.4958315 -5.2971783 -1.463437  -4.455333 ]\n",
      "386: action: 4, reward: 0.34833553824034325, max_logit: -1.4438990354537964\n",
      "   [-4.145006  -4.3148713 -4.53474   -5.3266068 -1.443899  -4.4748125]\n",
      "387: action: 4, reward: 0.36781358661448504, max_logit: -1.473147988319397\n",
      "   [-4.1501474 -4.338238  -4.5382195 -5.3300314 -1.473148  -4.4426756]\n",
      "388: action: 4, reward: 0.3877205947893591, max_logit: -1.3806194067001343\n",
      "   [-4.0872355 -4.2877245 -4.4787793 -5.270137  -1.3806194 -4.379239 ]\n",
      "389: action: 4, reward: 0.4080660096308478, max_logit: -1.524160623550415\n",
      "   [-4.1997905 -4.409298  -4.613706  -5.378865  -1.5241606 -4.4562306]\n",
      "390: action: 4, reward: 0.42885948605061086, max_logit: -1.3886816501617432\n",
      "   [-4.1275835 -4.347221  -4.5575676 -5.3284593 -1.3886817 -4.443936 ]\n",
      "391: action: 4, reward: 0.4501108915878204, max_logit: -1.5218281745910645\n",
      "   [-4.2544885 -4.4648676 -4.681442  -5.453039  -1.5218282 -4.567268 ]\n",
      "392: action: 4, reward: 0.47183031109179996, max_logit: -1.5138359069824219\n",
      "   [-4.2661443 -4.4487643 -4.701944  -5.488083  -1.5138359 -4.6058273]\n",
      "393: action: 4, reward: 0.4940280515077871, max_logit: -1.5836974382400513\n",
      "   [-4.3401074 -4.518919  -4.770654  -5.5753155 -1.5836974 -4.7049046]\n",
      "394: action: 4, reward: 0.5167146467680916, max_logit: -1.4627113342285156\n",
      "   [-4.247327  -4.434728  -4.651151  -5.502709  -1.4627113 -4.6343064]\n",
      "395: action: 4, reward: 0.5399008627909708, max_logit: -1.1625621318817139\n",
      "   [-3.9965754 -4.22315   -4.3693366 -5.250232  -1.1625621 -4.412495 ]\n",
      "396: action: 4, reward: 0.5635977025895929, max_logit: -0.9536528587341309\n",
      "   [-3.8319733  -4.076223   -4.199451   -5.1019745  -0.95365286 -4.2737994 ]\n",
      "397: action: 4, reward: 0.5878164114935148, max_logit: -0.6614083051681519\n",
      "   [-3.554914  -3.891234  -3.9080229 -4.8319902 -0.6614083 -3.9968345]\n",
      "398: action: 4, reward: 0.6125684824851502, max_logit: -0.6392948627471924\n",
      "   [-3.5419447  -3.8673182  -3.8975062  -4.8133726  -0.63929486 -3.9943504 ]\n",
      "399: action: 4, reward: 0.6378656616537618, max_logit: -0.651191234588623\n",
      "   [-3.5421565  -3.8926616  -3.8896055  -4.823118   -0.65119123 -3.9731197 ]\n",
      "400: action: 4, reward: 0.6637199537695648, max_logit: -0.627432107925415\n",
      "   [-3.5359008 -3.8876033 -3.8810039 -4.8062935 -0.6274321 -3.97565  ]\n",
      "401: action: 4, reward: 0.6901436279805879, max_logit: -0.633583664894104\n",
      "   [-3.528346   -3.8709283  -3.8565166  -4.7901983  -0.63358366 -3.94943   ]\n",
      "402: action: 4, reward: 0.7171492236349946, max_logit: -0.5961124897003174\n",
      "   [-3.4968667 -3.8721125 -3.8296778 -4.7682314 -0.5961125 -3.9308863]\n",
      "403: action: 4, reward: 0.7447495562316272, max_logit: -0.6315741539001465\n",
      "   [-3.516699   -3.8820024  -3.827587   -4.776747   -0.63157415 -3.9325643 ]\n",
      "404: action: 4, reward: 0.7729577235015997, max_logit: -0.5829950571060181\n",
      "   [-3.4770794  -3.8613377  -3.7877216  -4.734779   -0.58299506 -3.8939753 ]\n",
      "405: action: 4, reward: 0.8017871116238222, max_logit: -0.5290520191192627\n",
      "   [-3.4911487 -3.8570569 -3.789812  -4.768344  -0.529052  -3.8944037]\n",
      "406: action: 4, reward: 0.8312514015774086, max_logit: -0.5035375356674194\n",
      "   [-3.532944   -3.8595085  -3.8333242  -4.823517   -0.50353754 -3.9571967 ]\n",
      "407: action: 4, reward: 0.8613645756339829, max_logit: -0.39303016662597656\n",
      "   [-3.503487   -3.818653   -3.822148   -4.8170195  -0.39303017 -3.922727  ]\n",
      "408: action: 4, reward: 0.8921409239929616, max_logit: -0.4702834486961365\n",
      "   [-3.6301696  -3.9142044  -3.9411538  -4.971128   -0.47028345 -4.0737014 ]\n",
      "409: action: 4, reward: 0.9235950515629653, max_logit: -0.35425901412963867\n",
      "   [-3.5752952 -3.84492   -3.882425  -4.9142146 -0.354259  -4.0116773]\n",
      "410: action: 4, reward: 0.9557418848925741, max_logit: -0.3928004205226898\n",
      "   [-3.6153429  -3.9026272  -3.9401813  -4.98895    -0.39280042 -4.0696893 ]\n",
      "411: action: 4, reward: 0.9885966792537175, max_logit: -0.3397473990917206\n",
      "   [-3.6000128 -3.870906  -3.9102683 -4.9710393 -0.3397474 -4.037877 ]\n",
      "412: action: 4, reward: 1.0221750258810607, max_logit: -0.36127912998199463\n",
      "   [-3.6170251  -3.8990707  -3.9555726  -5.0005445  -0.36127913 -4.0815897 ]\n",
      "413: action: 4, reward: 1.0564928593708198, max_logit: -0.31109365820884705\n",
      "   [-3.5801575  -3.8659966  -3.9176378  -4.9576216  -0.31109366 -4.0273056 ]\n",
      "414: action: 4, reward: 1.0915664652425219, max_logit: -0.5101248025894165\n",
      "   [-3.6514485 -3.9798155 -4.013455  -4.9815903 -0.5101248 -4.0398746]\n",
      "415: action: 4, reward: 1.1274124876672942, max_logit: -0.14880944788455963\n",
      "   [-3.217035   -3.7468894  -3.6237192  -4.5044923  -0.14880945 -3.55653   ]\n",
      "416: action: 4, reward: 1.1640479373663508, max_logit: 0.016647284850478172\n",
      "   [-2.9829643  -3.6287875  -3.4126198  -4.2687736   0.01664728 -3.2321765 ]\n",
      "417: action: 4, reward: 1.2014901996834262, max_logit: 0.11128682643175125\n",
      "   [-2.691717   -3.50412    -3.1551914  -3.9178076   0.11128683 -2.7968338 ]\n",
      "418: action: 4, reward: 1.2397570428349873, max_logit: 0.3218410611152649\n",
      "   [-2.5232935  -3.3961496  -3.003578   -3.7588103   0.32184106 -2.6844258 ]\n",
      "419: action: 4, reward: 1.278866626342134, max_logit: 0.27781543135643005\n",
      "   [-2.534559   -3.401575   -3.002847   -3.7690842   0.27781543 -2.6964297 ]\n",
      "420: action: 4, reward: 1.3188375096481981, max_logit: 0.3047330975532532\n",
      "   [-2.5339794 -3.3728116 -2.993908  -3.7694814  0.3047331 -2.7010102]\n",
      "421: action: 4, reward: 1.35968866092612, max_logit: 0.23815453052520752\n",
      "   [-2.5699532  -3.413861   -3.0303066  -3.8008568   0.23815453 -2.719217  ]\n",
      "422: action: 4, reward: 1.401439466079793, max_logit: 0.17722132802009583\n",
      "   [-2.6071563  -3.4187422  -3.0648026  -3.8420036   0.17722133 -2.7441092 ]\n",
      "423: action: 4, reward: 1.4441097379436374, max_logit: 0.14290714263916016\n",
      "   [-2.640548   -3.4383752  -3.1054673  -3.8653357   0.14290714 -2.7490742 ]\n",
      "424: action: 4, reward: 1.4877197256847767, max_logit: 0.13755306601524353\n",
      "   [-2.62982    -3.4195158  -3.1087592  -3.8623722   0.13755307 -2.7336497 ]\n",
      "425: action: 4, reward: 1.5322901244122757, max_logit: 0.0657588317990303\n",
      "   [-2.692767   -3.4646814  -3.18116    -3.9106407   0.06575883 -2.7800648 ]\n",
      "426: action: 4, reward: 1.5778420849979993, max_logit: 0.05770314484834671\n",
      "   [-2.736673   -3.4920099  -3.2034671  -3.975249    0.05770314 -2.8403652 ]\n",
      "427: action: 4, reward: 1.6243972241137523, max_logit: 0.040442563593387604\n",
      "   [-2.7855806  -3.5269818  -3.2261138  -4.038989    0.04044256 -2.9012556 ]\n",
      "428: action: 4, reward: 1.671977634489467, max_logit: 0.04599059373140335\n",
      "   [-2.8330243  -3.5524175  -3.2508996  -4.107842    0.04599059 -2.9501514 ]\n",
      "429: action: 4, reward: 1.7206058953973027, max_logit: 0.03325016051530838\n",
      "   [-2.842394   -3.5488927  -3.233543   -4.1381836   0.03325016 -2.936357  ]\n",
      "430: action: 4, reward: 1.7703050833666336, max_logit: 0.08077699691057205\n",
      "   [-2.7999148 -3.5314627 -3.2001534 -4.10343    0.080777  -2.9168236]\n",
      "431: action: 4, reward: 1.8210987831350098, max_logit: 0.07787812501192093\n",
      "   [-2.806914   -3.538876   -3.1813388  -4.109842    0.07787813 -2.9100742 ]\n",
      "432: action: 4, reward: 1.87301109884029, max_logit: 0.11673182994127274\n",
      "   [-2.769625   -3.516307   -3.1524084  -4.0702825   0.11673183 -2.889588  ]\n",
      "433: action: 4, reward: 1.9260666654592522, max_logit: 0.08776900917291641\n",
      "   [-2.7938962  -3.5404408  -3.1709454  -4.1147485   0.08776901 -2.8909736 ]\n",
      "434: action: 4, reward: 1.9802906604981183, max_logit: 0.023936575278639793\n",
      "   [-2.8363664  -3.5760212  -3.214812   -4.140773    0.02393658 -2.945552  ]\n",
      "435: action: 4, reward: 2.0357088159405317, max_logit: 0.041052140295505524\n",
      "   [-2.8234875  -3.5652907  -3.2019048  -4.130702    0.04105214 -2.9195173 ]\n",
      "436: action: 4, reward: 2.092347430458664, max_logit: -0.07208321243524551\n",
      "   [-2.9228032  -3.6452146  -3.2750697  -4.230291   -0.07208321 -3.020578  ]\n",
      "437: action: 4, reward: 2.150233381893246, max_logit: -0.009972924366593361\n",
      "   [-2.8343587  -3.5613258  -3.1792     -4.130194   -0.00997292 -2.9036424 ]\n",
      "438: action: 4, reward: 2.209394140008436, max_logit: 0.06100154668092728\n",
      "   [-2.72251    -3.5118122  -3.085425   -4.050667    0.06100155 -2.820968  ]\n",
      "439: action: 4, reward: 2.2698577795275945, max_logit: 0.06933004409074783\n",
      "   [-2.6685603  -3.5228581  -3.0278006  -4.009565    0.06933004 -2.7310889 ]\n",
      "440: action: 4, reward: 2.3316529934561334, max_logit: 0.08340121060609818\n",
      "   [-2.6050851  -3.5310323  -2.9788284  -3.9624615   0.08340121 -2.684439  ]\n",
      "441: action: 4, reward: 2.3948091066977772, max_logit: 0.1327725350856781\n",
      "   [-2.5570834  -3.500413   -2.9261858  -3.9132645   0.13277254 -2.6354465 ]\n",
      "442: action: 4, reward: 2.459356089970688, max_logit: 0.04197315126657486\n",
      "   [-2.5998185  -3.555759   -2.986986   -3.9359832   0.04197315 -2.6789901 ]\n",
      "443: action: 4, reward: 2.5253245740300616, max_logit: 0.09603429585695267\n",
      "   [-2.566653  -3.5209916 -2.946703  -3.9037402  0.0960343 -2.6641717]\n",
      "444: action: 4, reward: 2.592745864203948, max_logit: 0.11670330911874771\n",
      "   [-2.5445073  -3.5140712  -2.9236145  -3.8764243   0.11670331 -2.6415462 ]\n",
      "445: action: 4, reward: 2.6616519552491824, max_logit: 0.1708434820175171\n",
      "   [-2.50122    -3.4785008  -2.886053   -3.8472095   0.17084348 -2.596208  ]\n",
      "446: action: 4, reward: 2.7320755465344946, max_logit: 0.2543984651565552\n",
      "   [-2.459552   -3.4445572  -2.8481457  -3.8042839   0.25439847 -2.5868118 ]\n",
      "447: action: 4, reward: 2.804050057557982, max_logit: 0.1957547664642334\n",
      "   [-2.5359156  -3.4929533  -2.8993092  -3.9009495   0.19575477 -2.634631  ]\n",
      "448: action: 4, reward: 1.9817020041566322, max_logit: -0.23178762197494507\n",
      "   [-2.7907915  -3.6738296  -3.1591716  -4.131266   -0.23178762 -2.7587397 ]\n",
      "449: action: 4, reward: 2.0371512412394073, max_logit: -0.4800962805747986\n",
      "   [-2.9573677  -3.7927346  -3.3171182  -4.321046   -0.48009628 -2.8469698 ]\n",
      "450: action: 4, reward: 2.0938216219004766, max_logit: -0.7900775074958801\n",
      "   [-3.160511  -3.9504657 -3.4847925 -4.510177  -0.7900775 -2.9496534]\n",
      "451: action: 4, reward: 2.1517400390551846, max_logit: -0.8678945302963257\n",
      "   [-3.1505787  -3.9450529  -3.4750278  -4.49872    -0.86789453 -2.90703   ]\n",
      "452: action: 4, reward: 1.3150263382245957, max_logit: -0.6820322275161743\n",
      "   [-3.0533428 -3.8596225 -3.3754048 -4.4106445 -0.6820322 -2.8454251]\n",
      "453: action: 4, reward: 1.3557935571031816, max_logit: -1.1838639974594116\n",
      "   [-3.3100417 -4.0432634 -3.6209805 -4.635162  -1.183864  -3.0601578]\n",
      "454: action: 4, reward: 1.3974585814369478, max_logit: -1.577719807624817\n",
      "   [-3.5165117 -4.214171  -3.8560457 -4.814798  -1.5777198 -3.2475815]\n",
      "455: action: 4, reward: 1.440041183353047, max_logit: -1.9846398830413818\n",
      "   [-3.6475966 -4.3298435 -3.996394  -4.8954806 -1.9846399 -3.262854 ]\n",
      "456: action: 4, reward: 1.4835615704148513, max_logit: -2.183344841003418\n",
      "   [-3.7161806 -4.4541063 -4.06788   -4.9725647 -2.1833448 -3.2744582]\n",
      "457: action: 4, reward: 1.5280403952114443, max_logit: -1.9047523736953735\n",
      "   [-3.464257  -4.395235  -3.8427374 -4.7418475 -1.9047524 -2.9285507]\n",
      "458: action: 4, reward: 1.573498765158304, max_logit: -2.0450758934020996\n",
      "   [-3.592036  -4.550838  -3.917019  -4.8976927 -2.045076  -3.0222607]\n",
      "459: action: 4, reward: 1.6199582525138208, max_logit: -2.0425095558166504\n",
      "   [-3.6310132 -4.6207676 -3.9580815 -4.9367075 -2.0425096 -3.0544653]\n",
      "460: action: 4, reward: 1.6674409046164074, max_logit: -2.107513904571533\n",
      "   [-3.6948793 -4.6242065 -4.0138607 -5.0083966 -2.107514  -3.1287022]\n",
      "461: action: 4, reward: 1.7159692543470584, max_logit: -2.773134469985962\n",
      "   [-4.1713214 -4.910255  -4.442523  -5.4524894 -2.7731345 -3.5812178]\n",
      "462: action: 4, reward: 0.869658691172628, max_logit: -3.5441627502441406\n",
      "   [-4.679501  -5.2253075 -4.901954  -5.9293427 -3.5441628 -3.9621925]\n",
      "463: action: 4, reward: 0.9006176985988997, max_logit: -4.159920692443848\n",
      "   [-5.114411  -5.4845586 -5.2450585 -6.2943354 -4.1599207 -4.2696533]\n",
      "464: action: 5, reward: 0.9322585078875217, max_logit: -4.699296474456787\n",
      "   [-5.685722  -5.9316344 -5.7800326 -6.8113256 -4.9822755 -4.6992965]\n",
      "465: action: 5, reward: 0.9645961341768384, max_logit: -4.8555145263671875\n",
      "   [-5.9174337 -6.117346  -5.940195  -7.039673  -5.2555623 -4.8555145]\n",
      "466: action: 5, reward: 0.9976459232795318, max_logit: -4.734687328338623\n",
      "   [-5.806766  -5.9923763 -5.7930374 -6.9431705 -5.0554023 -4.7346873]\n",
      "467: action: 5, reward: 1.031423558964974, max_logit: -4.552014350891113\n",
      "   [-5.5901065 -5.778604  -5.593461  -6.801605  -4.7916903 -4.5520144]\n",
      "468: action: 5, reward: 1.0659450704019553, max_logit: -4.456882476806641\n",
      "   [-5.4629493 -5.6022954 -5.4340854 -6.7133126 -4.581758  -4.4568825]\n",
      "469: action: 5, reward: 1.1012268397653233, max_logit: -4.251143455505371\n",
      "   [-5.341323  -5.464327  -5.2940774 -6.6100717 -4.5027547 -4.2511435]\n",
      "470: action: 5, reward: 1.1372856100101392, max_logit: -4.274028301239014\n",
      "   [-5.3860507 -5.433825  -5.289656  -6.6532254 -4.5504622 -4.2740283]\n",
      "471: action: 5, reward: 1.1741384928170429, max_logit: -4.2149529457092285\n",
      "   [-5.4002185 -5.399488  -5.2668552 -6.645045  -4.5753546 -4.214953 ]\n",
      "472: action: 5, reward: 1.2118029767125982, max_logit: -4.36529541015625\n",
      "   [-5.5863714 -5.5186443 -5.401662  -6.7959538 -4.8188143 -4.3652954]\n",
      "473: action: 5, reward: 1.2502969353684672, max_logit: -4.3689680099487305\n",
      "   [-5.5775533 -5.485298  -5.3373938 -6.782437  -4.7220216 -4.368968 ]\n",
      "474: action: 5, reward: 1.2896386360833578, max_logit: -4.458134174346924\n",
      "   [-5.66382   -5.552608  -5.382424  -6.8688917 -4.8023267 -4.458134 ]\n",
      "475: action: 5, reward: 0.4339391088020705, max_logit: -4.502298831939697\n",
      "   [-5.6990914 -5.5771074 -5.374608  -6.9086084 -4.760413  -4.502299 ]\n",
      "476: action: 5, reward: 0.4553023814997577, max_logit: -4.867234230041504\n",
      "   [-6.062206  -5.913565  -5.7363367 -7.2402763 -5.286328  -4.867234 ]\n",
      "477: action: 5, reward: 0.4771361317844886, max_logit: -4.993500709533691\n",
      "   [-6.215325  -6.036225  -5.8878045 -7.377095  -5.505242  -4.9935007]\n",
      "478: action: 5, reward: 0.49945072085714487, max_logit: -5.270987510681152\n",
      "   [-6.4535832 -6.210217  -6.1427746 -7.587695  -5.859263  -5.2709875]\n",
      "479: action: 5, reward: 0.522256738100538, max_logit: -5.196873188018799\n",
      "   [-6.3593535 -6.0939207 -6.1215277 -7.5073266 -5.790308  -5.196873 ]\n",
      "480: action: 5, reward: 0.5455650061045982, max_logit: -5.075648307800293\n",
      "   [-6.238795  -5.947082  -6.0043316 -7.397205  -5.6186376 -5.0756483]\n",
      "481: action: 5, reward: 0.5693865858022318, max_logit: -4.9062724113464355\n",
      "   [-6.065702  -5.763186  -5.840932  -7.222067  -5.426773  -4.9062724]\n",
      "482: action: 5, reward: 0.5937327817182843, max_logit: -4.84946346282959\n",
      "   [-6.034305  -5.705145  -5.8135986 -7.187755  -5.3837986 -4.8494635]\n",
      "483: action: 5, reward: 0.6186151473341001, max_logit: -4.599742412567139\n",
      "   [-5.82437   -5.44379   -5.61488   -6.9202857 -5.233479  -4.5997424]\n",
      "484: action: 5, reward: 0.6440454905702238, max_logit: -4.521578311920166\n",
      "   [-5.7681293 -5.3905244 -5.595729  -6.8277054 -5.236727  -4.5215783]\n",
      "485: action: 5, reward: 0.6700358793898467, max_logit: -4.374286651611328\n",
      "   [-5.602766  -5.298394  -5.534107  -6.631636  -5.242332  -4.3742867]\n",
      "486: action: 5, reward: 0.6965986475256549, max_logit: -4.22036600112915\n",
      "   [-5.4500246 -5.151147  -5.464285  -6.469578  -5.1308026 -4.220366 ]\n",
      "487: action: 5, reward: 0.7237464003328001, max_logit: -4.328465938568115\n",
      "   [-5.5720468 -5.3198495 -5.6145377 -6.589829  -5.3127003 -4.328466 ]\n",
      "488: action: 5, reward: 0.7514920207707673, max_logit: -4.357146739959717\n",
      "   [-5.586494  -5.3354216 -5.6389656 -6.6431017 -5.3012347 -4.3571467]\n",
      "489: action: 5, reward: 0.7798486755169797, max_logit: -4.501265048980713\n",
      "   [-5.7535048 -5.502364  -5.820362  -6.7737765 -5.483829  -4.501265 ]\n",
      "490: action: 5, reward: 0.8088298212150431, max_logit: -4.669705390930176\n",
      "   [-5.923695  -5.59235   -6.0164285 -6.9400177 -5.6889906 -4.6697054]\n",
      "491: action: 5, reward: 0.8384492108605923, max_logit: -4.743176460266113\n",
      "   [-6.021397  -5.614507  -6.1588407 -6.983637  -5.7606816 -4.7431765]\n",
      "492: action: 5, reward: 0.8687209003277722, max_logit: -4.855343341827393\n",
      "   [-6.080348  -5.6020193 -6.287841  -7.0626926 -5.8703995 -4.8553433]\n",
      "493: action: 5, reward: 0.8996592550394488, max_logit: -4.837611198425293\n",
      "   [-6.0237846 -5.4602814 -6.2556467 -6.9835286 -5.749866  -4.837611 ]\n",
      "494: action: 5, reward: 0.9312789567843182, max_logit: -4.807974338531494\n",
      "   [-5.9684815 -5.402063  -6.176286  -6.9445343 -5.6841364 -4.8079743]\n",
      "495: action: 5, reward: 0.9635950106841445, max_logit: -4.7494940757751465\n",
      "   [-5.8823752 -5.3045063 -6.0600505 -6.898207  -5.526198  -4.749494 ]\n",
      "496: action: 5, reward: 0.9966227523144381, max_logit: -4.84762716293335\n",
      "   [-5.9607177 -5.4261756 -6.0869513 -6.9725637 -5.607929  -4.847627 ]\n",
      "497: action: 5, reward: 1.0303778549819478, max_logit: -4.555271625518799\n",
      "   [-5.6785245 -5.187599  -5.825083  -6.6922445 -5.252465  -4.5552716]\n",
      "498: action: 5, reward: 1.0648763371624264, max_logit: -4.548618793487549\n",
      "   [-5.6521745 -5.209973  -5.81709   -6.6440434 -5.2191005 -4.548619 ]\n",
      "499: action: 5, reward: 1.1001345701021927, max_logit: -4.297650337219238\n",
      "   [-5.4209166 -5.033874  -5.60124   -6.4245977 -4.930549  -4.2976503]\n",
      "500: action: 5, reward: 1.1361692855871044, max_logit: -4.14890718460083\n",
      "   [-5.2848215 -4.933943  -5.5171356 -6.2717586 -4.7805614 -4.148907 ]\n",
      "501: action: 5, reward: 1.1729975838826208, max_logit: -4.151224613189697\n",
      "   [-5.3078365 -4.9458137 -5.521521  -6.2982817 -4.8453465 -4.1512246]\n",
      "502: action: 5, reward: 1.2106369418487317, max_logit: -4.140849590301514\n",
      "   [-5.299885  -4.9295635 -5.5207806 -6.294757  -4.859721  -4.1408496]\n",
      "503: action: 5, reward: 1.2491052212335954, max_logit: -4.133396625518799\n",
      "   [-5.308309  -4.91362   -5.5217047 -6.3038206 -4.909578  -4.1333966]\n",
      "504: action: 5, reward: 1.2884206771498283, max_logit: -4.329929351806641\n",
      "   [-5.488173  -5.051176  -5.705496  -6.479645  -5.1090474 -4.3299294]\n",
      "505: action: 5, reward: 1.3286019667374627, max_logit: -4.353394031524658\n",
      "   [-5.539397  -5.0399003 -5.7648954 -6.5418997 -5.143586  -4.353394 ]\n",
      "506: action: 5, reward: 1.3696681580176895, max_logit: -4.504112720489502\n",
      "   [-5.674949  -5.152409  -5.9051633 -6.691634  -5.249241  -4.5041127]\n",
      "507: action: 5, reward: 1.4116387389415823, max_logit: -4.595530986785889\n",
      "   [-5.8186045 -5.317476  -6.0469894 -6.820374  -5.374864  -4.595531 ]\n",
      "508: action: 5, reward: 0.5586259869884048, max_logit: -4.403078556060791\n",
      "   [-5.6317086 -5.10656   -5.8495445 -6.6436415 -5.068725  -4.4030786]\n",
      "509: action: 5, reward: 0.5827352051418873, max_logit: -4.326014041900635\n",
      "   [-5.588897  -5.0961714 -5.7944007 -6.578727  -4.9686847 -4.326014 ]\n",
      "510: action: 5, reward: 0.607375374097846, max_logit: -4.11763858795166\n",
      "   [-5.380133  -4.8505716 -5.594599  -6.380481  -4.675633  -4.1176386]\n",
      "511: action: 5, reward: 0.6325581868424603, max_logit: -3.8158698081970215\n",
      "   [-5.096477  -4.6018524 -5.300909  -6.1265574 -4.2908397 -3.8158698]\n",
      "512: action: 5, reward: 0.6582955938733864, max_logit: -3.9963958263397217\n",
      "   [-5.1890726 -4.678714  -5.4260426 -6.2487164 -4.4040747 -3.9963958]\n",
      "513: action: 5, reward: 0.6845998088708647, max_logit: -3.9445343017578125\n",
      "   [-5.0915504 -4.5848556 -5.3058577 -6.192823  -4.195953  -3.9445343]\n",
      "514: action: 5, reward: 0.7114833144937176, max_logit: -4.2249884605407715\n",
      "   [-5.2557864 -4.742735  -5.4919066 -6.376477  -4.346856  -4.2249885]\n",
      "515: action: 5, reward: -0.15694877134670182, max_logit: -4.1664252281188965\n",
      "   [-5.1740327 -4.7051573 -5.3620067 -6.3322453 -4.2153854 -4.166425 ]\n",
      "516: action: 5, reward: -0.1485984629078053, max_logit: -4.130421161651611\n",
      "   [-5.106011  -4.7141695 -5.256632  -6.300498  -4.172744  -4.130421 ]\n",
      "517: action: 4, reward: -0.14006425788054444, max_logit: -4.0042948722839355\n",
      "   [-5.004089  -4.6927686 -5.078702  -6.2286816 -4.004295  -4.022854 ]\n",
      "518: action: 5, reward: -0.13134210636000127, max_logit: -3.79935622215271\n",
      "   [-4.833108  -4.6036196 -4.8757834 -6.1083713 -3.8461144 -3.7993562]\n",
      "519: action: 5, reward: -0.12242786925129542, max_logit: -3.9768171310424805\n",
      "   [-5.0300703 -4.757836  -5.018509  -6.3233833 -4.0240645 -3.9768171]\n",
      "520: action: 5, reward: -0.11331731630537736, max_logit: -4.23374080657959\n",
      "   [-5.2632184 -5.0134745 -5.2329736 -6.600289  -4.2555976 -4.233741 ]\n",
      "521: action: 5, reward: -0.10400612411156474, max_logit: -4.460190296173096\n",
      "   [-5.5027294 -5.225086  -5.433561  -6.8618565 -4.4878864 -4.4601903]\n",
      "522: action: 4, reward: -0.09448987404586903, max_logit: -4.718900203704834\n",
      "   [-5.755645  -5.4725194 -5.66896   -7.1225815 -4.7189    -4.742189 ]\n",
      "523: action: 4, reward: -0.0847640501741385, max_logit: -4.695147514343262\n",
      "   [-5.7092576 -5.438115  -5.5966506 -7.0458317 -4.6951475 -4.7043276]\n",
      "524: action: 5, reward: -0.07482403710902281, max_logit: -4.6169633865356445\n",
      "   [-5.602279  -5.32718   -5.5673575 -6.9392767 -4.618582  -4.6169634]\n",
      "525: action: 5, reward: -0.06466511781974207, max_logit: -4.60021448135376\n",
      "   [-5.576947  -5.299671  -5.5433946 -6.893479  -4.614021  -4.6002145]\n",
      "526: action: 5, reward: -0.054282471393620996, max_logit: -4.47962760925293\n",
      "   [-5.511915  -5.2569265 -5.4998384 -6.8450794 -4.54898   -4.4796276]\n",
      "527: action: 5, reward: -0.043671170748325994, max_logit: -4.6176438331604\n",
      "   [-5.6297073 -5.4037156 -5.629888  -6.9572115 -4.738248  -4.617644 ]\n",
      "528: action: 5, reward: -0.03282618029371935, max_logit: -4.61928653717041\n",
      "   [-5.6338406 -5.4296627 -5.604433  -6.958545  -4.734209  -4.6192865]\n",
      "529: action: 5, reward: -0.021742353542221357, max_logit: -4.779435634613037\n",
      "   [-5.7302012 -5.5301876 -5.7756467 -7.0744476 -4.8961267 -4.7794356]\n",
      "530: action: 5, reward: -0.01041443066654572, max_logit: -4.8617448806762695\n",
      "   [-5.7725286 -5.5878773 -5.7830534 -7.1165257 -4.894997  -4.861745 ]\n",
      "531: action: 5, reward: 0.0011629639963502314, max_logit: -4.959799766540527\n",
      "   [-5.8410025 -5.62295   -5.9057846 -7.199979  -5.0087905 -4.9598   ]\n",
      "532: action: 5, reward: 0.012995324496284866, max_logit: -4.960252285003662\n",
      "   [-5.840261  -5.6365066 -5.8751516 -7.207022  -4.9932885 -4.9602523]\n",
      "533: action: 5, reward: 0.025088265877052637, max_logit: -5.410921096801758\n",
      "   [-6.2193866 -6.0081887 -6.271116  -7.58485   -5.493916  -5.410921 ]\n",
      "534: action: 5, reward: 0.03744752684104141, max_logit: -5.580395698547363\n",
      "   [-6.372319  -6.161361  -6.395705  -7.7327504 -5.688586  -5.5803957]\n",
      "535: action: 5, reward: 0.05007897247253252, max_logit: -5.848700046539307\n",
      "   [-6.6221232 -6.3947186 -6.6489534 -7.95481   -6.037774  -5.8487   ]\n",
      "536: action: 5, reward: 0.06298859702097497, max_logit: -6.0387678146362305\n",
      "   [-6.724991  -6.4651647 -6.7524843 -8.054563  -6.1172943 -6.038768 ]\n",
      "537: action: 5, reward: 0.07618252674555508, max_logit: -6.005270004272461\n",
      "   [-6.686448  -6.46578   -6.7274346 -8.010816  -6.1031766 -6.00527  ]\n",
      "538: action: 5, reward: 0.08966702282241121, max_logit: -6.072724342346191\n",
      "   [-6.7277613 -6.49051   -6.733618  -8.058777  -6.097381  -6.0727243]\n",
      "539: action: 5, reward: 0.10344848431587356, max_logit: -6.013461112976074\n",
      "   [-6.670099  -6.446941  -6.6841455 -7.9954515 -6.0334907 -6.013461 ]\n",
      "540: action: 5, reward: 0.11753345121513836, max_logit: -5.990311145782471\n",
      "   [-6.6130857 -6.394017  -6.6341457 -7.915222  -6.028746  -5.990311 ]\n",
      "541: action: 5, reward: 0.1319286075378184, max_logit: -5.970545291900635\n",
      "   [-6.556875  -6.3770046 -6.6198797 -7.8297195 -6.0432878 -5.9705453]\n",
      "542: action: 5, reward: 0.1466407845018417, max_logit: -5.775800704956055\n",
      "   [-6.3652577 -6.2340336 -6.4895334 -7.6284986 -5.9577065 -5.7758007]\n",
      "543: action: 5, reward: 0.16167696376720456, max_logit: -5.679078102111816\n",
      "   [-6.2196383 -6.1001554 -6.413737  -7.482377  -5.8558164 -5.679078 ]\n",
      "544: action: 5, reward: 0.1770442807491164, max_logit: -5.7438178062438965\n",
      "   [-6.287197  -6.1530566 -6.432134  -7.547751  -5.9269905 -5.743818 ]\n",
      "545: action: 5, reward: 0.19275002800410954, max_logit: -5.7299394607543945\n",
      "   [-6.261494  -6.12291   -6.4285703 -7.5216775 -5.8938785 -5.7299395]\n",
      "546: action: 5, reward: 0.20880165869071973, max_logit: -5.762807369232178\n",
      "   [-6.3012877 -6.153578  -6.449804  -7.5647593 -5.9381404 -5.7628074]\n",
      "547: action: 5, reward: 0.22520679010638123, max_logit: -5.83200740814209\n",
      "   [-6.380867  -6.224063  -6.5282574 -7.5970907 -6.053926  -5.8320074]\n",
      "548: action: 5, reward: 0.24197320730221303, max_logit: -5.859936237335205\n",
      "   [-6.4042926 -6.260183  -6.575895  -7.60497   -6.1235886 -5.859936 ]\n",
      "549: action: 5, reward: 0.25910886677741335, max_logit: -5.860154628753662\n",
      "   [-6.4009843 -6.2715254 -6.602624  -7.61014   -6.1936345 -5.8601546]\n",
      "550: action: 5, reward: 0.27662190025501393, max_logit: -5.821990489959717\n",
      "   [-6.34406   -6.2043147 -6.5795565 -7.5293508 -6.1636386 -5.8219905]\n",
      "551: action: 5, reward: 0.29452061854078765, max_logit: -5.855222225189209\n",
      "   [-6.388815  -6.252354  -6.6187334 -7.566012  -6.2202754 -5.855222 ]\n",
      "552: action: 5, reward: 0.3128135154671392, max_logit: -5.767271041870117\n",
      "   [-6.299644  -6.1621404 -6.5569296 -7.4786353 -6.139555  -5.767271 ]\n",
      "553: action: 5, reward: 0.3315092719238511, max_logit: -5.841757774353027\n",
      "   [-6.3626456 -6.2347083 -6.622552  -7.5412364 -6.213588  -5.841758 ]\n",
      "554: action: 5, reward: 0.350616759977598, max_logit: -5.48906946182251\n",
      "   [-6.1112704 -6.0026073 -6.3583503 -7.2539587 -5.9907193 -5.4890695]\n",
      "555: action: 5, reward: 0.37014504708218354, max_logit: -5.409621238708496\n",
      "   [-6.0186696 -6.0160365 -6.3077917 -7.1486297 -5.9694905 -5.4096212]\n",
      "556: action: 5, reward: 0.3901034003814986, max_logit: -5.20419454574585\n",
      "   [-5.84232   -5.895337  -6.1238804 -6.9603987 -5.8046565 -5.2041945]\n",
      "557: action: 5, reward: 0.41050129110724204, max_logit: -5.057580471038818\n",
      "   [-5.714128  -5.8409724 -6.028853  -6.8085423 -5.7355185 -5.0575805]\n",
      "558: action: 5, reward: 0.43134839907349143, max_logit: -5.087212562561035\n",
      "   [-5.720245  -5.8472314 -6.022743  -6.8142004 -5.724598  -5.0872126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559: action: 5, reward: 0.4526546172702564, max_logit: -5.120464324951172\n",
      "   [-5.7163043 -5.8490934 -6.046736  -6.820213  -5.7296753 -5.1204643]\n",
      "560: action: 5, reward: 0.4744300565581946, max_logit: -5.115886688232422\n",
      "   [-5.7185583 -5.8459635 -6.027354  -6.820499  -5.720725  -5.1158867]\n",
      "561: action: 5, reward: 0.4966850504667184, max_logit: -5.254837989807129\n",
      "   [-5.8500257 -5.947565  -6.1393743 -6.95493   -5.882332  -5.254838 ]\n",
      "562: action: 5, reward: 0.5194301600977687, max_logit: -5.298998832702637\n",
      "   [-5.927488  -5.997564  -6.212462  -7.0416145 -6.0006194 -5.298999 ]\n",
      "563: action: 5, reward: 0.542676179137583, max_logit: -5.34075403213501\n",
      "   [-5.9813666 -6.0769463 -6.268131  -7.115984  -6.071569  -5.340754 ]\n",
      "564: action: 5, reward: 0.5664341389788369, max_logit: -5.397181987762451\n",
      "   [-6.093375  -6.2297416 -6.3430767 -7.2120705 -6.1969857 -5.397182 ]\n",
      "565: action: 5, reward: 0.5907153139555884, max_logit: -5.2730278968811035\n",
      "   [-5.9919515 -6.1368055 -6.251398  -7.1161385 -6.0788164 -5.273028 ]\n",
      "566: action: 5, reward: 0.6155312266935111, max_logit: -5.323387145996094\n",
      "   [-6.025054  -6.1746397 -6.2519703 -7.146524  -6.0601735 -5.323387 ]\n",
      "567: action: 5, reward: 0.6408936535779528, max_logit: -5.264330863952637\n",
      "   [-5.9569955 -6.108861  -6.19948   -7.083636  -5.9912295 -5.264331 ]\n",
      "568: action: 5, reward: 0.6668146303424161, max_logit: -5.200794696807861\n",
      "   [-5.972091  -6.1101108 -6.1812615 -7.091286  -6.0793796 -5.2007947]\n",
      "569: action: 5, reward: 0.6933064577801138, max_logit: -5.1828932762146\n",
      "   [-5.9870534 -6.1313834 -6.1814346 -7.1344433 -6.1634    -5.1828933]\n",
      "570: action: 5, reward: 0.7203817075813063, max_logit: -5.139367580413818\n",
      "   [-5.9921703 -6.1686063 -6.1881847 -7.1253195 -6.243445  -5.1393676]\n",
      "571: action: 5, reward: 0.7480532282991945, max_logit: -5.247558116912842\n",
      "   [-6.117301  -6.3273845 -6.2965527 -7.269118  -6.428278  -5.247558 ]\n",
      "572: action: 5, reward: 0.7763341514471981, max_logit: -5.319899559020996\n",
      "   [-6.183775  -6.380268  -6.3335185 -7.326427  -6.505623  -5.3198996]\n",
      "573: action: 5, reward: 0.8052378977305109, max_logit: -5.361323833465576\n",
      "   [-6.228585 -6.432235 -6.373744 -7.383914 -6.552816 -5.361324]\n",
      "574: action: 5, reward: 0.8347781834148945, max_logit: -5.418270587921143\n",
      "   [-6.273338  -6.46592   -6.4185505 -7.4213276 -6.610775  -5.4182706]\n",
      "575: action: 5, reward: 0.8649690268357281, max_logit: -5.844303607940674\n",
      "   [-6.776649  -6.7824674 -7.047744  -8.006825  -7.160779  -5.8443036]\n",
      "576: action: 5, reward: 0.8958247550504065, max_logit: -6.5685038566589355\n",
      "   [-7.4440126 -7.279633  -7.8037987 -8.677651  -7.9081707 -6.568504 ]\n",
      "577: action: 5, reward: 0.9273600106372414, max_logit: -7.222113132476807\n",
      "   [-8.068641 -7.77188  -8.560319 -9.390143 -8.637898 -7.222113]\n",
      "578: action: 5, reward: 0.9595897586440932, max_logit: -8.045336723327637\n",
      "   [-8.651919 -8.235035 -9.325342 -9.999908 -9.294484 -8.045337]\n",
      "579: action: 5, reward: 0.9925292936900317, max_logit: -8.060785293579102\n",
      "   [ -8.675653  -8.262734  -9.34673  -10.017802  -9.320146  -8.060785]\n",
      "580: action: 5, reward: 0.13028660757369803, max_logit: -8.146442413330078\n",
      "   [ -8.705996  -8.305573  -9.347978 -10.062109  -9.33374   -8.146442]\n",
      "581: action: 5, reward: 0.1449626232158126, max_logit: -8.1992826461792\n",
      "   [ -8.771265  -8.380072  -9.371427 -10.101354  -9.386301  -8.199283]\n",
      "582: action: 5, reward: 0.15996184478823705, max_logit: -8.201979637145996\n",
      "   [ -8.803617  -8.407473  -9.343502 -10.125921  -9.387534  -8.20198 ]\n",
      "583: action: 5, reward: 0.17529139016791653, max_logit: -7.912360668182373\n",
      "   [-8.58305   -8.189954  -9.08718   -9.915821  -9.090312  -7.9123607]\n",
      "584: action: 5, reward: 0.19095853398687881, max_logit: -7.673402309417725\n",
      "   [-8.456063  -7.9888377 -8.966131  -9.754093  -8.912549  -7.6734023]\n",
      "585: action: 5, reward: 0.20697071108440848, max_logit: -7.2264862060546875\n",
      "   [-8.145004 -7.619435 -8.670359 -9.409906 -8.591141 -7.226486]\n",
      "586: action: 5, reward: 0.22333552003524867, max_logit: -7.050535202026367\n",
      "   [-8.025416 -7.430709 -8.598392 -9.277821 -8.433082 -7.050535]\n",
      "587: action: 5, reward: 0.2400607267555026, max_logit: -7.049463748931885\n",
      "   [-8.028119  -7.4146323 -8.6224    -9.266668  -8.495556  -7.0494637]\n",
      "588: action: 5, reward: 0.25715426818794707, max_logit: -7.024231910705566\n",
      "   [-7.9911575 -7.3844614 -8.589975  -9.226889  -8.442038  -7.024232 ]\n",
      "589: action: 5, reward: 0.27462425606850716, max_logit: -7.0645976066589355\n",
      "   [-8.036237  -7.4804277 -8.602686  -9.281277  -8.47457   -7.0645976]\n",
      "590: action: 5, reward: 0.292478980775678, max_logit: -7.020845890045166\n",
      "   [-8.027706 -7.488198 -8.578332 -9.298983 -8.405392 -7.020846]\n",
      "591: action: 5, reward: 0.31072691526472246, max_logit: -7.040292739868164\n",
      "   [-8.040322  -7.4915056 -8.499954  -9.287345  -8.312422  -7.0402927]\n",
      "592: action: 5, reward: 0.32937671908850924, max_logit: -6.85486364364624\n",
      "   [-7.978496  -7.409207  -8.379417  -9.224687  -8.136707  -6.8548636]\n",
      "593: action: 5, reward: 0.34843724250690206, max_logit: -6.783553600311279\n",
      "   [-7.9217496 -7.2862005 -8.30999   -9.150164  -8.039274  -6.7835536]\n",
      "594: action: 5, reward: 0.3679175306866485, max_logit: -6.771939277648926\n",
      "   [-7.9219713 -7.2874036 -8.2974415 -9.142133  -8.020786  -6.7719393]\n",
      "595: action: 5, reward: 0.3878268279937612, max_logit: -6.862417221069336\n",
      "   [-7.973432  -7.3195724 -8.3464365 -9.189414  -8.064072  -6.862417 ]\n",
      "596: action: 5, reward: 0.4081745823804301, max_logit: -6.910451412200928\n",
      "   [-8.00995   -7.367332  -8.353925  -9.224472  -8.080205  -6.9104514]\n",
      "597: action: 5, reward: 0.42897044986854505, max_logit: -6.786577224731445\n",
      "   [-7.8881836 -7.187593  -8.266614  -9.130297  -7.9021564 -6.786577 ]\n",
      "598: action: 5, reward: 0.4502242991319594, max_logit: -6.577590465545654\n",
      "   [-7.7608047 -6.9573774 -8.080112  -9.000249  -7.6668544 -6.5775905]\n",
      "599: action: 5, reward: 0.47194621617966614, max_logit: -6.475343704223633\n",
      "   [-7.681297  -6.786604  -8.018889  -8.9469595 -7.5257783 -6.4753437]\n",
      "600: action: 5, reward: 0.4941465091421118, max_logit: -6.281852722167969\n",
      "   [-7.5656776 -6.573914  -7.8748145 -8.824551  -7.3224444 -6.2818527]\n",
      "601: action: 5, reward: 0.5168357131629162, max_logit: -6.249989986419678\n",
      "   [-7.5234656 -6.54032   -7.8674874 -8.788039  -7.3060966 -6.24999  ]\n",
      "602: action: 5, reward: 0.5400245953983234, max_logit: -6.266932487487793\n",
      "   [-7.5271773 -6.557071  -7.8355093 -8.790159  -7.2469907 -6.2669325]\n",
      "603: action: 5, reward: 0.5637241601267524, max_logit: -6.2311835289001465\n",
      "   [-7.4874377 -6.5080514 -7.8082843 -8.742789  -7.2250385 -6.2311835]\n",
      "604: action: 5, reward: 0.5879456539708746, max_logit: -6.326943874359131\n",
      "   [-7.56326   -6.5632863 -7.882774  -8.849442  -7.2734385 -6.326944 ]\n",
      "605: action: 5, reward: 0.6127005712346965, max_logit: -6.287818431854248\n",
      "   [-7.5314393 -6.4852977 -7.855067  -8.826914  -7.204036  -6.2878184]\n",
      "606: action: 5, reward: 0.6380006593581784, max_logit: -6.436793804168701\n",
      "   [-7.6904206 -6.568572  -8.022001  -8.988147  -7.341303  -6.436794 ]\n",
      "607: action: 5, reward: 0.6638579244919797, max_logit: -6.392837047576904\n",
      "   [-7.6600227 -6.48537   -7.966425  -8.985376  -7.222818  -6.392837 ]\n",
      "608: action: 5, reward: 0.6902846371949736, max_logit: -6.3949174880981445\n",
      "   [-7.6785603 -6.4903445 -7.963453  -9.008361  -7.246784  -6.3949175]\n",
      "609: action: 5, reward: 0.7172933382572395, max_logit: -6.4430999755859375\n",
      "   [-7.6774507 -6.5075645 -7.9952636 -9.040183  -7.2390075 -6.4431   ]\n",
      "610: action: 5, reward: 0.7448968446512902, max_logit: -6.4656877517700195\n",
      "   [-7.7058043 -6.5117135 -8.009628  -9.062683  -7.26108   -6.4656878]\n",
      "611: action: 1, reward: 0.7731082556143646, max_logit: -6.352959156036377\n",
      "   [-7.594401  -6.352959  -7.9570656 -8.9746065 -7.0884304 -6.427067 ]\n",
      "612: action: 1, reward: 0.8019409588646663, max_logit: -6.339000225067139\n",
      "   [-7.664181 -6.339    -8.030043 -9.047005 -7.079024 -6.524894]\n",
      "613: action: 1, reward: 0.8314086369545028, max_logit: -6.255651950836182\n",
      "   [-7.608155  -6.255652  -7.9884872 -8.974398  -6.9870706 -6.516273 ]\n",
      "614: action: 1, reward: 0.8615252737633371, max_logit: -6.333559989929199\n",
      "   [-7.720309  -6.33356   -8.0759535 -9.090747  -7.0138803 -6.707286 ]\n",
      "615: action: 1, reward: 0.8923051611338338, max_logit: -6.348565578460693\n",
      "   [-7.7308803 -6.3485656 -8.084884  -9.072344  -7.0432734 -6.6942267]\n",
      "616: action: 1, reward: 0.02785526600435608, max_logit: -6.387033462524414\n",
      "   [-7.7399173 -6.3870335 -8.075483  -9.103139  -7.0240126 -6.794846 ]\n",
      "617: action: 1, reward: 0.04027546386512405, max_logit: -6.488802909851074\n",
      "   [-7.828696  -6.488803  -8.154451  -9.180114  -7.120803  -6.9253297]\n",
      "618: action: 1, reward: 0.05296918839022059, max_logit: -6.59465217590332\n",
      "   [-7.929954  -6.594652  -8.219445  -9.284903  -7.2027607 -7.082718 ]\n",
      "619: action: 1, reward: 0.06594246338352845, max_logit: -6.719571113586426\n",
      "   [-8.024321  -6.719571  -8.304764  -9.396548  -7.318704  -7.2297945]\n",
      "620: action: 1, reward: 0.07920144530953711, max_logit: -6.944616794586182\n",
      "   [-8.232462  -6.944617  -8.494918  -9.603041  -7.5184646 -7.48175  ]\n",
      "621: action: 1, reward: 0.09275242621489135, max_logit: -6.940182685852051\n",
      "   [-8.205489  -6.9401827 -8.495994  -9.575008  -7.5366945 -7.441682 ]\n",
      "622: action: 1, reward: 0.1066018367142805, max_logit: -6.861374378204346\n",
      "   [-8.143125  -6.8613744 -8.478156  -9.5123415 -7.479198  -7.346948 ]\n",
      "623: action: 1, reward: 0.12075624904208501, max_logit: -6.772894859313965\n",
      "   [-8.066756  -6.772895  -8.475724  -9.429351  -7.4680233 -7.269659 ]\n",
      "624: action: 1, reward: 0.13522238017122887, max_logit: -6.778444290161133\n",
      "   [-8.057206  -6.7784443 -8.517498  -9.415238  -7.485127  -7.308015 ]\n",
      "625: action: 1, reward: 0.15000709500071727, max_logit: -6.787442684173584\n",
      "   [-8.026306  -6.7874427 -8.4582405 -9.374957  -7.4611635 -7.3510504]\n",
      "626: action: 1, reward: -0.7307902300363222, max_logit: -6.838314533233643\n",
      "   [-8.065392  -6.8383145 -8.43533   -9.408473  -7.4365997 -7.390674 ]\n",
      "627: action: 1, reward: -0.7350774771185512, max_logit: -6.960127830505371\n",
      "   [-8.102897  -6.960128  -8.40444   -9.458674  -7.4108524 -7.567186 ]\n",
      "628: action: 1, reward: -0.7394591410858172, max_logit: -7.071892261505127\n",
      "   [-8.215957  -7.0718923 -8.385991  -9.534215  -7.444837  -7.7149568]\n",
      "629: action: 1, reward: -0.7439373012556889, max_logit: -7.107476234436035\n",
      "   [-8.219863  -7.107476  -8.354386  -9.577954  -7.3818097 -7.756102 ]\n",
      "630: action: 1, reward: -0.7485140827379845, max_logit: -7.186517715454102\n",
      "   [-8.300008  -7.1865177 -8.395775  -9.659842  -7.4614244 -7.859378 ]\n",
      "631: action: 1, reward: -0.753191657443242, max_logit: -7.212128162384033\n",
      "   [-8.296702  -7.212128  -8.42301   -9.670089  -7.4820023 -7.866355 ]\n",
      "632: action: 1, reward: -0.7579722451133991, max_logit: -7.242519855499268\n",
      "   [-8.338896 -7.24252  -8.445214 -9.691753 -7.566438 -7.828278]\n",
      "633: action: 1, reward: -0.7628581143751708, max_logit: -7.246347904205322\n",
      "   [-8.303263  -7.246348  -8.403385  -9.624156  -7.5987725 -7.7107673]\n",
      "634: action: 1, reward: -0.7678515838166255, max_logit: -7.300176620483398\n",
      "   [-8.322631  -7.3001766 -8.452762  -9.627508  -7.708521  -7.7697825]\n",
      "635: action: 1, reward: -0.7729550230874711, max_logit: -7.3679022789001465\n",
      "   [-8.364772  -7.3679023 -8.496126  -9.60732   -7.8291736 -7.784279 ]\n",
      "636: action: 1, reward: -0.7781708540235706, max_logit: -7.367547035217285\n",
      "   [-8.35065   -7.367547  -8.501794  -9.595025  -7.8232007 -7.817276 ]\n",
      "637: action: 1, reward: -0.7835015517962253, max_logit: -7.68879508972168\n",
      "   [-8.618487 -7.688795 -8.764118 -9.864549 -8.113993 -8.280865]\n",
      "638: action: 1, reward: -0.7889496460867649, max_logit: -7.783146858215332\n",
      "   [-8.689146 -7.783147 -8.839418 -9.93166  -8.184341 -8.40507 ]\n",
      "639: action: 1, reward: -0.7945177222870087, max_logit: -7.854041576385498\n",
      "   [-8.723674  -7.8540416 -8.854264  -9.952161  -8.227118  -8.545049 ]\n",
      "640: action: 1, reward: -0.800208422726162, max_logit: -7.899249076843262\n",
      "   [-8.78181  -7.899249 -8.842671 -9.98838  -8.257731 -8.625445]\n",
      "641: action: 1, reward: -0.8060244479247324, max_logit: -7.77750301361084\n",
      "   [-8.636184  -7.777503  -8.680057  -9.8102455 -8.132507  -8.452646 ]\n",
      "642: action: 1, reward: -0.8119685578760619, max_logit: -7.708279132843018\n",
      "   [-8.607305 -7.708279 -8.604936 -9.750032 -8.087014 -8.371888]\n",
      "643: action: 1, reward: -0.8180435733560808, max_logit: -7.661088466644287\n",
      "   [-8.544574  -7.6610885 -8.540513  -9.6901245 -8.025473  -8.306424 ]\n",
      "644: action: 1, reward: -0.8242523772619058, max_logit: -7.629214763641357\n",
      "   [-8.525369  -7.629215  -8.51084   -9.667808  -8.020979  -8.2890005]\n",
      "645: action: 1, reward: -0.8305979159799188, max_logit: -7.572248935699463\n",
      "   [-8.474837  -7.572249  -8.451377  -9.61694   -7.9743934 -8.21553  ]\n",
      "646: action: 1, reward: -0.8370832007839737, max_logit: -7.573761940002441\n",
      "   [-8.462119  -7.573762  -8.4330435 -9.599989  -7.9598145 -8.22394  ]\n",
      "647: action: 1, reward: -0.8437113092643951, max_logit: -7.580953121185303\n",
      "   [-8.46896   -7.580953  -8.410983  -9.599514  -8.0133705 -8.185354 ]\n",
      "648: action: 1, reward: -0.8504853867884484, max_logit: -7.634920120239258\n",
      "   [-8.495876  -7.63492   -8.388937  -9.613395  -7.9990172 -8.231588 ]\n",
      "649: action: 1, reward: -0.8574086479929739, max_logit: -7.66538143157959\n",
      "   [-8.5337    -7.6653814 -8.398489  -9.642835  -8.07743   -8.204923 ]\n",
      "650: action: 1, reward: -0.8644843783098898, max_logit: -7.669026851654053\n",
      "   [-8.543595 -7.669027 -8.370893 -9.646424 -8.088013 -8.237358]\n",
      "651: action: 1, reward: -0.8717159355252958, max_logit: -7.71690559387207\n",
      "   [-8.589588  -7.7169056 -8.430299  -9.702181  -8.147013  -8.253469 ]\n",
      "652: action: 1, reward: -0.8791067513729075, max_logit: -7.768393516540527\n",
      "   [-8.661388  -7.7683935 -8.512207  -9.766818  -8.254503  -8.32963  ]\n",
      "653: action: 1, reward: -0.886660333162586, max_logit: -7.796152114868164\n",
      "   [-8.689414 -7.796152 -8.568846 -9.798912 -8.283788 -8.371402]\n",
      "654: action: 1, reward: -0.8943802654447306, max_logit: -7.605432987213135\n",
      "   [-8.517091  -7.605433  -8.419951  -9.638286  -8.102058  -8.1575775]\n",
      "655: action: 1, reward: -0.902270211711326, max_logit: -7.468524932861328\n",
      "   [-8.426078  -7.468525  -8.313655  -9.549735  -7.9530187 -8.069419 ]\n",
      "656: action: 1, reward: -0.9103339161344522, max_logit: -7.3517985343933105\n",
      "   [-8.358944  -7.3517985 -8.219718  -9.477795  -7.860083  -7.981158 ]\n",
      "657: action: 1, reward: -0.9185752053430797, max_logit: -7.125277996063232\n",
      "   [-8.221678  -7.125278  -8.021028  -9.324848  -7.6605444 -7.7668056]\n",
      "658: action: 1, reward: -0.9269979902389962, max_logit: -7.1600775718688965\n",
      "   [-8.264138  -7.1600776 -8.039034  -9.358617  -7.7003164 -7.8028507]\n",
      "659: action: 1, reward: -0.9356062678527229, max_logit: -7.162517547607422\n",
      "   [-8.277725  -7.1625175 -8.047264  -9.373378  -7.7076774 -7.813459 ]\n",
      "660: action: 1, reward: -0.9444041232403059, max_logit: -7.213939189910889\n",
      "   [-8.311612  -7.213939  -8.071111  -9.401727  -7.7365017 -7.8597198]\n",
      "661: action: 1, reward: -0.9533957314218771, max_logit: -7.329689025878906\n",
      "   [-8.396096  -7.329689  -8.161776  -9.535054  -7.814832  -7.9453278]\n",
      "662: action: 1, reward: -0.9625853593629098, max_logit: -7.301425457000732\n",
      "   [-8.331385  -7.3014255 -8.112277  -9.474542  -7.7492537 -7.9231596]\n",
      "663: action: 1, reward: -0.9719773679991062, max_logit: -7.417001247406006\n",
      "   [-8.445955  -7.4170012 -8.222361  -9.614621  -7.856592  -8.043771 ]\n",
      "664: action: 1, reward: -0.9815762143058777, max_logit: -7.362655162811279\n",
      "   [-8.365634  -7.362655  -8.151612  -9.558773  -7.7698483 -7.9538016]\n",
      "665: action: 1, reward: -0.9913864534134024, max_logit: -7.358872890472412\n",
      "   [-8.351363  -7.358873  -8.146836  -9.545762  -7.7740464 -7.9448223]\n",
      "666: action: 1, reward: -1.0014127407682596, max_logit: -7.24816370010376\n",
      "   [-8.258254  -7.2481637 -8.048302  -9.454966  -7.663793  -7.7876806]\n",
      "667: action: 1, reward: -1.0116598343426733, max_logit: -7.224883079528809\n",
      "   [-8.228726  -7.224883  -8.0342245 -9.412147  -7.6651726 -7.766432 ]\n",
      "668: action: 1, reward: -1.0221325968924035, max_logit: -7.003912448883057\n",
      "   [-8.030687  -7.0039124 -7.847224  -9.247315  -7.3537865 -7.5942106]\n",
      "669: action: 1, reward: -1.032835998264369, max_logit: -6.884757041931152\n",
      "   [-7.953811 -6.884757 -7.775833 -9.201391 -7.191098 -7.517766]\n",
      "670: action: 1, reward: -1.0437751177550842, max_logit: -6.8000264167785645\n",
      "   [-7.847979  -6.8000264 -7.649008  -9.122927  -7.001597  -7.4451447]\n",
      "671: action: 1, reward: -1.0549551465210407, max_logit: -6.898635387420654\n",
      "   [-7.9307985 -6.8986354 -7.7519307 -9.267247  -7.0411    -7.592871 ]\n",
      "672: action: 1, reward: -1.0663813900421668, max_logit: -6.840462684631348\n",
      "   [-7.9012966 -6.8404627 -7.6827893 -9.234049  -7.0151896 -7.534569 ]\n",
      "673: action: 1, reward: -1.0780592706395438, max_logit: -6.920222282409668\n",
      "   [-7.9412675 -6.9202223 -7.765873  -9.319444  -7.060771  -7.6669173]\n",
      "674: action: 1, reward: -1.0899943300485657, max_logit: -6.913833141326904\n",
      "   [-7.9419413 -6.913833  -7.731172  -9.309415  -7.044504  -7.645002 ]\n",
      "675: action: 1, reward: -1.1021922320487694, max_logit: -7.1184492111206055\n",
      "   [-8.078059  -7.118449  -7.9165406 -9.481603  -7.210253  -7.858951 ]\n",
      "676: action: 4, reward: -1.114658765151579, max_logit: -7.2488579750061035\n",
      "   [-8.155264  -7.264555  -7.983345  -9.575691  -7.248858  -7.9922314]\n",
      "677: action: 4, reward: -1.1273998453472434, max_logit: -7.481568813323975\n",
      "   [-8.329772  -7.4947686 -8.213513  -9.753481  -7.481569  -8.221785 ]\n",
      "678: action: 4, reward: -1.1404215189122668, max_logit: -7.580967903137207\n",
      "   [-8.4204855 -7.66004   -8.317684  -9.856286  -7.580968  -8.388417 ]\n",
      "679: action: 4, reward: -1.1537299652786697, max_logit: -7.597403526306152\n",
      "   [-8.3838825 -7.6124125 -8.355465  -9.795215  -7.5974035 -8.3596525]\n",
      "680: action: 1, reward: -1.1673314999664346, max_logit: -7.579038143157959\n",
      "   [-8.403337  -7.579038  -8.457892  -9.788818  -7.6906395 -8.391647 ]\n",
      "681: action: 1, reward: -1.1812325775805361, max_logit: -7.517911434173584\n",
      "   [-8.3573675 -7.5179114 -8.44741   -9.723492  -7.6825867 -8.321183 ]\n",
      "682: action: 1, reward: -1.1954397948739717, max_logit: -7.523944854736328\n",
      "   [-8.36899   -7.523945  -8.517259  -9.737659  -7.7449474 -8.39547  ]\n",
      "683: action: 1, reward: -1.2099598938782483, max_logit: -7.506822109222412\n",
      "   [-8.366461  -7.506822  -8.53332   -9.738675  -7.7458253 -8.411441 ]\n",
      "684: action: 1, reward: -1.2247997651028135, max_logit: -7.502987384796143\n",
      "   [-8.380929  -7.5029874 -8.523991  -9.752991  -7.7711706 -8.452384 ]\n",
      "685: action: 1, reward: -1.2399664508049437, max_logit: -7.435238361358643\n",
      "   [-8.3120575 -7.4352384 -8.472994  -9.691965  -7.665133  -8.402426 ]\n",
      "686: action: 1, reward: -1.2554671483316464, max_logit: -7.422398090362549\n",
      "   [-8.31627  -7.422398 -8.464973 -9.691799 -7.67783  -8.394164]\n",
      "687: action: 1, reward: -1.2713092135351582, max_logit: -7.336686134338379\n",
      "   [-8.239254  -7.336686  -8.390707  -9.623678  -7.5697346 -8.3048   ]\n",
      "688: action: 1, reward: -1.2875001642636652, max_logit: -7.391063690185547\n",
      "   [-8.285525  -7.3910637 -8.451056  -9.668407  -7.616833  -8.377384 ]\n",
      "689: action: 1, reward: -1.304047683928893, max_logit: -7.520922660827637\n",
      "   [-8.408705  -7.5209227 -8.565075  -9.804546  -7.722296  -8.553634 ]\n",
      "690: action: 1, reward: -1.3209596251522697, max_logit: -7.591453552246094\n",
      "   [-8.451795  -7.5914536 -8.612724  -9.82405   -7.79849   -8.667928 ]\n",
      "691: action: 1, reward: -1.3382440134913858, max_logit: -7.736381530761719\n",
      "   [-8.583627  -7.7363815 -8.717936  -9.957225  -7.922806  -8.859661 ]\n",
      "692: action: 1, reward: -1.3559090512485188, max_logit: -7.774540901184082\n",
      "   [-8.577958  -7.774541  -8.7507305 -9.939258  -7.9777474 -8.909454 ]\n",
      "693: action: 1, reward: -1.3739631213630352, max_logit: -7.807443141937256\n",
      "   [-8.608512 -7.807443 -8.764559 -9.972274 -8.000185 -8.933942]\n",
      "694: action: 1, reward: -1.3924147913895129, max_logit: -7.7677130699157715\n",
      "   [-8.572365 -7.767713 -8.732358 -9.940461 -7.964598 -8.866645]\n",
      "695: action: 1, reward: -1.41127281756347, max_logit: -7.817200183868408\n",
      "   [-8.61016  -7.8172   -8.776552 -9.976556 -8.031134 -8.900649]\n",
      "696: action: 1, reward: -1.4305461489566358, max_logit: -7.706496715545654\n",
      "   [-8.505676  -7.7064967 -8.648674  -9.865324  -7.860203  -8.847469 ]\n",
      "697: action: 1, reward: -1.4502439317237303, max_logit: -7.700765609741211\n",
      "   [-8.532357  -7.7007656 -8.660814  -9.887198  -7.850704  -8.918569 ]\n",
      "698: action: 1, reward: -1.4703755134427705, max_logit: -7.5933051109313965\n",
      "   [-8.42193  -7.593305 -8.510932 -9.767896 -7.698416 -8.846803]\n",
      "699: action: 1, reward: -1.4909504475509587, max_logit: -7.552493572235107\n",
      "   [-8.403476  -7.5524936 -8.492     -9.745698  -7.669843  -8.858543 ]\n",
      "700: action: 1, reward: -1.5119784978782669, max_logit: -7.531291961669922\n",
      "   [-8.370664  -7.531292  -8.454895  -9.721378  -7.6410127 -8.839922 ]\n",
      "701: action: 1, reward: -1.5334696432808583, max_logit: -7.484092712402344\n",
      "   [-8.339914  -7.4840927 -8.44012   -9.685369  -7.616581  -8.79397  ]\n",
      "702: action: 1, reward: -1.5554340823765511, max_logit: -7.504898548126221\n",
      "   [-8.342407  -7.5048985 -8.427084  -9.683803  -7.6105485 -8.800464 ]\n",
      "703: action: 1, reward: -1.5778822383845696, max_logit: -7.5628790855407715\n",
      "   [-8.386796  -7.562879  -8.489607  -9.7295885 -7.6933646 -8.876988 ]\n",
      "704: action: 1, reward: -1.6008247640718831, max_logit: -7.646154403686523\n",
      "   [-8.469819  -7.6461544 -8.513018  -9.788553  -7.7292356 -9.014794 ]\n",
      "705: action: 1, reward: -1.62427254680847, max_logit: -7.668522357940674\n",
      "   [-8.489659  -7.6685224 -8.545445  -9.799592  -7.784837  -9.051026 ]\n",
      "706: action: 1, reward: -1.6482367137339191, max_logit: -7.698092460632324\n",
      "   [-8.515626  -7.6980925 -8.543936  -9.830494  -7.7851124 -9.136194 ]\n",
      "707: action: 1, reward: -1.6727286370378098, max_logit: -7.629632949829102\n",
      "   [-8.446246  -7.629633  -8.460153  -9.75728   -7.7308226 -9.03715  ]\n",
      "708: action: 1, reward: -1.6977599393563836, max_logit: -7.668909549713135\n",
      "   [-8.495351  -7.6689095 -8.526059  -9.824669  -7.7850814 -9.1016865]\n",
      "709: action: 1, reward: -1.7233424992880604, max_logit: -7.647485256195068\n",
      "   [-8.458806  -7.6474853 -8.469804  -9.780578  -7.768544  -9.031966 ]\n",
      "710: action: 1, reward: -1.7494884570304277, max_logit: -7.650905609130859\n",
      "   [-8.481747  -7.6509056 -8.510147  -9.80078   -7.794111  -9.052952 ]\n",
      "711: action: 1, reward: -1.776210220141366, max_logit: -7.538602828979492\n",
      "   [-8.323964  -7.538603  -8.357691  -9.650214  -7.6417103 -8.864935 ]\n",
      "712: action: 1, reward: -1.8035204694270544, max_logit: -7.390023708343506\n",
      "   [-8.257015  -7.3900237 -8.228654  -9.562705  -7.514895  -8.736644 ]\n",
      "713: action: 1, reward: -1.8314321649596403, max_logit: -7.295248985290527\n",
      "   [-8.165658  -7.295249  -8.160483  -9.480092  -7.4063263 -8.642895 ]\n",
      "714: action: 1, reward: -1.8599585522274449, max_logit: -7.150606632232666\n",
      "   [-8.100855  -7.1506066 -8.028887  -9.387653  -7.3102493 -8.494525 ]\n",
      "715: action: 1, reward: -1.8891131684205993, max_logit: -7.144094944000244\n",
      "   [-8.092675 -7.144095 -8.057233 -9.408372 -7.285428 -8.515977]\n",
      "716: action: 1, reward: -1.9189098488551202, max_logit: -7.187038898468018\n",
      "   [-8.141853 -7.187039 -8.096037 -9.451658 -7.329042 -8.593492]\n",
      "717: action: 1, reward: -1.9493627335384527, max_logit: -7.179605484008789\n",
      "   [-8.139935  -7.1796055 -8.10464   -9.457312  -7.29269   -8.606097 ]\n",
      "718: action: 1, reward: -1.980486273879609, max_logit: -7.238739967346191\n",
      "   [-8.189967  -7.23874   -8.139685  -9.509206  -7.3588233 -8.658073 ]\n",
      "719: action: 1, reward: -2.0122952395470803, max_logit: -7.306549072265625\n",
      "   [-8.222387 -7.306549 -8.200903 -9.521033 -7.44122  -8.714915]\n",
      "720: action: 1, reward: -2.0448047254777793, max_logit: -7.3777875900268555\n",
      "   [-8.272201  -7.3777876 -8.280239  -9.5828085 -7.512389  -8.776066 ]\n",
      "721: action: 1, reward: -2.078030159040339, max_logit: -7.491042137145996\n",
      "   [-8.362274 -7.491042 -8.376383 -9.663739 -7.670179 -8.887463]\n",
      "722: action: 1, reward: -2.1119873073561677, max_logit: -7.460057258605957\n",
      "   [-8.320843  -7.4600573 -8.328249  -9.630122  -7.6183944 -8.817523 ]\n",
      "723: action: 1, reward: -2.14669228478173, max_logit: -7.490258693695068\n",
      "   [-8.344302  -7.4902587 -8.35206   -9.651298  -7.6805124 -8.833653 ]\n",
      "724: action: 1, reward: -2.182161560555614, max_logit: -7.472668647766113\n",
      "   [-8.326042  -7.4726686 -8.323214  -9.62539   -7.637674  -8.80562  ]\n",
      "725: action: 1, reward: -2.2184119666140028, max_logit: -7.269836902618408\n",
      "   [-8.195019  -7.269837  -8.165326  -9.538112  -7.3945775 -8.656845 ]\n",
      "726: action: 1, reward: -2.255460705578265, max_logit: -7.284371376037598\n",
      "   [-8.352862  -7.2843714 -8.278128  -9.733912  -7.4369197 -8.80704  ]\n",
      "727: action: 1, reward: -2.293325358918455, max_logit: -7.283054351806641\n",
      "   [-8.41692   -7.2830544 -8.328255  -9.785979  -7.477561  -8.909144 ]\n",
      "728: action: 1, reward: -2.332023895296597, max_logit: -7.3522868156433105\n",
      "   [-8.574406  -7.352287  -8.413846  -9.975903  -7.5037947 -9.135587 ]\n",
      "729: action: 1, reward: -2.371574679093707, max_logit: -7.3260416984558105\n",
      "   [-8.532971  -7.3260417 -8.3900175 -9.950971  -7.4587255 -9.096418 ]\n",
      "730: action: 1, reward: -2.4119964791246065, max_logit: -7.327737808227539\n",
      "   [-8.5308485 -7.327738  -8.366568  -9.944495  -7.452326  -9.0805855]\n",
      "731: action: 1, reward: -2.453308477544658, max_logit: -7.256911754608154\n",
      "   [-8.458825  -7.2569118 -8.315738  -9.886291  -7.3460155 -9.007284 ]\n",
      "732: action: 4, reward: -2.495530278952654, max_logit: -7.210092067718506\n",
      "   [ -8.603738   -7.22117    -8.3501215 -10.104047   -7.210092   -8.929939 ]\n",
      "733: action: 4, reward: -2.538681919694172, max_logit: -6.80514669418335\n",
      "   [ -8.504309   -6.965761   -8.216773  -10.123931   -6.8051467  -8.58589  ]\n",
      "734: action: 4, reward: -2.58278387736982, max_logit: -6.7099223136901855\n",
      "   [ -8.610024   -6.8873296  -8.32479   -10.340331   -6.7099223  -8.526087 ]\n",
      "735: action: 4, reward: -2.6278570805528756, max_logit: -6.610420227050781\n",
      "   [ -8.693889   -6.7638097  -8.379422  -10.470454   -6.61042    -8.418558 ]\n",
      "736: action: 4, reward: -2.6739229187209346, max_logit: -6.693350791931152\n",
      "   [ -8.744726   -6.80571    -8.438007  -10.5143385  -6.693351   -8.458232 ]\n",
      "737: action: 4, reward: -2.7210032524062844, max_logit: -6.704562664031982\n",
      "   [ -8.765148   -6.825644   -8.442338  -10.504066   -6.7045627  -8.408112 ]\n",
      "738: action: 4, reward: -2.769120423569812, max_logit: -6.768346786499023\n",
      "   [ -8.803025  -6.871713  -8.478117 -10.521976  -6.768347  -8.41177 ]\n",
      "739: action: 4, reward: -2.818297266203378, max_logit: -6.7050371170043945\n",
      "   [ -8.780593  -6.824627  -8.409081 -10.478673  -6.705037  -8.303846]\n",
      "740: action: 4, reward: -2.8685571171656807, max_logit: -6.576806545257568\n",
      "   [ -8.686594   -6.6919837  -8.330071  -10.373288   -6.5768065  -8.221725 ]\n",
      "741: action: 4, reward: -2.9199238272567576, max_logit: -6.408774375915527\n",
      "   [ -8.5572     -6.5426908  -8.184557  -10.246526   -6.4087744  -8.096077 ]\n",
      "742: action: 4, reward: -2.9724217725363755, max_logit: -6.266148090362549\n",
      "   [ -8.431388   -6.368503   -8.088676  -10.114884   -6.266148   -7.9859304]\n",
      "743: action: 4, reward: -3.026075865891686, max_logit: -6.248922824859619\n",
      "   [ -8.413266   -6.3393865  -8.08034   -10.106497   -6.248923   -7.9874477]\n",
      "744: action: 4, reward: -3.0809115688596256, max_logit: -6.31880521774292\n",
      "   [ -8.452728   -6.4011674  -8.152208  -10.15042    -6.318805   -8.04711  ]\n",
      "745: action: 4, reward: -3.136954903709688, max_logit: -6.297718048095703\n",
      "   [ -8.421338  -6.369426  -8.119148 -10.110667  -6.297718  -8.030634]\n",
      "746: action: 4, reward: -3.194232465792782, max_logit: -6.3419647216796875\n",
      "   [ -8.494159   -6.42834    -8.217387  -10.166457   -6.3419647  -8.160617 ]\n",
      "747: action: 4, reward: -3.2527714361620466, max_logit: -6.309811592102051\n",
      "   [ -8.448071   -6.3906903  -8.163497  -10.108232   -6.3098116  -8.159631 ]\n",
      "748: action: 4, reward: -3.3125995944716182, max_logit: -6.299517631530762\n",
      "   [ -8.4682     -6.443977   -8.201794  -10.142477   -6.2995176  -8.220385 ]\n",
      "749: action: 4, reward: -3.3737453321594573, max_logit: -6.17322301864624\n",
      "   [ -8.374121  -6.377483  -8.120059 -10.039228  -6.173223  -8.143584]\n",
      "750: action: 4, reward: -3.4362376659204954, max_logit: -6.114130973815918\n",
      "   [-8.327489 -6.336788 -8.072243 -9.997121 -6.114131 -8.073951]\n",
      "751: action: 4, reward: -3.5001062514765025, max_logit: -6.082958698272705\n",
      "   [-8.311454  -6.3092465 -8.087481  -9.9889965 -6.0829587 -8.037198 ]\n",
      "752: action: 4, reward: -3.5653813976492064, max_logit: -5.9539103507995605\n",
      "   [-8.20916   -6.173447  -7.9810705 -9.876726  -5.9539104 -7.9136987]\n",
      "753: action: 4, reward: -3.632094080743328, max_logit: -5.630182266235352\n",
      "   [-7.98258   -5.8869076 -7.805134  -9.676206  -5.6301823 -7.684252 ]\n",
      "754: action: 4, reward: -3.700275959246388, max_logit: -5.453523635864258\n",
      "   [-7.8536334 -5.6974206 -7.6949525 -9.564672  -5.4535236 -7.558968 ]\n",
      "755: action: 4, reward: -3.7699593888522305, max_logit: -5.227517127990723\n",
      "   [-7.692074  -5.4758897 -7.562348  -9.411421  -5.227517  -7.4091287]\n",
      "756: action: 4, reward: -3.8411774378154058, max_logit: -5.0180134773254395\n",
      "   [-7.522629  -5.3084416 -7.4277573 -9.267471  -5.0180135 -7.2459836]\n",
      "757: action: 4, reward: -3.9139639026437125, max_logit: -5.1286187171936035\n",
      "   [-7.592276  -5.419239  -7.5136595 -9.328303  -5.1286187 -7.3332   ]\n",
      "758: action: 4, reward: -0.536116496234197, max_logit: -5.1060872077941895\n",
      "   [-7.566814  -5.4367647 -7.479806  -9.303778  -5.106087  -7.3193903]\n",
      "759: action: 4, reward: -0.536116496234197, max_logit: -5.082870960235596\n",
      "   [-7.531152  -5.4460382 -7.449653  -9.269027  -5.082871  -7.278707 ]\n",
      "760: action: 4, reward: -0.536116496234197, max_logit: -5.164961338043213\n",
      "   [-7.5996394 -5.5316896 -7.507498  -9.332173  -5.1649613 -7.381334 ]\n",
      "761: action: 4, reward: -0.536116496234197, max_logit: -5.183692455291748\n",
      "   [-7.6027756 -5.5365677 -7.4914074 -9.323579  -5.1836925 -7.379228 ]\n",
      "762: action: 4, reward: -0.536116496234197, max_logit: -5.244241714477539\n",
      "   [-7.649811  -5.5795217 -7.55812   -9.376177  -5.2442417 -7.4655647]\n",
      "763: action: 4, reward: -0.536116496234197, max_logit: -5.252891540527344\n",
      "   [-7.649159  -5.5737853 -7.540495  -9.377219  -5.2528915 -7.4483356]\n",
      "764: action: 4, reward: -0.536116496234197, max_logit: -5.205198287963867\n",
      "   [-7.6200123 -5.5392756 -7.5449905 -9.356202  -5.2051983 -7.431543 ]\n",
      "765: action: 4, reward: -0.536116496234197, max_logit: -5.158511161804199\n",
      "   [-7.584431  -5.4994245 -7.5061436 -9.328376  -5.158511  -7.382057 ]\n",
      "766: action: 4, reward: -0.536116496234197, max_logit: -5.16376256942749\n",
      "   [-7.5871983 -5.515134  -7.5223646 -9.322695  -5.1637626 -7.385434 ]\n",
      "767: action: 4, reward: -0.536116496234197, max_logit: -5.112948417663574\n",
      "   [-7.5547643 -5.4768095 -7.5092955 -9.297856  -5.1129484 -7.3614182]\n",
      "768: action: 4, reward: -0.536116496234197, max_logit: -5.1595258712768555\n",
      "   [-7.5928106 -5.527547  -7.5434666 -9.329775  -5.159526  -7.405648 ]\n",
      "769: action: 4, reward: -0.536116496234197, max_logit: -5.154918670654297\n",
      "   [-7.6053667 -5.5289674 -7.5588856 -9.335502  -5.1549187 -7.4462485]\n",
      "770: action: 4, reward: -0.536116496234197, max_logit: -5.135867595672607\n",
      "   [-7.5902395 -5.519871  -7.5546927 -9.32852   -5.1358676 -7.437368 ]\n",
      "771: action: 4, reward: -0.536116496234197, max_logit: -5.128759384155273\n",
      "   [-7.596932  -5.5228114 -7.5488257 -9.332246  -5.1287594 -7.451732 ]\n",
      "772: action: 4, reward: -0.536116496234197, max_logit: -5.079864025115967\n",
      "   [-7.562825  -5.484717  -7.519104  -9.29773   -5.079864  -7.4251184]\n",
      "773: action: 4, reward: -0.536116496234197, max_logit: -5.057655334472656\n",
      "   [-7.5490565 -5.4697757 -7.5026665 -9.280575  -5.0576553 -7.412319 ]\n",
      "774: action: 4, reward: -0.536116496234197, max_logit: -5.0544023513793945\n",
      "   [-7.550421  -5.4712744 -7.501639  -9.277742  -5.0544024 -7.4169865]\n",
      "775: action: 4, reward: -0.536116496234197, max_logit: -5.0258989334106445\n",
      "   [-7.533954  -5.4479227 -7.4854693 -9.258465  -5.025899  -7.4010296]\n",
      "776: action: 4, reward: -0.536116496234197, max_logit: -5.039904594421387\n",
      "   [-7.547398  -5.4632254 -7.4966288 -9.270265  -5.0399046 -7.416799 ]\n",
      "777: action: 4, reward: -0.536116496234197, max_logit: -5.0277180671691895\n",
      "   [-7.5441294 -5.455564  -7.4907794 -9.26201   -5.027718  -7.414514 ]\n",
      "778: action: 4, reward: -0.536116496234197, max_logit: -5.013173580169678\n",
      "   [-7.535853  -5.4413147 -7.481613  -9.249498  -5.0131736 -7.405127 ]\n",
      "779: action: 4, reward: -0.536116496234197, max_logit: -5.03597354888916\n",
      "   [-7.557548  -5.46339   -7.5011487 -9.265771  -5.0359735 -7.4256597]\n",
      "780: action: 4, reward: -0.536116496234197, max_logit: -5.006333351135254\n",
      "   [-7.540131  -5.4385076 -7.483448  -9.244613  -5.0063334 -7.405927 ]\n",
      "781: action: 4, reward: -0.536116496234197, max_logit: -5.002514362335205\n",
      "   [-7.539148  -5.43492   -7.4768004 -9.242414  -5.0025144 -7.398562 ]\n",
      "782: action: 4, reward: -0.536116496234197, max_logit: -5.016933441162109\n",
      "   [-7.553308  -5.44825   -7.486902  -9.2499075 -5.0169334 -7.4081907]\n",
      "783: action: 4, reward: -0.536116496234197, max_logit: -4.995053768157959\n",
      "   [-7.5375443 -5.4290648 -7.4719043 -9.232988  -4.995054  -7.38473  ]\n",
      "784: action: 4, reward: -0.536116496234197, max_logit: -5.024331092834473\n",
      "   [-7.5594296 -5.454079  -7.486272  -9.251208  -5.024331  -7.399487 ]\n",
      "785: action: 4, reward: -0.536116496234197, max_logit: -5.014641284942627\n",
      "   [-7.5560775 -5.451047  -7.4818835 -9.245166  -5.0146413 -7.388034 ]\n",
      "786: action: 4, reward: -0.536116496234197, max_logit: -5.009093761444092\n",
      "   [-7.5504875 -5.4421077 -7.4763355 -9.237455  -5.0090938 -7.375012 ]\n",
      "787: action: 4, reward: -0.536116496234197, max_logit: -5.040532112121582\n",
      "   [-7.574853 -5.46821  -7.494429 -9.257874 -5.040532 -7.392804]\n",
      "788: action: 4, reward: -0.536116496234197, max_logit: -5.012811660766602\n",
      "   [-7.5581007 -5.4441495 -7.474103  -9.2397995 -5.0128117 -7.3637466]\n",
      "789: action: 4, reward: -0.536116496234197, max_logit: -5.013495445251465\n",
      "   [-7.5590463 -5.443854  -7.4715967 -9.241372  -5.0134954 -7.354825 ]\n",
      "790: action: 4, reward: -0.536116496234197, max_logit: -5.030533790588379\n",
      "   [-7.575491  -5.459177  -7.4820743 -9.255204  -5.030534  -7.3622518]\n",
      "791: action: 4, reward: -0.536116496234197, max_logit: -4.999029636383057\n",
      "   [-7.5542626 -5.429258  -7.457999  -9.233191  -4.9990296 -7.3323364]\n",
      "792: action: 4, reward: -0.536116496234197, max_logit: -5.024158000946045\n",
      "   [-7.5745726 -5.4501896 -7.468926  -9.253616  -5.024158  -7.3383093]\n",
      "793: action: 4, reward: -0.536116496234197, max_logit: -5.020648956298828\n",
      "   [-7.573601  -5.4484935 -7.4694533 -9.253128  -5.020649  -7.3352838]\n",
      "794: action: 4, reward: -0.536116496234197, max_logit: -5.002589702606201\n",
      "   [-7.560653  -5.4297147 -7.45425   -9.241329  -5.0025897 -7.3145995]\n",
      "795: action: 4, reward: -0.536116496234197, max_logit: -5.028900623321533\n",
      "   [-7.580523  -5.450441  -7.4704976 -9.258369  -5.0289006 -7.32848  ]\n",
      "796: action: 4, reward: -0.536116496234197, max_logit: -5.014188289642334\n",
      "   [-7.5705876 -5.431111  -7.463073  -9.246519  -5.0141883 -7.3187823]\n",
      "797: action: 4, reward: -0.536116496234197, max_logit: -5.024324417114258\n",
      "   [-7.574978  -5.4312773 -7.464115  -9.251501  -5.0243244 -7.3161693]\n",
      "798: action: 4, reward: -0.536116496234197, max_logit: -5.044126033782959\n",
      "   [-7.5941358 -5.4472604 -7.4825835 -9.265253  -5.044126  -7.3360076]\n",
      "799: action: 4, reward: -0.536116496234197, max_logit: -5.025168418884277\n",
      "   [-7.580352  -5.425611  -7.46507   -9.249429  -5.0251684 -7.317187 ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "counter = 0\n",
    "for this_reward in discounted_rewards:\n",
    "    #print(\"{}: action: {}-{}, {}, {}\".format(counter, np.argmax(all_logits[counter]), actions[counter], this_reward, all_logits[counter]))\n",
    "    #frame: action-action, reward, logits\n",
    "    \n",
    "    print(\"{}: action: {}, reward: {}, max_logit: {}\".format(counter, np.argmax(all_logits[counter]), this_reward, all_logits[counter][np.argmax(all_logits[counter])]  ))\n",
    "    print(\"   {}\".format(all_logits[counter]))\n",
    "          \n",
    "    counter += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2  1\n",
      "1: 2  2\n",
      "2: 2  2\n",
      "3: 1  1\n",
      "4: 1  1\n",
      "5: 1  1\n",
      "6: 1  1\n",
      "7: 1  1\n",
      "8: 1  1\n",
      "9: 1  1\n",
      "10: 1  1\n",
      "11: 1  1\n",
      "12: 1  1\n",
      "13: 1  1\n",
      "14: 1  1\n",
      "15: 1  1\n",
      "16: 1  1\n",
      "17: 1  1\n",
      "18: 1  1\n",
      "19: 1  1\n",
      "20: 1  1\n",
      "21: 1  1\n",
      "22: 1  1\n",
      "23: 1  1\n",
      "24: 1  1\n",
      "25: 1  1\n",
      "26: 1  1\n",
      "27: 1  1\n",
      "28: 1  1\n",
      "29: 1  1\n",
      "30: 1  1\n",
      "31: 1  1\n",
      "32: 1  1\n",
      "33: 1  1\n",
      "34: 1  1\n",
      "35: 1  1\n",
      "36: 1  1\n",
      "37: 1  1\n",
      "38: 1  1\n",
      "39: 1  1\n",
      "40: 1  1\n",
      "41: 1  1\n",
      "42: 1  1\n",
      "43: 1  1\n",
      "44: 1  1\n",
      "45: 1  1\n",
      "46: 1  1\n",
      "47: 1  1\n",
      "48: 1  1\n",
      "49: 1  1\n",
      "50: 1  1\n",
      "51: 1  1\n",
      "52: 1  1\n",
      "53: 1  1\n",
      "54: 1  1\n",
      "55: 1  1\n",
      "56: 1  1\n",
      "57: 1  1\n",
      "58: 1  1\n",
      "59: 1  1\n",
      "60: 1  1\n",
      "61: 1  1\n",
      "62: 1  1\n",
      "63: 1  1\n",
      "64: 1  1\n",
      "65: 1  1\n",
      "66: 1  1\n",
      "67: 1  1\n",
      "68: 1  1\n",
      "69: 1  1\n",
      "70: 1  1\n",
      "71: 1  1\n",
      "72: 1  1\n",
      "73: 1  1\n",
      "74: 1  1\n",
      "75: 1  1\n",
      "76: 1  1\n",
      "77: 1  1\n",
      "78: 1  1\n",
      "79: 1  1\n",
      "80: 1  1\n",
      "81: 1  1\n",
      "82: 1  1\n",
      "83: 1  1\n",
      "84: 1  1\n",
      "85: 1  1\n",
      "86: 1  1\n",
      "87: 1  1\n",
      "88: 1  1\n",
      "89: 1  1\n",
      "90: 1  1\n",
      "91: 1  1\n",
      "92: 1  1\n",
      "93: 1  1\n",
      "94: 1  1\n",
      "95: 1  1\n",
      "96: 1  1\n",
      "97: 1  1\n",
      "98: 1  1\n",
      "99: 1  1\n",
      "100: 1  1\n",
      "101: 1  1\n",
      "102: 1  1\n",
      "103: 1  1\n",
      "104: 1  1\n",
      "105: 1  1\n",
      "106: 1  1\n",
      "107: 1  1\n",
      "108: 1  1\n",
      "109: 1  1\n",
      "110: 1  1\n",
      "111: 1  1\n",
      "112: 1  1\n",
      "113: 1  1\n",
      "114: 1  1\n",
      "115: 1  1\n",
      "116: 1  1\n",
      "117: 1  1\n",
      "118: 1  1\n",
      "119: 1  1\n",
      "120: 1  1\n",
      "121: 1  1\n",
      "122: 1  1\n",
      "123: 1  1\n",
      "124: 1  1\n",
      "125: 1  1\n",
      "126: 1  1\n",
      "127: 1  1\n",
      "128: 2  2\n",
      "129: 1  1\n",
      "130: 1  1\n",
      "131: 1  1\n",
      "132: 1  1\n",
      "133: 1  1\n",
      "134: 1  1\n",
      "135: 1  1\n",
      "136: 1  1\n",
      "137: 1  1\n",
      "138: 1  1\n",
      "139: 2  2\n",
      "140: 1  1\n",
      "141: 1  1\n",
      "142: 1  1\n",
      "143: 2  2\n",
      "144: 2  2\n",
      "145: 2  2\n",
      "146: 2  2\n",
      "147: 2  2\n",
      "148: 2  2\n",
      "149: 1  1\n",
      "150: 1  1\n",
      "151: 1  1\n",
      "152: 1  1\n",
      "153: 1  1\n",
      "154: 1  1\n",
      "155: 1  1\n",
      "156: 1  1\n",
      "157: 1  1\n",
      "158: 1  1\n",
      "159: 1  1\n",
      "160: 1  1\n",
      "161: 1  1\n",
      "162: 1  1\n",
      "163: 1  1\n",
      "164: 1  1\n",
      "165: 1  1\n",
      "166: 2  2\n",
      "167: 2  2\n",
      "168: 2  2\n",
      "169: 2  2\n",
      "170: 2  2\n",
      "171: 2  2\n",
      "172: 2  2\n",
      "173: 2  2\n",
      "174: 2  2\n",
      "175: 2  2\n",
      "176: 2  2\n",
      "177: 2  2\n",
      "178: 2  2\n",
      "179: 2  2\n",
      "180: 2  2\n",
      "181: 2  2\n",
      "182: 2  2\n",
      "183: 2  2\n",
      "184: 2  2\n",
      "185: 2  2\n",
      "186: 2  2\n",
      "187: 2  2\n",
      "188: 2  2\n",
      "189: 2  2\n",
      "190: 2  2\n",
      "191: 2  2\n",
      "192: 2  2\n",
      "193: 2  2\n",
      "194: 2  2\n",
      "195: 2  2\n",
      "196: 2  2\n",
      "197: 2  2\n",
      "198: 2  2\n",
      "199: 2  2\n",
      "200: 2  2\n",
      "201: 2  2\n",
      "202: 2  2\n",
      "203: 2  2\n",
      "204: 2  2\n",
      "205: 2  2\n",
      "206: 2  2\n",
      "207: 2  2\n",
      "208: 2  2\n",
      "209: 2  2\n",
      "210: 2  2\n",
      "211: 2  2\n",
      "212: 2  2\n",
      "213: 2  2\n",
      "214: 2  2\n",
      "215: 2  2\n",
      "216: 2  2\n",
      "217: 2  2\n",
      "218: 2  2\n",
      "219: 1  1\n",
      "220: 1  1\n",
      "221: 1  1\n",
      "222: 1  1\n",
      "223: 1  1\n",
      "224: 1  1\n",
      "225: 1  1\n",
      "226: 1  1\n",
      "227: 1  1\n",
      "228: 1  1\n",
      "229: 1  1\n",
      "230: 1  1\n",
      "231: 1  1\n",
      "232: 1  1\n",
      "233: 1  1\n",
      "234: 1  1\n",
      "235: 1  1\n",
      "236: 1  1\n",
      "237: 1  1\n",
      "238: 1  1\n",
      "239: 1  1\n",
      "240: 1  1\n",
      "241: 1  1\n",
      "242: 1  1\n",
      "243: 1  1\n",
      "244: 1  1\n",
      "245: 1  1\n",
      "246: 1  1\n",
      "247: 1  1\n",
      "248: 1  1\n",
      "249: 1  1\n",
      "250: 1  1\n",
      "251: 1  1\n",
      "252: 1  1\n",
      "253: 1  1\n",
      "254: 1  1\n",
      "255: 1  1\n",
      "256: 1  1\n",
      "257: 1  1\n",
      "258: 1  1\n",
      "259: 1  1\n",
      "260: 1  1\n",
      "261: 1  1\n",
      "262: 1  1\n",
      "263: 1  1\n",
      "264: 1  1\n",
      "265: 1  1\n",
      "266: 1  1\n",
      "267: 1  1\n",
      "268: 1  1\n",
      "269: 1  1\n",
      "270: 1  1\n",
      "271: 1  1\n",
      "272: 1  1\n",
      "273: 1  1\n",
      "274: 1  1\n",
      "275: 1  1\n",
      "276: 1  1\n",
      "277: 1  1\n",
      "278: 1  1\n",
      "279: 1  1\n",
      "280: 1  1\n",
      "281: 1  1\n",
      "282: 1  1\n",
      "283: 1  1\n",
      "284: 1  1\n",
      "285: 1  1\n",
      "286: 1  1\n",
      "287: 1  1\n",
      "288: 1  1\n",
      "289: 1  1\n",
      "290: 1  1\n",
      "291: 1  1\n",
      "292: 1  1\n",
      "293: 1  1\n",
      "294: 1  1\n",
      "295: 1  1\n",
      "296: 1  1\n",
      "297: 1  1\n",
      "298: 1  1\n",
      "299: 1  1\n",
      "300: 1  1\n",
      "301: 1  1\n",
      "302: 1  1\n",
      "303: 1  1\n",
      "304: 1  1\n",
      "305: 1  1\n",
      "306: 1  1\n",
      "307: 1  1\n",
      "308: 1  1\n",
      "309: 1  1\n",
      "310: 1  1\n",
      "311: 1  1\n",
      "312: 1  1\n",
      "313: 1  1\n",
      "314: 1  1\n",
      "315: 1  1\n",
      "316: 1  1\n",
      "317: 1  1\n",
      "318: 1  1\n",
      "319: 1  1\n",
      "320: 1  1\n",
      "321: 1  1\n",
      "322: 1  1\n",
      "323: 1  1\n",
      "324: 1  1\n",
      "325: 1  1\n",
      "326: 1  1\n",
      "327: 1  1\n",
      "328: 1  1\n",
      "329: 1  1\n",
      "330: 1  1\n",
      "331: 1  1\n",
      "332: 1  1\n",
      "333: 1  1\n",
      "334: 1  1\n",
      "335: 1  1\n",
      "336: 1  1\n",
      "337: 1  1\n",
      "338: 1  1\n",
      "339: 1  1\n",
      "340: 1  1\n",
      "341: 1  1\n",
      "342: 1  1\n",
      "343: 1  1\n",
      "344: 1  1\n",
      "345: 1  1\n",
      "346: 1  1\n",
      "347: 1  1\n",
      "348: 1  1\n",
      "349: 1  1\n",
      "350: 1  1\n",
      "351: 1  1\n",
      "352: 1  1\n",
      "353: 1  1\n",
      "354: 1  1\n",
      "355: 1  1\n",
      "356: 1  1\n",
      "357: 1  1\n",
      "358: 1  1\n",
      "359: 1  1\n",
      "360: 1  1\n",
      "361: 1  1\n",
      "362: 1  1\n",
      "363: 1  1\n",
      "364: 1  1\n",
      "365: 1  1\n",
      "366: 1  1\n",
      "367: 1  1\n",
      "368: 1  1\n",
      "369: 1  1\n",
      "370: 1  1\n",
      "371: 1  1\n",
      "372: 1  1\n",
      "373: 1  1\n",
      "374: 1  1\n",
      "375: 1  1\n",
      "376: 1  1\n",
      "377: 1  1\n",
      "378: 1  1\n",
      "379: 1  1\n",
      "380: 1  1\n",
      "381: 1  1\n",
      "382: 1  1\n",
      "383: 1  1\n",
      "384: 1  1\n",
      "385: 1  1\n",
      "386: 1  1\n",
      "387: 1  1\n",
      "388: 1  1\n",
      "389: 1  1\n",
      "390: 1  1\n",
      "391: 1  1\n",
      "392: 1  1\n",
      "393: 1  1\n",
      "394: 1  1\n",
      "395: 1  1\n",
      "396: 1  1\n",
      "397: 1  1\n",
      "398: 1  1\n",
      "399: 1  1\n",
      "400: 1  1\n",
      "401: 1  1\n",
      "402: 1  1\n",
      "403: 1  1\n",
      "404: 1  1\n",
      "405: 1  1\n",
      "406: 2  2\n",
      "407: 2  2\n",
      "408: 2  2\n",
      "409: 4  4\n",
      "410: 2  2\n",
      "411: 1  1\n",
      "412: 1  1\n",
      "413: 1  1\n",
      "414: 1  1\n",
      "415: 2  2\n",
      "416: 2  2\n",
      "417: 2  2\n",
      "418: 2  2\n",
      "419: 2  2\n",
      "420: 2  2\n",
      "421: 2  2\n",
      "422: 4  4\n",
      "423: 4  4\n",
      "424: 4  4\n",
      "425: 4  4\n",
      "426: 4  4\n",
      "427: 4  4\n",
      "428: 4  4\n",
      "429: 4  4\n",
      "430: 4  4\n",
      "431: 4  4\n",
      "432: 2  2\n",
      "433: 2  2\n",
      "434: 2  2\n",
      "435: 2  2\n",
      "436: 4  4\n",
      "437: 4  4\n",
      "438: 4  4\n",
      "439: 4  4\n",
      "440: 2  2\n",
      "441: 2  2\n",
      "442: 2  2\n",
      "443: 2  2\n",
      "444: 2  2\n",
      "445: 2  2\n",
      "446: 2  2\n",
      "447: 2  2\n",
      "448: 2  2\n",
      "449: 2  2\n",
      "450: 2  2\n",
      "451: 2  2\n",
      "452: 2  2\n",
      "453: 2  2\n",
      "454: 2  2\n",
      "455: 2  2\n",
      "456: 2  2\n",
      "457: 2  2\n",
      "458: 2  2\n",
      "459: 2  2\n",
      "460: 2  2\n",
      "461: 2  2\n",
      "462: 2  2\n",
      "463: 1  1\n",
      "464: 1  1\n",
      "465: 1  1\n",
      "466: 1  1\n",
      "467: 1  1\n",
      "468: 1  1\n",
      "469: 1  1\n",
      "470: 1  1\n",
      "471: 1  1\n",
      "472: 1  1\n",
      "473: 1  1\n",
      "474: 1  1\n",
      "475: 1  1\n",
      "476: 1  1\n",
      "477: 1  1\n",
      "478: 1  1\n",
      "479: 1  1\n",
      "480: 1  1\n",
      "481: 1  1\n",
      "482: 1  1\n",
      "483: 1  1\n",
      "484: 1  1\n",
      "485: 1  1\n",
      "486: 1  1\n",
      "487: 1  1\n",
      "488: 1  1\n",
      "489: 1  1\n",
      "490: 1  1\n",
      "491: 1  1\n",
      "492: 1  1\n",
      "493: 1  1\n",
      "494: 1  1\n",
      "495: 1  1\n",
      "496: 1  1\n",
      "497: 1  1\n",
      "498: 1  1\n",
      "499: 1  1\n",
      "500: 1  1\n",
      "501: 1  1\n",
      "502: 1  1\n",
      "503: 1  1\n",
      "504: 1  1\n",
      "505: 1  1\n",
      "506: 1  1\n",
      "507: 1  1\n",
      "508: 1  1\n",
      "509: 5  5\n",
      "510: 5  5\n",
      "511: 5  5\n",
      "512: 1  1\n",
      "513: 1  1\n",
      "514: 1  1\n",
      "515: 1  1\n",
      "516: 1  1\n",
      "517: 1  1\n",
      "518: 1  1\n",
      "519: 1  1\n",
      "520: 5  5\n",
      "521: 5  5\n",
      "522: 5  5\n",
      "523: 1  1\n",
      "524: 1  1\n",
      "525: 1  1\n",
      "526: 1  1\n",
      "527: 1  1\n",
      "528: 5  5\n",
      "529: 5  5\n",
      "530: 5  5\n",
      "531: 5  5\n",
      "532: 5  5\n",
      "533: 5  5\n",
      "534: 5  5\n",
      "535: 5  5\n",
      "536: 5  5\n",
      "537: 5  5\n",
      "538: 5  5\n",
      "539: 5  5\n",
      "540: 5  5\n",
      "541: 5  5\n",
      "542: 5  5\n",
      "543: 5  5\n",
      "544: 5  5\n",
      "545: 5  5\n",
      "546: 5  5\n",
      "547: 5  5\n",
      "548: 5  5\n",
      "549: 5  5\n",
      "550: 5  5\n",
      "551: 5  5\n",
      "552: 5  5\n",
      "553: 5  5\n",
      "554: 5  5\n",
      "555: 5  5\n",
      "556: 5  5\n",
      "557: 5  5\n",
      "558: 5  5\n",
      "559: 5  5\n",
      "560: 5  5\n",
      "561: 5  5\n",
      "562: 5  5\n",
      "563: 5  5\n",
      "564: 5  5\n",
      "565: 5  5\n",
      "566: 1  1\n",
      "567: 1  1\n",
      "568: 1  1\n",
      "569: 1  1\n",
      "570: 1  1\n",
      "571: 1  1\n",
      "572: 1  1\n",
      "573: 1  1\n",
      "574: 1  1\n",
      "575: 1  1\n",
      "576: 1  1\n",
      "577: 1  1\n",
      "578: 1  1\n",
      "579: 1  1\n",
      "580: 1  1\n",
      "581: 1  1\n",
      "582: 1  1\n",
      "583: 1  1\n",
      "584: 1  1\n",
      "585: 1  1\n",
      "586: 1  1\n",
      "587: 1  1\n",
      "588: 1  1\n",
      "589: 1  1\n",
      "590: 1  1\n",
      "591: 4  4\n",
      "592: 4  4\n",
      "593: 4  4\n",
      "594: 4  4\n",
      "595: 4  4\n",
      "596: 4  4\n",
      "597: 4  4\n",
      "598: 4  4\n",
      "599: 4  4\n",
      "600: 4  4\n",
      "601: 4  4\n",
      "602: 4  4\n",
      "603: 4  4\n",
      "604: 4  4\n",
      "605: 4  4\n",
      "606: 4  4\n",
      "607: 4  4\n",
      "608: 4  4\n",
      "609: 4  4\n",
      "610: 4  4\n",
      "611: 4  4\n",
      "612: 4  4\n",
      "613: 4  4\n",
      "614: 4  4\n",
      "615: 4  4\n",
      "616: 4  4\n",
      "617: 4  4\n",
      "618: 4  4\n",
      "619: 4  4\n",
      "620: 4  4\n",
      "621: 4  4\n",
      "622: 4  4\n",
      "623: 4  4\n",
      "624: 4  4\n",
      "625: 4  4\n",
      "626: 4  4\n",
      "627: 4  4\n",
      "628: 4  4\n",
      "629: 4  4\n",
      "630: 4  4\n",
      "631: 4  4\n",
      "632: 4  4\n",
      "633: 4  4\n",
      "634: 4  4\n",
      "635: 4  4\n",
      "636: 4  4\n",
      "637: 4  4\n",
      "638: 4  4\n",
      "639: 4  4\n",
      "640: 4  4\n",
      "641: 4  4\n",
      "642: 4  4\n",
      "643: 4  4\n",
      "644: 4  4\n",
      "645: 4  4\n",
      "646: 4  4\n",
      "647: 4  4\n",
      "648: 4  4\n",
      "649: 4  4\n",
      "650: 4  4\n",
      "651: 4  4\n",
      "652: 4  4\n",
      "653: 4  4\n",
      "654: 4  4\n",
      "655: 4  4\n",
      "656: 4  4\n",
      "657: 4  4\n",
      "658: 4  4\n",
      "659: 4  4\n",
      "660: 4  4\n",
      "661: 4  4\n",
      "662: 4  4\n",
      "663: 4  4\n",
      "664: 4  4\n",
      "665: 4  4\n",
      "666: 4  4\n",
      "667: 4  4\n",
      "668: 4  4\n",
      "669: 4  4\n",
      "670: 4  4\n",
      "671: 4  4\n",
      "672: 4  4\n",
      "673: 4  4\n",
      "674: 4  4\n",
      "675: 4  4\n",
      "676: 4  4\n",
      "677: 4  4\n",
      "678: 4  4\n",
      "679: 4  4\n",
      "680: 4  4\n",
      "681: 4  4\n",
      "682: 4  4\n",
      "683: 4  4\n",
      "684: 4  4\n",
      "685: 4  4\n",
      "686: 4  4\n",
      "687: 4  4\n",
      "688: 4  4\n",
      "689: 4  4\n",
      "690: 4  4\n",
      "691: 4  4\n",
      "692: 4  4\n",
      "693: 4  4\n",
      "694: 4  4\n",
      "695: 4  4\n",
      "696: 4  4\n",
      "697: 4  4\n",
      "698: 4  4\n",
      "699: 4  4\n",
      "700: 4  4\n",
      "701: 4  4\n",
      "702: 4  4\n",
      "703: 4  4\n",
      "704: 4  4\n",
      "705: 4  4\n",
      "706: 4  4\n",
      "707: 4  4\n",
      "708: 4  4\n",
      "709: 1  1\n",
      "710: 1  1\n",
      "711: 1  1\n",
      "712: 1  1\n",
      "713: 1  1\n",
      "714: 1  1\n",
      "715: 1  1\n",
      "716: 1  1\n",
      "717: 1  1\n",
      "718: 1  1\n",
      "719: 1  1\n",
      "720: 1  1\n",
      "721: 1  1\n",
      "722: 1  1\n",
      "723: 1  1\n",
      "724: 1  1\n",
      "725: 1  1\n",
      "726: 1  1\n",
      "727: 1  1\n",
      "728: 1  1\n",
      "729: 1  1\n",
      "730: 1  1\n",
      "731: 1  1\n",
      "732: 1  1\n",
      "733: 1  1\n",
      "734: 1  1\n",
      "735: 1  1\n",
      "736: 1  1\n",
      "737: 1  1\n",
      "738: 1  1\n",
      "739: 1  1\n",
      "740: 1  1\n",
      "741: 1  1\n",
      "742: 1  1\n",
      "743: 1  1\n",
      "744: 1  1\n",
      "745: 1  1\n",
      "746: 1  1\n",
      "747: 1  1\n",
      "748: 1  1\n",
      "749: 1  1\n",
      "750: 1  1\n",
      "751: 1  1\n",
      "752: 1  1\n",
      "753: 1  1\n",
      "754: 1  1\n",
      "755: 1  1\n",
      "756: 1  1\n",
      "757: 1  1\n",
      "758: 1  1\n",
      "759: 5  5\n",
      "760: 5  5\n",
      "761: 5  5\n",
      "762: 5  5\n",
      "763: 5  5\n",
      "764: 5  5\n",
      "765: 5  5\n",
      "766: 5  5\n",
      "767: 5  5\n",
      "768: 5  5\n",
      "769: 5  5\n",
      "770: 5  5\n",
      "771: 5  5\n",
      "772: 5  5\n",
      "773: 5  5\n",
      "774: 5  5\n",
      "775: 5  5\n",
      "776: 5  5\n",
      "777: 5  5\n",
      "778: 5  5\n",
      "779: 5  5\n",
      "780: 5  5\n",
      "781: 5  5\n",
      "782: 5  5\n",
      "783: 5  5\n",
      "784: 5  5\n",
      "785: 5  5\n",
      "786: 5  5\n",
      "787: 5  5\n",
      "788: 5  5\n",
      "789: 5  5\n",
      "790: 5  5\n",
      "791: 5  5\n",
      "792: 5  5\n",
      "793: 5  5\n",
      "794: 5  5\n",
      "795: 5  5\n",
      "796: 5  5\n",
      "797: 5  5\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-583d52ff8256>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}: {}  {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_logits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_training_logits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(all_logits)):\n",
    "    print(\"{}: {}  {}\".format(i, np.argmax(all_logits[i]), np.argmax(all_training_logits[i])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len(rewards)\n",
    "#len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_logits\n",
    "\n",
    "# discounted_rewards_median = np.median(discounted_rewards)\n",
    "# discounted_rewards_mean = np.mean(discounted_rewards)\n",
    "# #average_logits = get_average_logits(all_logits, discounted_rewards)\n",
    "# max_reward = np.argmax(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len(all_gradients)\n",
    "np.shape(all_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.getsizeof(all_variables))\n",
    "#np.shape(all_gradients[1])\n",
    "#all_gradients\n",
    "#all_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "def get_size(obj, seen=None):\n",
    "    \"\"\"Recursively finds size of objects\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    # Important mark as seen *before* entering recursion to gracefully handle\n",
    "    # self-referential objects\n",
    "    seen.add(obj_id)\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum([get_size(v, seen) for v in obj.values()])\n",
    "        size += sum([get_size(k, seen) for k in obj.keys()])\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        size += get_size(obj.__dict__, seen)\n",
    "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum([get_size(i, seen) for i in obj])\n",
    "    return size\n",
    "\n",
    "get_size(all_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[261 260 259 258 257 256 255 254 253 252 251 250 249 248 247 246 245 244\n",
      " 243 242 241 240 239 238 237 236 235 230 229 228 227 226 225 224 223 222\n",
      " 221 220 132 131 130 126 127 128 286 295 125 123 555 554 529 528 527 526\n",
      " 525 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156\n",
      " 157 158 159 160 161 162 163 164 165 166 167 168 169 524 523 522 521 520\n",
      " 449 448 447 446 445 444 443 442 441 440 439 438 437 436 435 434 433 192\n",
      " 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 432 431\n",
      " 430 429 428 427 426 425 424 423 422 122 121 120 119 118 117 116 115 114\n",
      " 421 420 231 232 233 234 419 393 392 391 390 389 388 387 386 385 384 383\n",
      " 382 381 380 379 378 377 376 375 374 373 372 371 370 124 350 349 348 347\n",
      " 317 316 315 314 313 312 311 310 309 308 307 306 305 304 303 302 301 300\n",
      " 299 298 297 296 287 288 289 290 291 292 293 294 351 352   0  31 170 171\n",
      " 172 173 174 454 453 452 451 450 209 210 211 212 213 399 398 397 396 318\n",
      " 319 320 321 322 395 394 356 355 354 353   1 175 330 332 333 334 335 336\n",
      " 337   2   3   4   5   6   7   8   9  10  11  12  13  14  15 329 328 327\n",
      " 326 325 357 358 359 360 361 362 363 364 365 366 367 368 369  16 133 134\n",
      "  32  33  34  35  36  37  38  39  40  41  42 135 136 103 104 105 106 107\n",
      " 108 109 110 324 323 137 138 139 517 400 516 515 514 513 512 469 468 467\n",
      " 466 465 464 463 462 461  46  45  44  43 111 112 113 219 218 217 216 215\n",
      " 214 460 459 458 457 456 455 331 189 188 187 186 185 184 183 182 181 180\n",
      " 179 178 177 176 190 470  19  18  17 519 191 338 339 340 341 518  47  48\n",
      "  49  50 473 472 471  20  51 342  21 474 475  23  52 476 477 478 346 345\n",
      " 344 343  24  22  54  53  55  25 479  56  26  96 482  98  57 481 480  27\n",
      "  28  58  97  59 101 504 505 506 100  99 485 484  61 483  30  29  60  62\n",
      " 510 509 508  67  66  65  64  63 507 511 493 102 492 491 490 489 488 487\n",
      " 486  68  69  70 494  71  90  91  92  93  94  95  81  80  79  78 503 502\n",
      " 501  89  88 500 499  87  86  85  84  83  82 498 497 496 495  77  76  75\n",
      "  74  73  72]\n",
      "-0.7816080678548915\n",
      "-0.790043477322384\n",
      "-0.7983499165625977\n",
      "-0.8065293574204782\n",
      "-0.8145837415931414\n",
      "-0.8225149810908078\n",
      "-0.8303249586906896\n",
      "-0.8380155283839392\n",
      "-0.8455885158157628\n",
      "-0.853045718718806\n",
      "-0.8603889073399135\n",
      "-0.867619824860363\n",
      "-0.874740187809675\n",
      "-0.8817516864730955\n",
      "-0.8886559852928485\n",
      "-0.8954547232632537\n",
      "-0.9021495143198034\n",
      "-0.908741947722291\n",
      "-0.9152335884320801\n",
      "-0.9216259774836091\n",
      "-0.9279206323502109\n",
      "-0.9341190473043441\n",
      "-0.940222693772314\n",
      "-0.9462330206835702\n",
      "-0.9521514548146652\n",
      "-0.9579794011279534\n",
      "-0.9637182431051105\n",
      "-1.3916554800487952\n",
      "-1.3907637840918567\n",
      "-1.3898857214067433\n",
      "-1.3890210835523396\n",
      "-1.3881696652744153\n",
      "-0.5558275606453214\n",
      "-0.5677149617964633\n",
      "-0.5794206147071522\n",
      "-0.5909472981532102\n",
      "-0.6022977484253436\n",
      "-0.613474659978704\n",
      "-1.0309911031977808\n",
      "-1.0356136584260547\n",
      "-1.0401655387213933\n",
      "-1.0576876754633135\n",
      "-1.053407853253596\n",
      "-1.049061580230583\n",
      "-0.5223633595308472\n",
      "-0.40174024103524125\n",
      "-0.23039835902449907\n",
      "-0.2638664121112175\n",
      "-0.5018296295217497\n",
      "-0.5145426130558731\n",
      "-0.16039322251941177\n",
      "-0.17832647795403733\n",
      "-0.19598554918478192\n",
      "-0.21337462825463147\n",
      "-0.23049784311380425\n",
      "-0.4983117743192363\n",
      "-0.48534678208436205\n",
      "-0.472180488431775\n",
      "-0.4588097678477811\n",
      "-0.4452314462902855\n",
      "-0.43144230043531506\n",
      "-0.41743905691184086\n",
      "-0.4032183915247212\n",
      "-0.38877692846557943\n",
      "-0.3741112395114283\n",
      "-0.35921784321085354\n",
      "-0.34409320405756016\n",
      "-0.32873373165108816\n",
      "-0.3131357798444952\n",
      "-0.29729564587880775\n",
      "-0.2812095695040322\n",
      "-0.2648737320865181\n",
      "-0.24828425570246243\n",
      "-0.231437202217339\n",
      "-0.2143285723510344\n",
      "-0.19695430472846895\n",
      "-0.17931027491547682\n",
      "-0.16139229443971675\n",
      "-0.14319610979638162\n",
      "-0.12471740143846866\n",
      "-0.10595178275137367\n",
      "-0.08689479901156306\n",
      "-0.06754192632907832\n",
      "-0.04788857057362094\n",
      "-0.027930066283963433\n",
      "-0.24735925859967542\n",
      "-0.2639628774017179\n",
      "-0.28031264101169134\n",
      "-0.29641243065930284\n",
      "-0.3122660682335625\n",
      "-0.026828689571571016\n",
      "-0.04680403297324378\n",
      "-0.06647397038503347\n",
      "-0.08584317120444604\n",
      "-0.10491623343787568\n",
      "-0.12369768479211454\n",
      "-0.1421919837491736\n",
      "-0.1604035206246706\n",
      "-0.17833661861003644\n",
      "-0.1959955347987864\n",
      "-0.2133844611971013\n",
      "-0.23050752571895738\n",
      "-0.24736879316604124\n",
      "-0.26397226619268355\n",
      "-0.2803218862560384\n",
      "-0.2964215345517369\n",
      "-0.31227503293523406\n",
      "-0.31718584284447077\n",
      "-0.3014085923274543\n",
      "-0.28538637576347464\n",
      "-0.269115389678403\n",
      "-0.2525917715433327\n",
      "-0.2358115988576635\n",
      "-0.2187708882179488\n",
      "-0.2014655943722849\n",
      "-0.18389160926001927\n",
      "-0.16604476103654803\n",
      "-0.14792081308297228\n",
      "-0.1295154630003774\n",
      "-0.11082434158849765\n",
      "-0.09184301180852242\n",
      "-0.07256696772979836\n",
      "-0.052991633460178135\n",
      "-0.033112362059760495\n",
      "-0.3278861448290694\n",
      "-0.34325857611625693\n",
      "-0.35839597602001505\n",
      "-0.3733019379700469\n",
      "-0.3879800004555756\n",
      "-0.4024336478653374\n",
      "-0.4166663113147319\n",
      "-0.43068136946032637\n",
      "-0.4444821493019061\n",
      "-0.4580719269722629\n",
      "-0.47145392851490836\n",
      "-0.28021765059333414\n",
      "-0.2963188925635497\n",
      "-0.3121739602556377\n",
      "-0.327786617464672\n",
      "-0.34316057044050496\n",
      "-0.35829946876758506\n",
      "-0.3732069062313223\n",
      "-0.38788642167120846\n",
      "-0.4023414998208929\n",
      "-0.4846313306498958\n",
      "-0.49760726152793433\n",
      "-0.19186461019087267\n",
      "-0.17414155505279097\n",
      "-0.15614332226239247\n",
      "-0.1378656392639724\n",
      "-0.5103848014729726\n",
      "-0.03552656239441259\n",
      "-0.05536892272761327\n",
      "-0.0749079102688014\n",
      "-0.0941481633296188\n",
      "-0.11309424930587202\n",
      "-0.13175066576177535\n",
      "-0.1501218414976164\n",
      "-0.16821213760109796\n",
      "-0.18602584848260542\n",
      "-0.2035672028946466\n",
      "-0.22084036493570458\n",
      "-0.23784943503874278\n",
      "-0.25459845094459654\n",
      "-0.27109138866048216\n",
      "-0.28733216340385154\n",
      "-0.3033246305318159\n",
      "-0.31907258645635944\n",
      "-0.33457976954556007\n",
      "-0.3498498610110314\n",
      "-0.3648864857817963\n",
      "-0.37969321336479966\n",
      "-0.3942735586922652\n",
      "-0.40863098295609607\n",
      "-0.4227688944295186\n",
      "-0.24726129553737644\n",
      "-0.043759292793953075\n",
      "-0.06347578169022519\n",
      "-0.08289082226156498\n",
      "-0.10200902339615138\n",
      "-0.025855502817209365\n",
      "-0.04584572541560373\n",
      "-0.06553031453386814\n",
      "-0.08491394304764062\n",
      "-0.10400121238826987\n",
      "-0.12279665363513782\n",
      "-0.14130472859128124\n",
      "-0.15952983084256817\n",
      "-0.17747628680068012\n",
      "-0.19514835673014838\n",
      "-0.21255023575968757\n",
      "-0.22968605487806676\n",
      "-0.24655988191475461\n",
      "-0.26317572250557125\n",
      "-0.27953752104357643\n",
      "-0.2956491616154189\n",
      "-0.31151446892337004\n",
      "-0.3271372091932609\n",
      "-0.34252109106853657\n",
      "-0.3576697664906422\n",
      "-0.37258683156594813\n",
      "-0.3872758274194207\n",
      "-0.5097718050978342\n",
      "-0.496984747442555\n",
      "-0.4839991510772054\n",
      "-0.470811933383371\n",
      "-0.45741996388025147\n",
      "-0.44382006348152414\n",
      "-0.43000900374066825\n",
      "-0.41598350608457224\n",
      "-0.023736675124501828\n",
      "-0.0034031755624766846\n",
      "0.06988345796509957\n",
      "0.08457413812896059\n",
      "-0.007661675560426688\n",
      "0.01292141305983773\n",
      "0.033824085745029216\n",
      "0.05505130452861331\n",
      "0.07660810848724595\n",
      "0.07779768469641861\n",
      "0.056222693130574326\n",
      "0.03497756481280487\n",
      "0.014057256414954169\n",
      "-0.0065431982829413935\n",
      "-0.01292443443776497\n",
      "0.0075769417677214795\n",
      "0.028396633327391244\n",
      "0.049539582576027155\n",
      "0.07101080858574982\n",
      "0.0901673901778657\n",
      "0.0684032763490819\n",
      "0.04697191728671907\n",
      "0.02586822545376827\n",
      "-0.005554901309475708\n",
      "0.015060898216883766\n",
      "0.035996789695228945\n",
      "0.05725774304475192\n",
      "0.07884880535027351\n",
      "0.005087191097328459\n",
      "-0.015376118940645245\n",
      "0.0811373111686922\n",
      "0.059511259558067214\n",
      "0.038215851860119505\n",
      "0.017246032810996147\n",
      "0.09167055388692126\n",
      "0.09849961493698839\n",
      "0.26409330737322645\n",
      "0.31408340856514716\n",
      "0.3396620837930461\n",
      "0.36563790724080625\n",
      "0.39201704524453107\n",
      "0.41880575988216306\n",
      "0.446010410460023\n",
      "0.11379592793629259\n",
      "0.13626483240071394\n",
      "0.15908260111751624\n",
      "0.1822546507400473\n",
      "0.2057864820235176\n",
      "0.22968368113081106\n",
      "0.25395192095857083\n",
      "0.27859696248387295\n",
      "0.30362465613181117\n",
      "0.3290409431643146\n",
      "0.35485185709052947\n",
      "0.3810635250990983\n",
      "0.40768216951267805\n",
      "0.434714109265042\n",
      "0.23967001438345248\n",
      "0.21562013274495065\n",
      "0.19193795331615196\n",
      "0.16861785424340006\n",
      "0.14565429962639395\n",
      "0.10309914044658355\n",
      "0.12540196085575495\n",
      "0.14805106680725663\n",
      "0.17105183491600226\n",
      "0.19440972527710992\n",
      "0.21813028276206106\n",
      "0.24221913833498296\n",
      "0.26668201038936984\n",
      "0.2915247061055582\n",
      "0.31675312282927826\n",
      "0.34237324947161096\n",
      "0.36839116793068033\n",
      "0.3948130545354198\n",
      "0.4621657614011158\n",
      "0.1743996350644861\n",
      "0.1978095051648717\n",
      "0.10658932942412136\n",
      "0.1289463403778405\n",
      "0.15165047826532665\n",
      "0.1747071327653878\n",
      "0.19812177723987381\n",
      "0.22189997003298315\n",
      "0.24604735579074605\n",
      "0.2705696668009918\n",
      "0.29547272435412264\n",
      "0.32076244012501487\n",
      "0.346444817576378\n",
      "0.22158284945439008\n",
      "0.24572531142809684\n",
      "0.16529391249041542\n",
      "0.18856240226212423\n",
      "0.21219217107621324\n",
      "0.23618882834471314\n",
      "0.26055807057439234\n",
      "0.28530568271903595\n",
      "0.3104375395527217\n",
      "0.3359596070644185\n",
      "0.1230418382040334\n",
      "0.10077510206035864\n",
      "0.27024262220497625\n",
      "0.2951406018884376\n",
      "0.3204251609479347\n",
      "0.4478846911837389\n",
      "0.11226942530190591\n",
      "0.42065138444972494\n",
      "0.3938344517841635\n",
      "0.3674275271821261\n",
      "0.3414243419694791\n",
      "0.31581872331477734\n",
      "0.44468600271673275\n",
      "0.4175016012054203\n",
      "0.3907328260433521\n",
      "0.36437332265758976\n",
      "0.3384168336312041\n",
      "0.31285719721784155\n",
      "0.2876883458790034\n",
      "0.2629043048436872\n",
      "0.2384991906900515\n",
      "0.45322430644541556\n",
      "0.4259093615411937\n",
      "0.39901203888352477\n",
      "0.37252595338390043\n",
      "0.3618779438742373\n",
      "0.38819870267167117\n",
      "0.41492813167616854\n",
      "0.20702301773906567\n",
      "0.18347228087752146\n",
      "0.16028161472710573\n",
      "0.13744551411327646\n",
      "0.11495855803092238\n",
      "0.092815408357484\n",
      "0.21446720994876417\n",
      "0.19080265772770577\n",
      "0.16749991635769926\n",
      "0.14455345405894504\n",
      "0.12195782362784588\n",
      "0.09970766114390926\n",
      "0.2888958094990333\n",
      "0.4431871415375865\n",
      "0.41602565633729327\n",
      "0.3892794471153642\n",
      "0.3629421646557334\n",
      "0.3370075568164416\n",
      "0.311469467045456\n",
      "0.2863218329191816\n",
      "0.2615586847033175\n",
      "0.23717414393571642\n",
      "0.2131624220309112\n",
      "0.18951781890597744\n",
      "0.166234721627404\n",
      "0.1433076030786535\n",
      "0.1207310206480933\n",
      "0.47077035051364086\n",
      "0.4722924838147329\n",
      "0.5471046663839209\n",
      "0.518354370723467\n",
      "0.4900436426003038\n",
      "0.5036263866215314\n",
      "0.4987818311748114\n",
      "0.4736374550224298\n",
      "0.5016934518847594\n",
      "0.5301850611903068\n",
      "0.5591190464913215\n",
      "0.4755408368331374\n",
      "0.4809633578230046\n",
      "0.5091331005783563\n",
      "0.5377402218566202\n",
      "0.5667915126311457\n",
      "0.5577104493080114\n",
      "0.5287980002583874\n",
      "0.5003275979332868\n",
      "0.576301354542825\n",
      "0.5962938693155737\n",
      "0.5885022763545898\n",
      "0.6059513661293437\n",
      "0.5870718085365079\n",
      "0.616889047963897\n",
      "0.6666396230393467\n",
      "0.6262542954009591\n",
      "0.6471692458304643\n",
      "0.6779195902770481\n",
      "0.7091473810514135\n",
      "0.7106687802953957\n",
      "0.6794177286221926\n",
      "0.6486444789161055\n",
      "0.618341725991947\n",
      "0.6976922749971537\n",
      "0.6360617396859616\n",
      "0.6875779151269543\n",
      "0.6566799031183125\n",
      "0.7189556662290851\n",
      "0.7292270670711758\n",
      "0.7408600312411212\n",
      "0.750820605110975\n",
      "0.761251485227249\n",
      "0.7701593957806384\n",
      "0.8389830064217972\n",
      "0.8359864026085486\n",
      "0.7831802961111888\n",
      "0.8057701395017574\n",
      "0.7730650690333027\n",
      "0.793773131662326\n",
      "0.8267997266091444\n",
      "0.8160424210162662\n",
      "0.8028193512089467\n",
      "0.8494147808842812\n",
      "0.9386094802078958\n",
      "0.8710680860091826\n",
      "0.9052948038415529\n",
      "0.9400529440379707\n",
      "0.903873409344206\n",
      "0.8696684234232602\n",
      "0.9417478430714893\n",
      "0.906963789312202\n",
      "0.9177220172390906\n",
      "0.8727115541132706\n",
      "0.8943992441724512\n",
      "0.8603391101689123\n",
      "0.8833052978967169\n",
      "0.9526731090107833\n",
      "1.0845666850746218\n",
      "1.0475990528436745\n",
      "1.0111966242284096\n",
      "1.135739098678512\n",
      "1.0979890838212873\n",
      "1.0608162345438343\n",
      "1.0242117264759447\n",
      "0.9881668701645159\n",
      "0.975350757746863\n",
      "1.1221082965754958\n",
      "1.240184049025606\n",
      "0.9738848819237728\n",
      "1.200837159821462\n",
      "1.1620918510459781\n",
      "1.1239389250466973\n",
      "1.0863693247954367\n",
      "1.0493741317382614\n",
      "1.012944563678331\n",
      "0.9770719726911162\n",
      "1.1740752404976182\n",
      "1.2130066097999361\n",
      "1.2525424484063685\n",
      "1.2801418591185478\n",
      "1.2926921416312815\n",
      "2.1857794095947805\n",
      "1.396004964083623\n",
      "1.4383821332122082\n",
      "1.4814172729797037\n",
      "1.5251205993908725\n",
      "1.5695024870696421\n",
      "1.730123011002908\n",
      "1.6832853722954346\n",
      "1.637163841197508\n",
      "1.5917474690336049\n",
      "1.6688683693570494\n",
      "1.6229672619567281\n",
      "1.577767943399804\n",
      "2.1319751725835805\n",
      "2.0789935565373305\n",
      "1.5332596839324952\n",
      "1.4894319178498183\n",
      "2.02682198428201\n",
      "1.9754480709378779\n",
      "1.9248596209794573\n",
      "1.8750446253404704\n",
      "1.8259912585630362\n",
      "1.7776878759904537\n",
      "1.4462742409874203\n",
      "1.4037764082517623\n",
      "1.3619283311880612\n",
      "1.3207200755854152\n",
      "1.5470254745241274\n",
      "1.5029872412260628\n",
      "1.4596223150127694\n",
      "1.4169204015923007\n",
      "1.374871364063667\n",
      "1.333465220510462\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print (worst_frame_indexes)\n",
    "\n",
    "for i in range(0, len(worst_frame_indexes)):\n",
    "    print(discounted_rewards[worst_frame_indexes[i]])\n",
    "\n",
    "# print(frames_to_train)\n",
    "\n",
    "\n",
    "# for i in range(0, len(frames_to_train)):\n",
    "#     this_random_frame_index = frames_to_train[i]\n",
    "#     if this_random_frame_index not in worst_frame_indexes:\n",
    "#         print(\"the nubmer {} is not in there\".format(this_random_frame_index))\n",
    "#     else:\n",
    "#         print(\"the nubmer {} is in there\".format(this_random_frame_index))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[550 549]\n",
      "0: reward: -1.7458191165518884\n",
      "1: reward: -1.7395125601937154\n"
     ]
    }
   ],
   "source": [
    "worst_frame_indexes = np.argpartition(discounted_rewards, 2)[:2]\n",
    "print (worst_frame_indexes)\n",
    "\n",
    "for i in range(0, len(worst_frame_indexes)):\n",
    "    print(\"{}: reward: {}\".format(i, discounted_rewards[worst_frame_indexes[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
