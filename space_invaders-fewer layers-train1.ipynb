{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs.shape: (210, 160, 3)\n",
      "env.action_space: Discrete(6)\n",
      "[0.11849965 0.00589975 0.8756006 ]\n",
      "test_softmax: [0.13103449 0.13103449 0.13824064 0.13103449 0.33762142 0.13103449]\n",
      "multinomial_action_array: [0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "\n",
    "# To plot pretty figures and animations\n",
    "%matplotlib nbagg\n",
    "import matplotlib\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "####### Space Invaders\n",
    "load_model           = True\n",
    "perform_learning     = True\n",
    "BATCH_SIZE           = 32\n",
    "environment_name     = \"SpaceInvadersNoFrameskip-v4\"\n",
    "discrete_actions     = 6\n",
    "saver_path           = \"./models/\"\n",
    "saver_file_name      = \"space_invaders_three_layers_q_rl\"\n",
    "height               = 210\n",
    "width                = 160\n",
    "channels             = 1\n",
    "frames_captured      = 4\n",
    "max_learning_rate    = .00000001    # 2 x 10^-7   .0000001 seems to be the point where it will stop forming a bias to only do one thing\n",
    "min_learning_rate    = .00000000001  # 5 x 10^-9   .0000001 seems to be the point where it will stop forming a bias to only do one thing\n",
    "dropout_keep_prob    = 1.0\n",
    "negative_retrain_attempts = 10\n",
    "\n",
    "max_steps_until_done = 4500000  #1000*3000\n",
    "n_epochs             = 1001\n",
    "use_random_every_x_epoch = 50\n",
    "discount_decay_rate_range = [0.97, 0.99]\n",
    "frame_limit          = 5001\n",
    "max_score            = 5.0\n",
    "death_reward_range   = [-22.0, -16.0]\n",
    "death_reward_frames_delay = 43 #24 when capturing every fifth frame in the buffer.   45 when capturing every third\n",
    "maximum_negative_training_batches = 350   #150 works when capturing every fifth frame - maybe use 250 for every third\n",
    "max_train_frames     = 1000\n",
    "\n",
    "####### Pitfall\n",
    "# environment_name     = \"Pitfall-v0\"\n",
    "# discrete_actions     = 18\n",
    "# load_model           = False\n",
    "# saver_file           = \"./models/pitfall_rl\"\n",
    "# height               = 210\n",
    "# width                = 160\n",
    "# channels             = 1\n",
    "# frames_captured      = 5\n",
    "# learning_rate        =.00001\n",
    "# n_epochs             = 11\n",
    "# use_random_every_x_epoch = 5\n",
    "# discount_decay_rate  = 0.95\n",
    "# frame_limit          = 1000\n",
    "\n",
    "####### River Raid\n",
    "# environment_name     = \"Riverraid-v0\"\n",
    "# discrete_actions     = 18\n",
    "# load_model           = True\n",
    "# saver_file           = \"./models/pitfall_rl\"\n",
    "# height               = 210\n",
    "# width                = 160\n",
    "# channels             = 1\n",
    "# frames_captured      = 5\n",
    "# learning_rate        =.00001\n",
    "# n_epochs             = 501\n",
    "# use_random_every_x_epoch = 5\n",
    "# discount_decay_rate  = 0.95\n",
    "# frame_limit          = 1000\n",
    "\n",
    "\n",
    "def preprocess_observation(obs):\n",
    "    img = obs\n",
    "    img = img.mean(axis=2) # to greyscale\n",
    "    #img = (img - 128) / 128 - 1 # normalize from -1. to 1.\n",
    "    img = img / 256.0  # normalize from 0 to 1.\n",
    "    return img\n",
    "\n",
    "def show_observation(image, title=\"Image\"):\n",
    "    plt.figure(figsize=(11, 7))\n",
    "    plt.subplot(121)\n",
    "    plt.title(title)\n",
    "    plt.imshow(image, cmap=\"gray\") #cmap=\"gray\"\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def softmax(x):\n",
    "    ex = np.exp(x)\n",
    "    sum_ex = np.sum( np.exp(x))\n",
    "    return ex/sum_ex\n",
    "    \n",
    "env = gym.make(environment_name)\n",
    "observation = env.reset()\n",
    "print(\"obs.shape: {}\".format(observation.shape)) #obs.shape: (210, 160, 3)\n",
    "print(\"env.action_space: {}\".format(env.action_space)) #env.action_space: Discrete(9)\n",
    "\n",
    "for step_counter in range(102):\n",
    "    observation, reward_float, done_bool, info_dict = env.step(1)\n",
    "    obs_greyscale = preprocess_observation(observation)\n",
    "\n",
    "#show_observation(observation)\n",
    "#show_observation(obs_greyscale)\n",
    "    \n",
    "print (softmax([1,-2,3]))\n",
    "\n",
    "test_softmax = softmax([4.3210541e-25, 5.4929095e-33, 5.3535387e-02, 1.2303401e-42, 9.4646466e-01, 1.9473004e-27])\n",
    "print (\"test_softmax: {}\".format(test_softmax))\n",
    "\n",
    "multinomial_action_array = np.random.multinomial(1, test_softmax)\n",
    "print (\"multinomial_action_array: {}\".format(multinomial_action_array))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "eps_min = 0.00\n",
    "eps_max = 0.5\n",
    "eps_decay_steps = 25000\n",
    "\n",
    "def helper_discount_rewards(rewards, discount_rate, begin_index, end_index):\n",
    "    '''\n",
    "    Takes in rewards and applies discount rate\n",
    "    '''\n",
    "    discounted_rewards = np.zeros(len(rewards))\n",
    "    cumulative_rewards = 0\n",
    "    for step_counter in reversed(range(len(rewards))):\n",
    "        cumulative_rewards = rewards[step_counter] + cumulative_rewards * discount_rate\n",
    "        discounted_rewards[step_counter] = cumulative_rewards\n",
    "    \n",
    "    reward_mean = discounted_rewards.mean()\n",
    "    reward_std = discounted_rewards.std()\n",
    "        \n",
    "    #return discounted_rewards\n",
    "    return [(discounted_reward - reward_mean)/reward_std for discounted_reward in discounted_rewards]\n",
    "    #return [(discounted_reward - reward_mean)/(reward_mean*.75) for discounted_reward in discounted_rewards]\n",
    "\n",
    "def action_to_one_hot(action, possible_action_count):\n",
    "    return_array = np.zeros(possible_action_count)\n",
    "    action_int = int(action)\n",
    "    return_array[action_int] = 1.0\n",
    "    return return_array\n",
    "\n",
    "def getRewardArrays(actions, discounted_rewards, possible_action_count):\n",
    "    reward_arrays = []   \n",
    "    for this_action, this_reward in zip(actions, discounted_rewards):\n",
    "        this_value = action_to_one_hot(this_action, possible_action_count)\n",
    "        this_value = this_value * this_reward\n",
    "        reward_arrays.append(this_value)\n",
    "        \n",
    "    return reward_arrays\n",
    "\n",
    "def getRewardAverages(actions, discounted_rewards, possible_action_count):\n",
    "    reward_arrays = getRewardArrays(actions, discounted_rewards, possible_action_count)     \n",
    "    return np.mean(reward_arrays, axis=0)\n",
    "\n",
    "def weightRewardAveragesToAverageZero(actions, rewardArrays, possible_action_count):\n",
    "    positive_sums = np.zeros(possible_action_count)\n",
    "    negative_sums = np.zeros(possible_action_count)\n",
    "    \n",
    "    positive_counts = np.zeros(possible_action_count)\n",
    "    negative_counts = np.zeros(possible_action_count)\n",
    "    \n",
    "    for i in range(0, possible_action_count):\n",
    "        positiveSum = 0\n",
    "        negativeSum = 0\n",
    "        positiveCount = 0\n",
    "        negativeCount = 0\n",
    "        for rewardArray in rewardArrays:\n",
    "            if rewardArray[i] >= 0:\n",
    "                positiveSum = positiveSum + rewardArray[i]\n",
    "                positiveCount = positiveCount + 1\n",
    "            else:\n",
    "                negativeSum = negativeSum + rewardArray[i]\n",
    "                negativeCount = negativeCount + 1\n",
    "    \n",
    "        positive_sums[i] = positiveSum\n",
    "        negative_sums[i] = negativeSum\n",
    "        positive_counts[i] = positiveCount\n",
    "        negative_counts[i] = negativeCount\n",
    "        \n",
    "#     print(\"positive_sums: {}\".format(positive_sums));\n",
    "#     print(\"negative_sums: {}\".format(negative_sums));\n",
    "#     print(\"positive_counts: {}\".format(positive_counts));\n",
    "#     print(\"negative_counts: {}\".format(negative_counts));\n",
    "\n",
    "    for i in range(0, possible_action_count):\n",
    "        makeupTotal = positive_sums[i] + negative_sums[i]\n",
    "        for rewardArray in rewardArrays:\n",
    "            if makeupTotal > 0 and rewardArray[i] < 0:\n",
    "                rewardArray[i] = rewardArray[i] - makeupTotal/negative_counts[i]\n",
    "            elif makeupTotal < 0 and rewardArray[i] > 0:\n",
    "                rewardArray[i] = rewardArray[i] - makeupTotal/positive_counts[i]\n",
    "                \n",
    "    return rewardArrays\n",
    "\n",
    "\n",
    "def get_average_logits (logits_list, discounted_rewards):\n",
    "    logit_sums = np.zeros(len(logits_list[0][0]))\n",
    "    logit_sums_counter = np.ones(len(logits_list[0][0]))\n",
    "\n",
    "    for this_logit, this_reward in zip(logits_list, discounted_rewards):\n",
    "        temp_array = np.zeros(len(logits_list[0][0]))\n",
    "        temp_counter_array = np.zeros(len(logits_list[0][0]))\n",
    "        \n",
    "        action = np.argmax(this_logit)\n",
    "        temp_array[action] = this_logit[0][action]\n",
    "        logit_sums = logit_sums + temp_array*this_reward\n",
    "        temp_counter_array[action] = 1\n",
    "        logit_sums_counter = logit_sums_counter + temp_counter_array\n",
    "        \n",
    "    return (logit_sums/logit_sums_counter)\n",
    "\n",
    "# print(\"action_to_one_hot(3, 9): \" + str(action_to_one_hot(3.0, 9)))\n",
    "# print(\"action_to_one_hot(9, 9): \" + str(action_to_one_hot(8, 9)))\n",
    "#print(get_average_logits(all_logits, discounted_rewards))\n",
    "#print(all_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs  = discrete_actions\n",
    "n_outputs = discrete_actions\n",
    "n_hidden1 = 512\n",
    "n_hidden2 = 256\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "#with tf.name_scope(\"inputs\"):\n",
    "tf_input_frame = tf.placeholder(tf.float32, shape=(None, height*frames_captured, width, channels), name='tf_input_frame')\n",
    "#tf_train_index = tf.placeholder(tf.int32, shape=(None, 1))\n",
    "tf_train_index_one_hots = tf.placeholder(tf.float32, shape=(None, n_outputs), name='tf_train_index_one_hots')\n",
    "tf_input_learning_rate = tf.placeholder(tf.float32, name='tf_input_learning_rate')\n",
    "tf_dropout_keep_prob = tf.placeholder(tf.float32, name='tf_dropout_keep_prob')\n",
    "tf_reward = tf.placeholder(tf.float32, shape=(None, 1), name='tf_reward')\n",
    "tf_q_input = tf.placeholder(tf.float32, shape=(None, 1), name='tf_q_input')\n",
    "    \n",
    "initializer = tf.contrib.slim.variance_scaling_initializer(factor=1.0 / np.sqrt(3.0), mode='FAN_IN', uniform=True)\n",
    "\n",
    "convs   = [32,64,64]\n",
    "kerns   = [8,4,3]\n",
    "strides = [4,2,1]\n",
    "\n",
    "pads    = 'valid'\n",
    "activ   = tf.nn.elu\n",
    "\n",
    "# Policy Network\n",
    "conv1 = tf.layers.conv2d(\n",
    "        inputs = tf_input_frame,\n",
    "        filters = convs[0],\n",
    "        kernel_size = kerns[0],\n",
    "        strides = strides[0],\n",
    "        padding = pads,\n",
    "        activation = activ,\n",
    "        name='conv1')\n",
    "\n",
    "conv2 = tf.layers.conv2d(\n",
    "        inputs=conv1,\n",
    "        filters = convs[1],\n",
    "        kernel_size = kerns[1],\n",
    "        strides = strides[1],\n",
    "        padding = pads,\n",
    "        activation = activ,\n",
    "        name='conv2')\n",
    "\n",
    "conv3 = tf.layers.conv2d(\n",
    "        inputs=conv2,\n",
    "        filters = convs[2],\n",
    "        kernel_size = kerns[2],\n",
    "        strides = strides[2],\n",
    "        padding = pads,\n",
    "        activation = activ,\n",
    "        name='conv3')\n",
    "\n",
    "flat = tf.layers.flatten(conv3)\n",
    "\n",
    "hidden1 = tf.layers.dense(flat,    n_hidden1, activation=activ, name=\"hidden1\", kernel_initializer=initializer)\n",
    "hidden1_drop = tf.nn.dropout(hidden1, tf_dropout_keep_prob)\n",
    "hidden2 = tf.layers.dense(hidden1_drop, n_hidden2, activation=activ, name=\"hidden2\", kernel_initializer=initializer)\n",
    "\n",
    "q_predicted = tf.layers.dense(inputs=hidden2, units=1, name=\"output_q\", activation=None)\n",
    "logits = tf.layers.dense(inputs=hidden2, units=n_outputs, name=\"output\", activation=None)\n",
    "\n",
    "#loss = tf.reduce_sum(tf.square(single_logit-tf_reward))\n",
    "loss = tf.square(logits-tf_reward)\n",
    "loss = loss * tf_train_index_one_hots\n",
    "loss = tf.reduce_sum(loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(tf_input_learning_rate)\n",
    "training_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(max_to_keep=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model before training: space_invaders_three_layers_q_rl\n",
      "INFO:tensorflow:Restoring parameters from ./models/space_invaders_three_layers_q_rl-4260583\n",
      "Death at frame 196. Score: 35.0. Total Rewards: 20.0\n",
      "Death at frame 331. Score: 70.0. Total Rewards: 35.0\n",
      "Death at frame 844. Score: 255.0. Total Rewards: 95.0\n",
      "original_len: 845\n",
      "original punish_frames: [153, 288, 801]\n",
      "Death reward at frame 153: -18.416088394897113\n",
      "Death reward at frame 288: -18.416088394897113\n",
      "Death reward at frame 801: -18.416088394897113\n",
      "Epoch: 0, frames: 845, score: 255.0, avg loss: 35.3551, learning_rate: 3.10650706e-09, step: 3105177, discount_decay_rate: 0.9721, death_penalty: -18.416\n",
      "actions trained (positive):   [ 84.  96.  84.  86. 693. 538.]\n",
      "actions trained (negative):   [ 96.  81.  67. 128. 546. 637.]\n",
      "actions trained (total):      [ 180.  177.  151.  214. 1239. 1175.]\n",
      "actions out while training:   [ 0.  0.  0.  0. 45. 53.]\n",
      "training disagreements with runthrough: 0\n",
      "\n",
      "Using strict AI actions\n",
      "Death at frame 523. Score: 200.0. Total Rewards: 85.0\n",
      "Death at frame 755. Score: 305.0. Total Rewards: 110.0\n",
      "Death at frame 1006. Score: 550.0. Total Rewards: 125.0\n",
      "original_len: 1006\n",
      "original punish_frames: [320, 552, 963]\n",
      "Death reward at frame 314: -17.858438559602483\n",
      "Death reward at frame 546: -17.858438559602483\n",
      "Death reward at frame 957: -17.858438559602483\n",
      "Epoch: 1, frames: 1000, score: 550.0, avg loss: 24.6398, learning_rate: 3.1039229800000006e-09, step: 3106341, discount_decay_rate: 0.9854, death_penalty: -17.858\n",
      "actions trained (positive):   [ 17.   0.   0.   0. 838. 774.]\n",
      "actions trained (negative):   [351. 216.   0.   4. 916. 628.]\n",
      "actions trained (total):      [ 368.  216.    0.    4. 1754. 1402.]\n",
      "actions out while training:   [ 6. 11.  0.  0. 54. 46.]\n",
      "training disagreements with runthrough: 0\n",
      "\n",
      "Using strict AI actions\n",
      "Death at frame 523. Score: 200.0. Total Rewards: 85.0\n",
      "Death at frame 1001. Score: 425.0. Total Rewards: 140.0\n",
      "Death at frame 1004. Score: 445.0. Total Rewards: 145.0\n",
      "original_len: 1004\n",
      "original punish_frames: [0, 768, 961]\n",
      "Death reward at frame 764: -21.756896015222104\n",
      "Death reward at frame 957: -21.756896015222104\n",
      "Epoch: 2, frames: 1000, score: 445.0, avg loss: 31.3399, learning_rate: 3.1006329399999997e-09, step: 3107823, discount_decay_rate: 0.9848, death_penalty: -21.757\n",
      "actions trained (positive):   [314. 399.  77.  36. 830. 486.]\n",
      "actions trained (negative):   [ 96.  86. 491. 448. 397.  84.]\n",
      "actions trained (total):      [ 410.  485.  568.  484. 1227.  570.]\n",
      "actions out while training:   [17. 32.  9. 10. 30. 19.]\n",
      "training disagreements with runthrough: 0\n",
      "\n",
      "Using strict AI actions\n",
      "Death at frame 523. Score: 200.0. Total Rewards: 85.0\n",
      "Death at frame 755. Score: 280.0. Total Rewards: 100.0\n",
      "Death at frame 858. Score: 280.0. Total Rewards: 100.0\n",
      "original_len: 859\n",
      "original punish_frames: [480, 712, 815]\n",
      "Death reward at frame 480: -19.743910745435112\n",
      "Death reward at frame 712: -19.743910745435112\n",
      "Death reward at frame 815: -19.743910745435112\n",
      "Epoch: 3, frames: 859, score: 280.0, avg loss: 42.3468, learning_rate: 3.0987304000000002e-09, step: 3108680, discount_decay_rate: 0.973, death_penalty: -19.744\n",
      "actions trained (positive):   [   4.    0.    0.    0.  989. 1087.]\n",
      "actions trained (negative):   [  0.   0.   0.   0. 583. 537.]\n",
      "actions trained (total):      [   4.    0.    0.    0. 1572. 1624.]\n",
      "actions out while training:   [ 0.  0.  0.  0. 52. 48.]\n",
      "training disagreements with runthrough: 0\n",
      "\n",
      "Using strict AI actions\n",
      "Death at frame 523. Score: 200.0. Total Rewards: 85.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(environment_name)\n",
    "\n",
    "def get_concatenated_frames(frames, end_index, num_frames_to_concatenate):\n",
    "    concatenated_frames = frames[:,:,end_index-1]\n",
    "\n",
    "    for j in range(1,num_frames_to_concatenate,1):\n",
    "        if end_index-j <= 1:\n",
    "            this_frame = frames[:,:,0]\n",
    "        elif j >= num_frames:\n",
    "            this_frame = frames[:,:,end_index-1]\n",
    "        else:\n",
    "            this_frame = frames[:,:,end_index-1-j]\n",
    "            \n",
    "        concatenated_frames = np.append(concatenated_frames, this_frame, axis=0)\n",
    "    return concatenated_frames\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if load_model:\n",
    "        print(\"Loading existing model before training: {}\".format(saver_file_name))\n",
    "        #saver.restore(sess, tf.train.latest_checkpoint(saver_file))\n",
    "        \n",
    "        ckpt = tf.train.get_checkpoint_state(saver_path)\n",
    "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess, os.path.join(saver_path, ckpt_name))\n",
    "    else:\n",
    "        print(\"Creating new model before training: {}\".format(saver_file_name))\n",
    "        sess.run(init)\n",
    "    \n",
    "    step = global_step.eval(session=sess)\n",
    "    \n",
    "    for epoch in range(n_epochs):  #play n_epochs games\n",
    "        if step > max_steps_until_done:\n",
    "            print(\"Max Steps reached: step: {}, max steps: {}\".format(step, max_steps_until_done))\n",
    "            break\n",
    "                \n",
    "        observation = env.reset()\n",
    "        temp_lives = 3\n",
    "        score = 0.0\n",
    "        total_rewards = 0.0\n",
    "        frames = np.empty([height, width, 0])\n",
    "        actions = np.empty([0])\n",
    "        rewards = np.empty([0])\n",
    "        all_logits = []\n",
    "        all_training_logits = []\n",
    "        punish_frames = []\n",
    "        default_input_q = np.reshape([0.0], (1,1))\n",
    "            \n",
    "        #get the first frame\n",
    "        input_value = 0  #set an initial input value\n",
    "        observation, reward_float, done_bool, info_dict = env.step(input_value)  #run one to get frames that show enemy fire\n",
    "        \n",
    "        obs_greyscale = preprocess_observation(observation)\n",
    "        obs_greyscale_reshape = np.reshape(obs_greyscale, (height,width,1))\n",
    "        frames = np.append(frames, obs_greyscale_reshape, axis=2)\n",
    "        actions = np.append(actions, input_value)\n",
    "        last_action_step = 0\n",
    "        decision_step_counter = 0\n",
    "\n",
    "        game_step_counter = 0\n",
    "        action_from_ai_epsilon_greedy = 0\n",
    "        points_at_death = []\n",
    "        \n",
    "        gc.disable()\n",
    "        while True:\n",
    "            num_frames = np.ma.size(frames, axis=2)                     \n",
    "            concatenated_frames = get_concatenated_frames(frames, num_frames, frames_captured)\n",
    "            concatenated_frames_reshaped = np.reshape(concatenated_frames, (1, height*frames_captured, width, 1))\n",
    "            \n",
    "            #use the input value from the AI\n",
    "            temp_input = np.zeros(discrete_actions) #[0, 0, 0, ...]\n",
    "            temp_input[action_from_ai_epsilon_greedy] = 1\n",
    "            temp_input_reshaped = np.reshape(temp_input, (1, len(temp_input)))\n",
    "            \n",
    "            \n",
    "            #tf_dropout_keep_prob: 1.0,\n",
    "            feed_dict = {tf_input_frame : concatenated_frames_reshaped, \n",
    "                         tf_input_learning_rate: 0.0,\n",
    "                         tf_dropout_keep_prob: 1.0,\n",
    "                         tf_q_input: default_input_q}\n",
    "            logits_out = sess.run([logits], feed_dict=feed_dict)\n",
    "\n",
    "            all_logits.append(logits_out[0][0])\n",
    "            \n",
    "            #if global_step % 5 == 0:  #only allow a change of direction every 5 steps.  \n",
    "            action_from_ai_logits_argmax = np.argmax(logits_out[0])\n",
    "    \n",
    "            positive_logits = logits_out[0] + abs(np.amin(logits_out[0]))\n",
    "            softmax_logits = softmax(positive_logits / np.amax(positive_logits))\n",
    "\n",
    "            try:\n",
    "                multinomial_action_array = np.random.multinomial(1, softmax_logits[0])\n",
    "                action_from_multinomial_action = np.argmax(multinomial_action_array)\n",
    "#                print (\"multinomial_action_array: {}\".format(multinomial_action_array))\n",
    "            except ValueError:\n",
    "                #I have no idea why this occassionally errors out.\n",
    "                action_from_multinomial_action = np.argmax(softmax_logits)\n",
    "                print (\"multinomial error, using action {}\".format(action_from_multinomial_action))\n",
    "                continue\n",
    "                \n",
    "#            print (\"action_from_multinomial_action: {}\".format(action_from_multinomial_action))\n",
    "        \n",
    "            # decide which action to use\n",
    "            #only train even frames for consistency between frames with enemy vs friendly fire.\n",
    "            #perform logic here for consistency between what is trained and what actions are taken\n",
    "#            if i % 2 != 0:\n",
    "            if epoch % use_random_every_x_epoch != 0:\n",
    "                if game_step_counter == 0:\n",
    "                    print(\"Using strict AI actions\")\n",
    "                action_from_ai_epsilon_greedy = action_from_ai_logits_argmax  #do what the AI says\n",
    "            else:\n",
    "#                print(\"Using probability-based actions\")\n",
    "                if step % 2 == 0:\n",
    "                    action_from_ai_epsilon_greedy = action_from_multinomial_action  #use probability-based action\n",
    "                else:\n",
    "                    action_from_ai_epsilon_greedy = action_from_ai_logits_argmax \n",
    "            \n",
    "            this_reward_for_set = 0\n",
    "            \n",
    "            #run the next step given the input from the logits\n",
    "            observation, reward_float, done_bool, info_dict = env.step(action_from_ai_epsilon_greedy)\n",
    "            score = score + reward_float\n",
    "            if reward_float > max_score:\n",
    "                this_reward_for_set = this_reward_for_set + max_score\n",
    "                #rewards = np.append(rewards, max_score)\n",
    "                total_rewards = total_rewards + max_score\n",
    "            else:\n",
    "                this_reward_for_set = this_reward_for_set + reward_float\n",
    "                #rewards = np.append(rewards, reward_float)\n",
    "                total_rewards = total_rewards + reward_float\n",
    "                \n",
    "            observation, reward_float, done_bool, info_dict = env.step(action_from_ai_epsilon_greedy)\n",
    "            score = score + reward_float\n",
    "            if reward_float > max_score:\n",
    "                this_reward_for_set = this_reward_for_set + max_score\n",
    "                #rewards = np.append(rewards, max_score)\n",
    "                total_rewards = total_rewards + max_score\n",
    "            else:\n",
    "                this_reward_for_set = this_reward_for_set + reward_float\n",
    "                #rewards = np.append(rewards, reward_float)\n",
    "                total_rewards = total_rewards + reward_float\n",
    "            \n",
    "            observation, reward_float, done_bool, info_dict = env.step(action_from_ai_epsilon_greedy)\n",
    "            score = score + reward_float\n",
    "            if reward_float > max_score:\n",
    "                this_reward_for_set = this_reward_for_set + max_score\n",
    "                #rewards = np.append(rewards, max_score)\n",
    "                total_rewards = total_rewards + max_score\n",
    "            else:\n",
    "                this_reward_for_set = this_reward_for_set + reward_float\n",
    "                #rewards = np.append(rewards, reward_float)\n",
    "                total_rewards = total_rewards + reward_float\n",
    "            \n",
    "#             observation, reward_float, done_bool, info_dict = env.step(action_from_ai_epsilon_greedy)\n",
    "#             score = score + reward_float\n",
    "#             if reward_float > max_score:\n",
    "#                 this_reward_for_set = this_reward_for_set + max_score\n",
    "#                 #rewards = np.append(rewards, max_score)\n",
    "#                 total_rewards = total_rewards + max_score\n",
    "#             else:\n",
    "#                 this_reward_for_set = this_reward_for_set + reward_float\n",
    "#                 #rewards = np.append(rewards, reward_float)\n",
    "#                 total_rewards = total_rewards + reward_float\n",
    "                \n",
    "#             observation, reward_float, done_bool, info_dict = env.step(action_from_ai_epsilon_greedy)\n",
    "#             score = score + reward_float\n",
    "#             if reward_float > max_score:\n",
    "#                 this_reward_for_set = this_reward_for_set + max_score\n",
    "#                 #rewards = np.append(rewards, max_score)\n",
    "#                 total_rewards = total_rewards + max_score\n",
    "#             else:\n",
    "#                 this_reward_for_set = this_reward_for_set + reward_float\n",
    "#                 #rewards = np.append(rewards, reward_float)\n",
    "#                 total_rewards = total_rewards + reward_float\n",
    "                \n",
    "            rewards = np.append(rewards, this_reward_for_set)\n",
    "            \n",
    "#            if step % 2 != 0:\n",
    "            env.render()  #display the current frame.\n",
    "                \n",
    "            #add this frame to our frame buffer\n",
    "            obs_greyscale = preprocess_observation(observation)\n",
    "            obs_greyscale_reshape = np.reshape(obs_greyscale, (height,width,1))\n",
    "            frames = np.append(frames, obs_greyscale_reshape, axis=2)\n",
    "            \n",
    "            actions = np.append(actions, action_from_ai_epsilon_greedy)\n",
    "            \n",
    "            lives = info_dict['ale.lives']\n",
    "\n",
    "            if done_bool:\n",
    "                punish_frames.append(len(rewards) - death_reward_frames_delay)\n",
    "                print(\"Death at frame {}. Score: {}. Total Rewards: {}\".format(len(rewards), score, total_rewards))\n",
    "                points_at_death.append(total_rewards)\n",
    "                break\n",
    "                \n",
    "            if game_step_counter > frame_limit:\n",
    "                break\n",
    "                \n",
    "            if lives != temp_lives:  #we lost a life.  consider this game over.\n",
    "                #print(\"Lost a life.  Current lives: {}\".format(lives))\n",
    "                temp_lives = lives\n",
    "                if len(rewards) > death_reward_frames_delay:\n",
    "                    punish_frames.append(len(rewards) - death_reward_frames_delay)\n",
    "                    print(\"Death at frame {}. Score: {}. Total Rewards: {}\".format(len(rewards), score, total_rewards))\n",
    "                    points_at_death.append(total_rewards)\n",
    "\n",
    "            decision_step_counter += 1\n",
    "            game_step_counter += 1\n",
    "            step += 1\n",
    "            \n",
    "            # only train that last max_train_frames frames\n",
    "            original_len = len(actions)\n",
    "\n",
    "            if original_len >= (max_train_frames+10):\n",
    "                frames = frames[:,:,-max_train_frames:]\n",
    "                rewards = rewards[-max_train_frames:]\n",
    "                actions = actions[-max_train_frames:]\n",
    "                all_logits = all_logits[-max_train_frames:]\n",
    "                punish_frames[:] = [x - (original_len-max_train_frames) for x in punish_frames]\n",
    "            \n",
    "        gc.enable()\n",
    "        \n",
    "        # only train that last 700 frames\n",
    "        original_len = len(actions)\n",
    "        print(\"original_len: {}\".format(original_len))\n",
    "        print(\"original punish_frames: {}\".format(punish_frames))\n",
    "        \n",
    "        if original_len > max_train_frames:\n",
    "            frames = frames[:,:,-max_train_frames:]\n",
    "            rewards = rewards[-max_train_frames:]\n",
    "            actions = actions[-max_train_frames:]\n",
    "            all_logits = all_logits[-max_train_frames:]\n",
    "            #punish_frames = punish_frames - (original_len-700)\n",
    "            punish_frames[:] = [x - (original_len-max_train_frames) for x in punish_frames]\n",
    "        \n",
    "        if perform_learning:\n",
    "            if epoch % 20 == 0 and epoch > 0:\n",
    "                print(\"Saving model at epoch {}. score: {}, file: {}\".format(epoch, score, saver_file_name))\n",
    "                saver.save(sess, os.path.join(saver_path, saver_file_name), global_step=step)\n",
    "\n",
    "            num_frames = np.ma.size(frames, axis=2)\n",
    "            frames_to_skip_begin = 0\n",
    "\n",
    "            #punish death\n",
    "            death_penalty = random.uniform(death_reward_range[0], death_reward_range[1])\n",
    "\n",
    "            for this_frame, this_points in zip(punish_frames, points_at_death):\n",
    "                if this_frame < 0 or this_frame > len(rewards):\n",
    "                    continue\n",
    "                rewards[this_frame] = death_penalty\n",
    "                print(\"Death reward at frame {}: {}\".format(this_frame, rewards[this_frame]))\n",
    "\n",
    "            discount_decay_rate = random.uniform(discount_decay_rate_range[0], discount_decay_rate_range[1])\n",
    "            discounted_rewards = helper_discount_rewards(rewards, discount_decay_rate, frames_to_skip_begin, num_frames)\n",
    "\n",
    "            positive_display_actions = np.zeros(discrete_actions)\n",
    "            negative_display_actions = np.zeros(discrete_actions)\n",
    "            ai_training_actions = np.zeros(discrete_actions)\n",
    "            loss_out_sum = 0.0\n",
    "            frames_taught = 0.000000001\n",
    "\n",
    "            reward_frame_counter = 0\n",
    "            punish_frame_counter = 0\n",
    "\n",
    "            frames_to_train = np.arange(num_frames-2-BATCH_SIZE)\n",
    "            np.random.shuffle(frames_to_train) \n",
    "\n",
    "            skipped_negative_training_batches = 0\n",
    "\n",
    "            disagreement_counter = 0\n",
    "            \n",
    "            \n",
    "            #for i in range(2 * int(num_frames/BATCH_SIZE)):\n",
    "            for i in range(0, len(frames_to_train)-BATCH_SIZE, int(BATCH_SIZE/4)):\n",
    "                learning_rate = max_learning_rate - step/max_steps_until_done*(max_learning_rate-min_learning_rate)\n",
    "                #iterate through BATCH_SIZE frames to generate a batch\n",
    "\n",
    "                for batch_index in range(0, BATCH_SIZE):\n",
    "                    this_random_frame_index = frames_to_train[i+batch_index-1]\n",
    "\n",
    "                    concatenated_frames = get_concatenated_frames(frames, this_random_frame_index, frames_captured)\n",
    "                    concatenated_frames_reshaped = np.reshape(concatenated_frames, (1, height*frames_captured, width, 1))\n",
    "\n",
    "                    action_taken_one_hot = action_to_one_hot(actions[this_random_frame_index], n_outputs)\n",
    "\n",
    "                    #print(\"reward for frame {} :{}. frame array: {}\".format(this_random_frame_index, reward_for_frame, reward_arrays[this_random_frame_index+1]) )\n",
    "                    max_logit                 = np.amax(all_logits[this_random_frame_index])\n",
    "                    second_max_logit_index = np.argsort(all_logits[this_random_frame_index])[len(all_logits[this_random_frame_index])-2]\n",
    "                    second_max_logit =                  all_logits[this_random_frame_index][second_max_logit_index]\n",
    "                    min_logit =                 np.amin(all_logits[this_random_frame_index])\n",
    "                    average_logit =          np.average(all_logits[this_random_frame_index])\n",
    "                    action_logit =                      all_logits[this_random_frame_index][int(actions[this_random_frame_index])]                        \n",
    "\n",
    "#                       print(\"original action: {}: original reward: {}, logits: {}\".format(actions[this_random_frame_index], reward_for_frame, all_logits[this_random_frame_index]))\n",
    "#                       print(\"second largest logit: {}\".format(second_max_logit))\n",
    "\n",
    "                    if discounted_rewards[this_random_frame_index] > 0.0:\n",
    "                        positive_display_actions = np.add(positive_display_actions, action_taken_one_hot)\n",
    "                    else:\n",
    "                        negative_display_actions = np.add(negative_display_actions, action_taken_one_hot)\n",
    "                        \n",
    "                    if epoch % use_random_every_x_epoch != 0:\n",
    "                        reward_for_frame = discounted_rewards[this_random_frame_index] + second_max_logit\n",
    "                    else:\n",
    "                        reward_for_frame = discounted_rewards[this_random_frame_index] + action_logit\n",
    "\n",
    "\n",
    "\n",
    "#                       print(\"reward for frame: {}, max_logit: {}, min_logit: {}\".format(reward_for_frame, max_logit, min_logit))\n",
    "\n",
    "                    action_taken_one_hot_reshaped = np.reshape(action_taken_one_hot, (1, len(action_taken_one_hot)))\n",
    "                    \n",
    "                    input_q = np.reshape([reward_for_frame], (1,1))\n",
    "                    \n",
    "                    train_index = actions[this_random_frame_index]\n",
    "                    \n",
    "                    if batch_index == 0:\n",
    "                        concatenated_frames_reshaped_batch = concatenated_frames_reshaped\n",
    "                        reward_for_frame_batch = np.reshape([reward_for_frame], (1,1))\n",
    "                        input_q_batch = np.reshape([input_q], (1,1))\n",
    "                        train_index_batch = np.reshape(action_taken_one_hot, (1, 6))\n",
    "                    else:\n",
    "                        concatenated_frames_reshaped_batch = np.append(concatenated_frames_reshaped_batch, concatenated_frames_reshaped, axis=0)\n",
    "                        reward_for_frame_batch = np.append(reward_for_frame_batch, np.reshape([reward_for_frame], (1,1)), axis=0)\n",
    "                        input_q_batch = np.append(input_q_batch, np.reshape([input_q], (1,1)), axis=0)\n",
    "                        action_taken_one_hot_temp = np.reshape(action_taken_one_hot, (1, 6))\n",
    "                        train_index_batch = np.append(train_index_batch, action_taken_one_hot_temp, axis=0)\n",
    "                        \n",
    "                feed_dict = {tf_input_frame : concatenated_frames_reshaped_batch, \n",
    "                             tf_input_learning_rate: learning_rate,\n",
    "                             tf_dropout_keep_prob: 1.0,  ######################### \n",
    "                             tf_reward: reward_for_frame_batch,\n",
    "                             tf_q_input: input_q_batch,\n",
    "                             tf_train_index_one_hots: train_index_batch}\n",
    "                loss_out, _, training_logits_out = sess.run([loss, training_op, logits], feed_dict=feed_dict)\n",
    "\n",
    "                all_training_logits.append(training_logits_out)\n",
    "\n",
    "#                 if np.argmax(all_training_logits[i]) != np.argmax(all_logits[i]):\n",
    "#                     disagreement_counter += 1\n",
    "\n",
    "                frames_taught = frames_taught + 1\n",
    "                loss_out_sum += abs(loss_out)\n",
    "\n",
    "                action_from_training = np.argmax(training_logits_out[0])\n",
    "                action_from_training_one_hot = action_to_one_hot(action_from_training, n_outputs)\n",
    "                ai_training_actions = np.add(ai_training_actions, action_from_training_one_hot)\n",
    "\n",
    "            print(\"Epoch: \" + str(epoch) + \", frames: \" + str(num_frames) + \", score: \" + str(score) + \", avg loss: \" + str(round(loss_out_sum/frames_taught, 4)) + \", learning_rate: \" + str(learning_rate) + \", step: \" + str(step) + \", discount_decay_rate: \" + str(round(discount_decay_rate, 4)) + \", death_penalty: \" + str(round(death_penalty, 3)) )\n",
    "            print(\"actions trained (positive):   {}\".format(positive_display_actions))\n",
    "            print(\"actions trained (negative):   {}\".format(negative_display_actions))\n",
    "            print(\"actions trained (total):      {}\".format(positive_display_actions+negative_display_actions))\n",
    "            print(\"actions out while training:   {}\".format(ai_training_actions))\n",
    "            print(\"training disagreements with runthrough: {}\".format(disagreement_counter))\n",
    "\n",
    "            print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "frame_to_display = 541\n",
    "print(\"discounted reward at frame {}: {}\".format(frame_to_display, round(discounted_rewards[frame_to_display], 3)))\n",
    "print(\"original logits at frame {}: {} {}\".format(frame_to_display, np.argmax(all_logits[frame_to_display]), all_logits[frame_to_display]))\n",
    "\n",
    "# print(\"training logits at frame {}: {} {}\".format(frame_to_display, np.argmax(all_training_logits[frame_to_display]), all_training_logits[frame_to_display]))\n",
    "# print(\"action at frame {}: {}\".format(frame_to_display, actions[frame_to_display]))\n",
    "\n",
    "\n",
    "concatenated_frames = get_concatenated_frames(frames, frame_to_display, 1)\n",
    "\n",
    "\n",
    "show_observation(concatenated_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: action: 1, reward: 0.048347210662703616, max_logit: 0.045410964637994766\n",
      "   [ 0.01128595  0.04541096  0.02357616  0.00821735  0.01273965 -0.01368476]\n",
      "1: action: 1, reward: 0.04550777543972051, max_logit: 0.045667391270399094\n",
      "   [ 0.01158465  0.04566739  0.02252124  0.00610268  0.01435087 -0.01371086]\n",
      "2: action: 1, reward: 0.04261618833772425, max_logit: 0.04560745880007744\n",
      "   [ 0.01086898  0.04560746  0.02229788  0.00565034  0.01561813 -0.01148797]\n",
      "3: action: 1, reward: 0.03967149148366227, max_logit: 0.04501480236649513\n",
      "   [ 0.01188441  0.0450148   0.02318219  0.00882586  0.01312489 -0.010982  ]\n",
      "4: action: 1, reward: 0.036672709411237014, max_logit: 0.04463428258895874\n",
      "   [ 0.0137003   0.04463428  0.02254695  0.01008862  0.01245583 -0.01282846]\n",
      "5: action: 1, reward: 0.03361884873777097, max_logit: 0.044971682131290436\n",
      "   [ 0.01238697  0.04497168  0.02271958  0.00902745  0.01334035 -0.01330754]\n",
      "6: action: 1, reward: 0.030508897835136613, max_logit: 0.045667391270399094\n",
      "   [ 0.01158465  0.04566739  0.02252124  0.00610268  0.01435087 -0.01371086]\n",
      "7: action: 1, reward: 0.027341826494642583, max_logit: 0.04560745880007744\n",
      "   [ 0.01086898  0.04560746  0.02229788  0.00565034  0.01561813 -0.01148797]\n",
      "8: action: 1, reward: 0.024116585585764485, max_logit: 0.04526989907026291\n",
      "   [ 0.01218355  0.0452699   0.02212755  0.00671119  0.01473445 -0.01100697]\n",
      "9: action: 1, reward: 0.02083210670860785, max_logit: 0.04457567632198334\n",
      "   [ 0.01298595  0.04457568  0.02232519  0.0096374   0.01372661 -0.01060486]\n",
      "10: action: 1, reward: 0.017487301839987757, max_logit: 0.04463428258895874\n",
      "   [ 0.0137003   0.04463428  0.02254695  0.01008862  0.01245583 -0.01282846]\n",
      "11: action: 1, reward: 0.014081062973008074, max_logit: 0.04522772878408432\n",
      "   [ 0.01268575  0.04522773  0.0216648   0.00691271  0.0149522  -0.01333336]\n",
      "12: action: 1, reward: 0.010612261750020864, max_logit: 0.04560745880007744\n",
      "   [ 0.01086898  0.04560746  0.02229788  0.00565034  0.01561813 -0.01148797]\n",
      "13: action: 1, reward: 0.007079749088844239, max_logit: 0.04526989907026291\n",
      "   [ 0.01218355  0.0452699   0.02212755  0.00671119  0.01473445 -0.01100697]\n",
      "14: action: 1, reward: 0.003482354802115138, max_logit: 0.04457567632198334\n",
      "   [ 0.01298595  0.04457568  0.02232519  0.0096374   0.01372661 -0.01060486]\n",
      "15: action: 1, reward: -0.0001811127903493916, max_logit: 0.04463428258895874\n",
      "   [ 0.0137003   0.04463428  0.02254695  0.01008862  0.01245583 -0.01282846]\n",
      "16: action: 1, reward: -0.00391186725631055, max_logit: 0.044971682131290436\n",
      "   [ 0.01238697  0.04497168  0.02271958  0.00902745  0.01334035 -0.01330754]\n",
      "17: action: 1, reward: -0.0077111444531168015, max_logit: 0.045667391270399094\n",
      "   [ 0.01158465  0.04566739  0.02252124  0.00610268  0.01435087 -0.01371086]\n",
      "18: action: 1, reward: -0.01158020293709646, max_logit: 0.04560745880007744\n",
      "   [ 0.01086898  0.04560746  0.02229788  0.00565034  0.01561813 -0.01148797]\n",
      "19: action: 1, reward: -0.015520324380469614, max_logit: 0.04501480236649513\n",
      "   [ 0.01188441  0.0450148   0.02318219  0.00882586  0.01312489 -0.010982  ]\n",
      "20: action: 1, reward: -0.019532813995917494, max_logit: 0.04463428258895874\n",
      "   [ 0.0137003   0.04463428  0.02254695  0.01008862  0.01245583 -0.01282846]\n",
      "21: action: 1, reward: -0.02361900096894995, max_logit: 0.044971682131290436\n",
      "   [ 0.01238697  0.04497168  0.02271958  0.00902745  0.01334035 -0.01330754]\n",
      "22: action: 1, reward: -0.02778023889821404, max_logit: 0.045667391270399094\n",
      "   [ 0.01158465  0.04566739  0.02252124  0.00610268  0.01435087 -0.01371086]\n",
      "23: action: 1, reward: -0.032017906243890004, max_logit: 0.04560745880007744\n",
      "   [ 0.01086898  0.04560746  0.02229788  0.00565034  0.01561813 -0.01148797]\n",
      "24: action: 1, reward: -0.03633340678432271, max_logit: 0.04526989907026291\n",
      "   [ 0.01218355  0.0452699   0.02212755  0.00671119  0.01473445 -0.01100697]\n",
      "25: action: 1, reward: -0.040728170081040245, max_logit: 0.04457567632198334\n",
      "   [ 0.01298595  0.04457568  0.02232519  0.0096374   0.01372661 -0.01060486]\n",
      "26: action: 1, reward: -0.04520365195231327, max_logit: 0.04463428258895874\n",
      "   [ 0.0137003   0.04463428  0.02254695  0.01008862  0.01245583 -0.01282846]\n",
      "27: action: 1, reward: -0.049761334955412406, max_logit: 0.04522772878408432\n",
      "   [ 0.01268575  0.04522773  0.0216648   0.00691271  0.0149522  -0.01333336]\n",
      "28: action: 1, reward: -0.05440272887772322, max_logit: 0.04560745880007744\n",
      "   [ 0.01086898  0.04560746  0.02229788  0.00565034  0.01561813 -0.01148797]\n",
      "29: action: 1, reward: -0.059129371236881396, max_logit: 0.04526989907026291\n",
      "   [ 0.01218355  0.0452699   0.02212755  0.00671119  0.01473445 -0.01100697]\n",
      "30: action: 1, reward: -0.06394282779009411, max_logit: 0.04457567632198334\n",
      "   [ 0.01298595  0.04457568  0.02232519  0.0096374   0.01372661 -0.01060486]\n",
      "31: action: 1, reward: -0.06884469305281575, max_logit: 0.04463428258895874\n",
      "   [ 0.0137003   0.04463428  0.02254695  0.01008862  0.01245583 -0.01282846]\n",
      "32: action: 1, reward: -0.07383659082695058, max_logit: 0.044971682131290436\n",
      "   [ 0.01238697  0.04497168  0.02271958  0.00902745  0.01334035 -0.01330754]\n",
      "33: action: 1, reward: -0.07892017473875654, max_logit: 0.045667391270399094\n",
      "   [ 0.01158465  0.04566739  0.02252124  0.00610268  0.01435087 -0.01371086]\n",
      "34: action: 1, reward: -0.08409712878662892, max_logit: 0.04560745880007744\n",
      "   [ 0.01086898  0.04560746  0.02229788  0.00565034  0.01561813 -0.01148797]\n",
      "35: action: 1, reward: -0.08936916789894504, max_logit: 0.04501480236649513\n",
      "   [ 0.01188441  0.0450148   0.02318219  0.00882586  0.01312489 -0.010982  ]\n",
      "36: action: 1, reward: -0.09473803850215506, max_logit: 0.04463428258895874\n",
      "   [ 0.0137003   0.04463428  0.02254695  0.01008862  0.01245583 -0.01282846]\n",
      "37: action: 1, reward: -0.10020551909930667, max_logit: 0.044971682131290436\n",
      "   [ 0.01238697  0.04497168  0.02271958  0.00902745  0.01334035 -0.01330754]\n",
      "38: action: 1, reward: -0.10577342085919564, max_logit: 0.045667391270399094\n",
      "   [ 0.01158465  0.04566739  0.02252124  0.00610268  0.01435087 -0.01371086]\n",
      "39: action: 1, reward: -0.11144358821633735, max_logit: 0.04560745880007744\n",
      "   [ 0.01086898  0.04560746  0.02229788  0.00565034  0.01561813 -0.01148797]\n",
      "40: action: 1, reward: -0.11721789948195788, max_logit: 0.04526989907026291\n",
      "   [ 0.01218355  0.0452699   0.02212755  0.00671119  0.01473445 -0.01100697]\n",
      "41: action: 1, reward: -0.12309826746620732, max_logit: 0.04457567632198334\n",
      "   [ 0.01298595  0.04457568  0.02232519  0.0096374   0.01372661 -0.01060486]\n",
      "42: action: 1, reward: -0.12908664011180104, max_logit: 0.04463428258895874\n",
      "   [ 0.0137003   0.04463428  0.02254695  0.01008862  0.01245583 -0.01282846]\n",
      "43: action: 1, reward: -0.13518500113929932, max_logit: 0.03997807204723358\n",
      "   [ 0.01201928  0.03997807  0.0276588  -0.00016252  0.01746061 -0.01635364]\n",
      "44: action: 1, reward: -0.14139537070423852, max_logit: 0.03675463795661926\n",
      "   [ 0.01534355  0.03675464  0.02629447  0.00049804  0.01436624 -0.01435292]\n",
      "45: action: 1, reward: -0.14771980606633203, max_logit: 0.037284478545188904\n",
      "   [ 1.73243340e-02  3.72844785e-02  1.76401287e-02  1.17553682e-05\n",
      "  1.60288382e-02 -1.32538425e-02]\n",
      "46: action: 1, reward: -0.1541604022709624, max_logit: 0.03546961396932602\n",
      "   [ 0.014244    0.03546961  0.01296766  0.0034704   0.02016358 -0.00783388]\n",
      "47: action: 1, reward: -0.16071929284319003, max_logit: 0.033753901720047\n",
      "   [ 0.0181402   0.0337539   0.01371255  0.00331619  0.02149558 -0.00695804]\n",
      "48: action: 1, reward: -0.16739865049450953, max_logit: 0.03476272523403168\n",
      "   [ 0.01524616  0.03476273  0.01344347  0.0029675   0.02114463 -0.0072513 ]\n",
      "49: action: 1, reward: -0.1742006878425862, max_logit: 0.033756572753190994\n",
      "   [ 0.0143055   0.03375657  0.01255121  0.00231775  0.02338047 -0.00752789]\n",
      "50: action: 1, reward: -0.18112765814421242, max_logit: 0.0323815643787384\n",
      "   [ 0.01739017  0.03238156  0.01550391  0.00339742  0.0235285  -0.00678181]\n",
      "51: action: 1, reward: -0.188181856041726, max_logit: 0.03200855851173401\n",
      "   [ 0.01784468  0.03200856  0.01634432  0.00177763  0.02203419 -0.00447562]\n",
      "52: action: 1, reward: -0.19536561832313817, max_logit: 0.03492903336882591\n",
      "   [ 0.02066669  0.03492903  0.01592186  0.00428953  0.02182213 -0.00688037]\n",
      "53: action: 1, reward: -0.20268132469622294, max_logit: 0.03415556624531746\n",
      "   [ 0.01852879  0.03415557  0.01346299  0.00298233  0.02228046 -0.0058334 ]\n",
      "54: action: 1, reward: -0.21013139857682345, max_logit: 0.03563316538929939\n",
      "   [ 0.01799461  0.03563317  0.03083874  0.00695589  0.03302308 -0.0025995 ]\n",
      "55: action: 4, reward: -0.2177183078916382, max_logit: 0.044182781130075455\n",
      "   [-0.00089401  0.03808622  0.0275823   0.00551364  0.04418278  0.00586984]\n",
      "56: action: 4, reward: -0.22544456589575124, max_logit: 0.03876301646232605\n",
      "   [-0.00500741  0.0296624   0.01694185  0.01097695  0.03876302  0.00575761]\n",
      "57: action: 4, reward: -0.23331273200517808, max_logit: 0.040040429681539536\n",
      "   [-0.00565561  0.03030589  0.01813282  0.01155855  0.04004043  0.00457089]\n",
      "58: action: 4, reward: -0.24132541264470328, max_logit: 0.03600803762674332\n",
      "   [-0.00406883  0.02936106  0.02013767  0.0116292   0.03600804  0.00463195]\n",
      "59: action: 4, reward: -0.24948526211128996, max_logit: 0.03652027249336243\n",
      "   [-0.00741537  0.02868104  0.01496101  0.00593091  0.03652027  0.00313383]\n",
      "60: action: 4, reward: -0.25779498345334767, max_logit: 0.03821377083659172\n",
      "   [-0.0051663   0.03480063  0.02005667  0.01187719  0.03821377  0.00574283]\n",
      "61: action: 4, reward: -0.2662573293661497, max_logit: 0.03479621931910515\n",
      "   [-0.00670883  0.03228676  0.02448799  0.00801089  0.03479622  0.00154246]\n",
      "62: action: 1, reward: -0.2748751031036964, max_logit: 0.033295467495918274\n",
      "   [-0.00403915  0.03329547  0.01984751  0.01167199  0.03254288  0.00044684]\n",
      "63: action: 4, reward: -0.28365115940732716, max_logit: 0.0350232869386673\n",
      "   [-0.00738196  0.0309965   0.02319079  0.01222162  0.03502329  0.0024443 ]\n",
      "64: action: 4, reward: -0.29258840545138765, max_logit: 0.03488258272409439\n",
      "   [-7.3089404e-03  2.5091358e-02  1.5436852e-02  1.0920173e-02\n",
      "  3.4882583e-02  9.2004324e-05]\n",
      "65: action: 4, reward: -0.30168980180626626, max_logit: 0.03454476594924927\n",
      "   [-0.00490974  0.03377631  0.02378364  0.01630595  0.03454477  0.00230393]\n",
      "66: action: 1, reward: -0.31095836341911876, max_logit: 0.043228212743997574\n",
      "   [-0.00621858  0.04322821  0.04124296  0.02275943  0.02977837  0.00128984]\n",
      "67: action: 1, reward: -0.3203971606126061, max_logit: 0.042674072086811066\n",
      "   [-0.02242284  0.04267407  0.04220778  0.03158242  0.02960271  0.00135284]\n",
      "68: action: 1, reward: -0.3300093201019753, max_logit: 0.043903861194849014\n",
      "   [-0.01919892  0.04390386  0.04387057  0.03315683  0.02924967  0.00183763]\n",
      "69: action: 1, reward: -0.33979802603082215, max_logit: 0.045089319348335266\n",
      "   [-0.01742509  0.04508932  0.04091856  0.03194674  0.02933596  0.00128728]\n",
      "70: action: 1, reward: -0.3497665210258763, max_logit: 0.041965823620557785\n",
      "   [-0.01983718  0.04196582  0.03893419  0.03096436  0.03257456 -0.00239973]\n",
      "71: action: 1, reward: -0.35991810727116125, max_logit: 0.041261572390794754\n",
      "   [-0.02114401  0.04126157  0.03806427  0.03064126  0.02745481  0.00012468]\n",
      "72: action: 1, reward: -0.370256147601882, max_logit: 0.04134383797645569\n",
      "   [-0.01872352  0.04134384  0.0399165   0.03123191  0.03096123 -0.00251593]\n",
      "73: action: 1, reward: -0.380784066618405, max_logit: 0.04484765976667404\n",
      "   [-0.02214411  0.04484766  0.0373796   0.03210322  0.02845022 -0.002184  ]\n",
      "74: action: 1, reward: -0.3915053518206984, max_logit: 0.04208483546972275\n",
      "   [-0.02221152  0.04208484  0.03831745  0.03019664  0.02842678 -0.00386748]\n",
      "75: action: 2, reward: -0.4024235547636077, max_logit: 0.03956207260489464\n",
      "   [-0.02561373  0.03924482  0.03956207  0.03039278  0.02748893 -0.00507078]\n",
      "76: action: 2, reward: -0.4135422922333521, max_logit: 0.040783919394016266\n",
      "   [-0.01551794  0.03889194  0.04078392  0.02726979  0.02136889  0.00790823]\n",
      "77: action: 1, reward: -0.4248652474456276, max_logit: 0.03916751965880394\n",
      "   [-0.01319508  0.03916752  0.03665506  0.03428238  0.02151851  0.00424335]\n",
      "78: action: 1, reward: -0.43639617126571717, max_logit: 0.04320128262042999\n",
      "   [-0.00401784  0.04320128  0.02788925  0.03048084  0.01405305  0.00500828]\n",
      "79: action: 1, reward: -0.4481388834510096, max_logit: 0.04104239493608475\n",
      "   [-0.00899952  0.04104239  0.02541029  0.02993313  0.01532201  0.00255828]\n",
      "80: action: 1, reward: -0.4600972739163405, max_logit: 0.043557871133089066\n",
      "   [-0.00872897  0.04355787  0.02723317  0.03150944  0.01464208  0.00256251]\n",
      "81: action: 1, reward: -0.4722753040225731, max_logit: 0.04343289136886597\n",
      "   [-0.00805434  0.04343289  0.02780491  0.02965613  0.01431664  0.00063555]\n",
      "82: action: 1, reward: -0.4846770078888472, max_logit: 0.04255141317844391\n",
      "   [-0.01046163  0.04255141  0.02486677  0.03042613  0.01595999  0.00279847]\n",
      "83: action: 1, reward: -0.4973064937289292, max_logit: 0.04447618126869202\n",
      "   [-0.0088984   0.04447618  0.02878167  0.03060034  0.01482442  0.00142652]\n",
      "84: action: 1, reward: -0.5101679452121077, max_logit: 0.044095467776060104\n",
      "   [-0.00657949  0.04409547  0.02391546  0.0293266   0.01499862  0.00154415]\n",
      "85: action: 1, reward: -0.5232656228490845, max_logit: 0.04303127899765968\n",
      "   [-0.00902995  0.04303128  0.02817949  0.02825525  0.01603912  0.00039587]\n",
      "86: action: 1, reward: -0.5366038654033194, max_logit: 0.048740945756435394\n",
      "   [0.0013226  0.04874095 0.02376506 0.04491396 0.02969511 0.00236746]\n",
      "87: action: 1, reward: -0.5501870913282985, max_logit: 0.04733549803495407\n",
      "   [ 0.00547614  0.0473355   0.02708514  0.03714912  0.03137766 -0.01022207]\n",
      "88: action: 4, reward: -0.5640198002312001, max_logit: 0.049179837107658386\n",
      "   [ 0.00934092  0.04052077  0.02423923  0.03334878  0.04917984 -0.00111932]\n",
      "89: action: 4, reward: -0.5781065743634434, max_logit: 0.04876050725579262\n",
      "   [ 0.01364681  0.04511566  0.02828023  0.04279479  0.04876051 -0.00184829]\n",
      "90: action: 4, reward: -0.5924520801386148, max_logit: 0.05027611181139946\n",
      "   [ 0.01255883  0.04560333  0.02685937  0.03867289  0.05027611 -0.00010179]\n",
      "91: action: 4, reward: -0.6070610696782736, max_logit: 0.050073642283678055\n",
      "   [ 0.01625367  0.04298224  0.03118627  0.04292574  0.05007364 -0.00412927]\n",
      "92: action: 4, reward: -0.6219383823861487, max_logit: 0.05359213426709175\n",
      "   [ 0.01182457  0.04375975  0.02828381  0.04682409  0.05359213 -0.00048527]\n",
      "93: action: 4, reward: -0.637088946551251, max_logit: 0.052829816937446594\n",
      "   [0.01350538 0.04290452 0.02784004 0.04452281 0.05282982 0.00284753]\n",
      "94: action: 4, reward: -0.6525177809804269, max_logit: 0.04859873279929161\n",
      "   [0.01490319 0.04306181 0.02876873 0.04294901 0.04859873 0.0074472 ]\n",
      "95: action: 4, reward: -0.6682299966608993, max_logit: 0.051667094230651855\n",
      "   [0.01565639 0.03704118 0.03449351 0.04326417 0.05166709 0.0066598 ]\n",
      "96: action: 4, reward: -0.6842307984533434, max_logit: 0.047841351479291916\n",
      "   [0.02057251 0.03600327 0.02584774 0.03003225 0.04784135 0.00532386]\n",
      "97: action: 4, reward: -0.70052548681606, max_logit: 0.05083181709051132\n",
      "   [ 0.0098516   0.0264127   0.03557108  0.0371341   0.05083182 -0.00023813]\n",
      "98: action: 4, reward: -0.7171194595608149, max_logit: 0.04250525310635567\n",
      "   [-0.00205532  0.02201585  0.02789232  0.03133532  0.04250525 -0.00476035]\n",
      "99: action: 4, reward: -0.7340182136409311, max_logit: 0.04649289697408676\n",
      "   [-0.00571067  0.01927208  0.02794016  0.02154725  0.0464929  -0.00999832]\n",
      "100: action: 4, reward: -0.7512273469722188, max_logit: 0.04665333032608032\n",
      "   [-0.01158938  0.02020304  0.02410914  0.02315029  0.04665333 -0.01207704]\n",
      "101: action: 4, reward: -0.7687525602873531, max_logit: 0.047331005334854126\n",
      "   [-0.00961559  0.01754626  0.02644571  0.02420252  0.04733101 -0.01134858]\n",
      "102: action: 4, reward: -0.7865996590243107, max_logit: 0.0442693755030632\n",
      "   [-0.00731839  0.01827084  0.02668976  0.02234846  0.04426938 -0.01077596]\n",
      "103: action: 4, reward: -0.8047745552494916, max_logit: 0.04723985865712166\n",
      "   [-0.00565232  0.01288578  0.02780681  0.02611312  0.04723986 -0.01262719]\n",
      "104: action: 4, reward: -0.8232832696161604, max_logit: 0.048967014998197556\n",
      "   [-0.00721138  0.01326354  0.02997111  0.02373561  0.04896701 -0.01131807]\n",
      "105: action: 4, reward: -0.8421319333588623, max_logit: 0.048517610877752304\n",
      "   [-0.00622674  0.01464334  0.02635164  0.02300127  0.04851761 -0.0125832 ]\n",
      "106: action: 4, reward: -0.8613267903244674, max_logit: 0.047009263187646866\n",
      "   [-0.00744806  0.01417634  0.0261882   0.02384729  0.04700926 -0.01264886]\n",
      "107: action: 4, reward: -0.8808741990405197, max_logit: 0.052006322890520096\n",
      "   [ 0.00267308  0.00748919  0.02395237  0.02441311  0.05200632 -0.0174027 ]\n",
      "108: action: 4, reward: -0.9007806348215773, max_logit: 0.05597918480634689\n",
      "   [-0.0061673   0.01159023  0.02701016  0.02322656  0.05597918 -0.02076911]\n",
      "109: action: 4, reward: -0.9210526919142374, max_logit: 0.045900456607341766\n",
      "   [-0.00756568  0.01255     0.03171414  0.02380498  0.04590046 -0.01694068]\n",
      "110: action: 4, reward: -0.9416970856815595, max_logit: 0.04601682350039482\n",
      "   [-0.00474321  0.00523416  0.0281763   0.02898469  0.04601682 -0.02216814]\n",
      "111: action: 4, reward: -0.9627206548276114, max_logit: 0.0443667508661747\n",
      "   [-0.00738482  0.00742248  0.02613829  0.03091335  0.04436675 -0.02236657]\n",
      "112: action: 4, reward: -0.9841303636628714, max_logit: 0.04733840003609657\n",
      "   [-0.00486362  0.00990441  0.02646282  0.02967497  0.0473384  -0.02438659]\n",
      "113: action: 4, reward: -1.0059333044112404, max_logit: 0.046085551381111145\n",
      "   [-0.01095552  0.00919961  0.02814592  0.03123535  0.04608555 -0.0232998 ]\n",
      "114: action: 4, reward: -1.028136699559427, max_logit: 0.04535616561770439\n",
      "   [-0.01298323  0.00680229  0.02741869  0.03175213  0.04535617 -0.02009013]\n",
      "115: action: 4, reward: -1.0507479042494816, max_logit: 0.04627586901187897\n",
      "   [-0.00993665  0.00463435  0.03127401  0.02971395  0.04627587 -0.02538692]\n",
      "116: action: 4, reward: -1.0737744087152776, max_logit: 0.048524849116802216\n",
      "   [-0.00916538  0.00368424  0.03144382  0.02937585  0.04852485 -0.02363794]\n",
      "117: action: 4, reward: -1.097223840763741, max_logit: 0.048534709960222244\n",
      "   [-0.009213    0.00160958  0.02708271  0.03137409  0.04853471 -0.02293424]\n",
      "118: action: 4, reward: -1.121103968301652, max_logit: 0.04090157151222229\n",
      "   [-0.00875149  0.0102183   0.02286794  0.0266989   0.04090157 -0.01976136]\n",
      "119: action: 4, reward: -1.14542270190886, max_logit: 0.03268977254629135\n",
      "   [-0.01149387  0.02310374  0.02350444  0.01994498  0.03268977 -0.01614073]\n",
      "120: action: 4, reward: -1.1701880974587566, max_logit: 0.036661747843027115\n",
      "   [-0.01321843  0.02783247  0.02195302  0.0216066   0.03666175 -0.01974339]\n",
      "121: action: 2, reward: -1.1954083587868813, max_logit: 0.03739340603351593\n",
      "   [-0.01871914  0.03201715  0.03739341  0.02964668  0.02887644 -0.00526876]\n",
      "122: action: 2, reward: -1.2210918404085414, max_logit: 0.040321413427591324\n",
      "   [-0.02364396  0.03348321  0.04032141  0.02287219  0.03000574 -0.00722973]\n",
      "123: action: 1, reward: -1.2472470502863444, max_logit: 0.03386535868048668\n",
      "   [-0.02365728  0.03386536  0.0323925   0.02601466  0.0315557  -0.01009218]\n",
      "124: action: 2, reward: -1.273882652648565, max_logit: 0.03735213726758957\n",
      "   [-0.0202634   0.03356062  0.03735214  0.02731933  0.02671701 -0.00907395]\n",
      "125: action: 1, reward: -1.3010074708592727, max_logit: 0.03819555789232254\n",
      "   [-0.02876185  0.03819556  0.03241257  0.02587269  0.02848772 -0.00955081]\n",
      "126: action: 1, reward: -1.32863049034118, max_logit: 0.036343321204185486\n",
      "   [-0.02479105  0.03634332  0.03540312  0.02989808  0.02456964 -0.00918638]\n",
      "127: action: 1, reward: -1.3567608615521698, max_logit: 0.037314824759960175\n",
      "   [-0.02295142  0.03731482  0.03568727  0.03073676  0.02879372 -0.01375185]\n",
      "128: action: 2, reward: -1.3854079030164959, max_logit: 0.04032890498638153\n",
      "   [-0.02167433  0.03781299  0.0403289   0.02726627  0.01613584 -0.01495553]\n",
      "129: action: 1, reward: -1.4145811044116556, max_logit: 0.052664462476968765\n",
      "   [-0.02425254  0.05266446  0.03017081  0.02918604  0.01704369 -0.02935884]\n",
      "130: action: 1, reward: -1.444290129711961, max_logit: 0.044018782675266266\n",
      "   [-0.01797432  0.04401878  0.03682041  0.02555428  0.02166432 -0.02803884]\n",
      "131: action: 1, reward: -1.4745448203898452, max_logit: 0.046022702008485794\n",
      "   [-0.01952779  0.0460227   0.03218479  0.03084336  0.02510192 -0.02734969]\n",
      "132: action: 1, reward: -1.50535519867597, max_logit: 0.042542506009340286\n",
      "   [-0.01769139  0.04254251  0.03414632  0.02694536  0.02680068 -0.02311531]\n",
      "133: action: 1, reward: -1.5367314708792095, max_logit: 0.045710667967796326\n",
      "   [-0.02126433  0.04571067  0.03389379  0.02870988  0.02719425 -0.02481665]\n",
      "134: action: 1, reward: -1.5686840307676133, max_logit: 0.04494469612836838\n",
      "   [-0.01940426  0.0449447   0.03252454  0.02740501  0.02743253 -0.02511042]\n",
      "135: action: 1, reward: -1.6012234630114675, max_logit: 0.04424406588077545\n",
      "   [-0.01959291  0.04424407  0.03294803  0.02828174  0.02408083 -0.02659595]\n",
      "136: action: 1, reward: -1.6343605466895934, max_logit: 0.04377967119216919\n",
      "   [-0.01679405  0.04377967  0.03451859  0.02897333  0.02284116 -0.02728642]\n",
      "137: action: 1, reward: -1.6681062588600484, max_logit: 0.045078154653310776\n",
      "   [-0.02016056  0.04507815  0.03385769  0.03062353  0.02310928 -0.0282451 ]\n",
      "138: action: 1, reward: -1.7024717781964076, max_logit: 0.04127784073352814\n",
      "   [-0.01876839  0.04127784  0.03533157  0.02507383  0.02484539 -0.02580155]\n",
      "139: action: 2, reward: -1.737468488690835, max_logit: 0.04051944613456726\n",
      "   [-0.02323205  0.03855676  0.04051945  0.03930402  0.03328153 -0.02209898]\n",
      "140: action: 2, reward: -1.7731079834251668, max_logit: 0.04857699200510979\n",
      "   [-0.01887787  0.03513654  0.04857699  0.02977404  0.02761291 -0.02078298]\n",
      "141: action: 2, reward: -1.8094020684112608, max_logit: 0.04542926326394081\n",
      "   [-0.01101379  0.02457798  0.04542926  0.02921817  0.03693237 -0.00849748]\n",
      "142: action: 2, reward: -1.846362766501879, max_logit: 0.049673017114400864\n",
      "   [-0.00160052  0.02217981  0.04967302  0.02755614  0.03451036 -0.01727792]\n",
      "143: action: 2, reward: -1.884002321373402, max_logit: 0.04965531826019287\n",
      "   [-0.00488461  0.02409872  0.04965532  0.03080454  0.03276169 -0.0154801 ]\n",
      "144: action: 2, reward: -1.9223332015816965, max_logit: 0.04914700239896774\n",
      "   [-0.00327745  0.01935662  0.049147    0.03005008  0.03234773 -0.01526276]\n",
      "145: action: 2, reward: -1.9613681046924718, max_logit: 0.049498166888952255\n",
      "   [-0.00594048  0.02253225  0.04949817  0.03044011  0.03026985 -0.01731716]\n",
      "146: action: 2, reward: -2.0011199614875026, max_logit: 0.047855861485004425\n",
      "   [-0.00606601  0.02493707  0.04785586  0.03003624  0.02854245 -0.01527913]\n",
      "147: action: 2, reward: -2.0416019402481065, max_logit: 0.04618292301893234\n",
      "   [-0.00472222  0.0256291   0.04618292  0.02673576  0.02903173 -0.01635891]\n",
      "148: action: 2, reward: -2.082827451117296, max_logit: 0.04893288388848305\n",
      "   [-0.0063608   0.02504606  0.04893288  0.03014019  0.02863452 -0.01971046]\n",
      "149: action: 2, reward: -2.1248101505420482, max_logit: 0.045995719730854034\n",
      "   [-0.00650725  0.02536369  0.04599572  0.02599717  0.02877154 -0.01742971]\n",
      "150: action: 2, reward: -2.1675639457971694, max_logit: 0.045162633061409\n",
      "   [-0.01833683  0.02485967  0.04516263  0.01791161  0.02106133 -0.02285363]\n",
      "151: action: 2, reward: -2.211102999592246, max_logit: 0.04753785952925682\n",
      "   [-0.01887903  0.02222875  0.04753786  0.01596882  0.01637977 -0.01618885]\n",
      "152: action: 2, reward: -2.2554417347632136, max_logit: 0.04073939099907875\n",
      "   [-0.01896099  0.02424233  0.04073939  0.01581377  0.00549336 -0.03618613]\n",
      "153: action: 2, reward: -2.300594839050094, max_logit: 0.05692796781659126\n",
      "   [-0.01077807  0.02721     0.05692797  0.00940062  0.00435933 -0.03204998]\n",
      "154: action: 2, reward: -2.3465772699624865, max_logit: 0.053596705198287964\n",
      "   [-0.01020933  0.02612886  0.05359671  0.00652346  0.00117928 -0.03230038]\n",
      "155: action: 2, reward: -2.393404259734424, max_logit: 0.05349058285355568\n",
      "   [-0.00844788  0.02420742  0.05349058  0.00816549  0.00495324 -0.02758407]\n",
      "156: action: 2, reward: -2.441091320370232, max_logit: 0.0539303794503212\n",
      "   [-0.01027491  0.02490885  0.05393038  0.00555381 -0.00085808 -0.03006169]\n",
      "157: action: 2, reward: -2.489654248783068, max_logit: 0.05621559917926788\n",
      "   [-0.00605505  0.02257546  0.0562156   0.00770031  0.00439015 -0.03263807]\n",
      "158: action: 2, reward: -2.5391091320278414, max_logit: 0.05346296355128288\n",
      "   [-0.00989589  0.02540944  0.05346296  0.00628063  0.00269867 -0.03066215]\n",
      "159: action: 2, reward: -2.5894723526302394, max_logit: 0.054286327213048935\n",
      "   [-0.01150023  0.02374975  0.05428633  0.00717454  0.00360109 -0.03068357]\n",
      "160: action: 2, reward: -2.6407605940136394, max_logit: 0.06367617100477219\n",
      "   [-0.00128977  0.02166257  0.06367617  0.01086676 -0.00039713 -0.02914506]\n",
      "161: action: 2, reward: -2.692990846025693, max_logit: 0.04580272361636162\n",
      "   [-0.00360707  0.02290973  0.04580272  0.012954   -0.00318448 -0.04138109]\n",
      "162: action: 2, reward: -2.7461804105664185, max_logit: 0.06331469863653183\n",
      "   [-0.00238573  0.01731235  0.0633147   0.01028018  0.00487527 -0.04107421]\n",
      "163: action: 2, reward: -2.800346907319662, max_logit: 0.06172756850719452\n",
      "   [-0.01408953  0.01643046  0.06172757 -0.00120991  0.00153935 -0.03797468]\n",
      "164: action: 2, reward: -2.85550827958983, max_logit: 0.06226777285337448\n",
      "   [-0.01406046  0.01360652  0.06226777  0.0015965   0.00346248 -0.03948545]\n",
      "165: action: 2, reward: -2.911682800245828, max_logit: 0.06324891746044159\n",
      "   [-0.0123812   0.01362455  0.06324892  0.00382848  0.003878   -0.0368684 ]\n",
      "166: action: 2, reward: -2.9688890777741648, max_logit: 0.06232713162899017\n",
      "   [-0.01380741  0.01513903  0.06232713  0.00145901  0.00422455 -0.03695315]\n",
      "167: action: 2, reward: -3.0271460624432387, max_logit: 0.06336728483438492\n",
      "   [-0.01442482  0.01458432  0.06336728  0.00203712  0.00243958 -0.03561121]\n",
      "168: action: 2, reward: -3.086473052580845, max_logit: 0.06271537393331528\n",
      "   [-0.01409593  0.01270776  0.06271537  0.00181909  0.0034592  -0.0363846 ]\n",
      "169: action: 2, reward: -3.146889700966973, max_logit: 0.06278977543115616\n",
      "   [-0.01360383  0.01392246  0.06278978  0.00095377  0.00339379 -0.03692475]\n",
      "170: action: 2, reward: -3.208416021344035, max_logit: 0.062205471098423004\n",
      "   [-0.01298596  0.01323985  0.06220547  0.00219712  0.00359252 -0.03623333]\n",
      "171: action: 2, reward: -3.271072395046651, max_logit: 0.062141768634319305\n",
      "   [-0.02082011  0.01651067  0.06214177 -0.00432195  0.00494716 -0.03346706]\n",
      "172: action: 2, reward: -3.3348795777532176, max_logit: 0.06687762588262558\n",
      "   [-0.02012931  0.01657475  0.06687763 -0.00272245  0.00221823 -0.03068325]\n",
      "173: action: 2, reward: 0.21974340606436707, max_logit: 0.050069309771060944\n",
      "   [-0.02042682  0.01829351  0.05006931  0.00139151  0.00264644 -0.02916859]\n",
      "174: action: 2, reward: 0.22005200308862452, max_logit: 0.04318293184041977\n",
      "   [-0.01217365  0.01241483  0.04318293 -0.0074982   0.0024643  -0.0394585 ]\n",
      "175: action: 2, reward: 0.22036626811141297, max_logit: 0.04371219873428345\n",
      "   [-0.01109297  0.01385008  0.0437122  -0.0073909   0.00229859 -0.04156265]\n",
      "176: action: 2, reward: 0.22068630523680619, max_logit: 0.04358883947134018\n",
      "   [-0.01312556  0.01222554  0.04358884 -0.00816964  0.00332785 -0.03904177]\n",
      "177: action: 2, reward: 0.22101222048095628, max_logit: 0.044773317873477936\n",
      "   [-0.0126333   0.01243154  0.04477332 -0.00758328  0.0017077  -0.04014976]\n",
      "178: action: 2, reward: 0.2213441218072131, max_logit: 0.044145617634058\n",
      "   [-0.01228882  0.01321269  0.04414562 -0.00617328  0.0024239  -0.04214413]\n",
      "179: action: 2, reward: 0.2216821191618882, max_logit: 0.04365722835063934\n",
      "   [-0.01417414  0.01227366  0.04365723 -0.0081334   0.00336905 -0.04065151]\n",
      "180: action: 2, reward: 0.22202632451067608, max_logit: 0.04443372040987015\n",
      "   [-0.0122309   0.01311385  0.04443372 -0.00653364  0.00112402 -0.04179117]\n",
      "181: action: 2, reward: 0.2223768518757439, max_logit: 0.04379798471927643\n",
      "   [-0.01364682  0.01325472  0.04379798 -0.00727736  0.00324134 -0.04139194]\n",
      "182: action: 2, reward: 0.222733817373503, max_logit: 0.0442238487303257\n",
      "   [-0.01361023  0.01230921  0.04422385 -0.0085147   0.00276555 -0.03967096]\n",
      "183: action: 2, reward: 0.22309733925307365, max_logit: 0.044710878282785416\n",
      "   [-0.01172518  0.01324748  0.04471088 -0.00655445  0.00182    -0.04116431]\n",
      "184: action: 2, reward: 0.22346753793545657, max_logit: 0.04393358528614044\n",
      "   [-0.01366897  0.01240671  0.04393359 -0.00815321  0.00406486 -0.04002357]\n",
      "185: action: 2, reward: 0.22384453605342375, max_logit: 0.04457021877169609\n",
      "   [-0.01225359  0.01226619  0.04457022 -0.0074104   0.00194785 -0.04042217]\n",
      "186: action: 2, reward: 0.22422845849214218, max_logit: 0.044145617634058\n",
      "   [-0.01228882  0.01321269  0.04414562 -0.00617328  0.0024239  -0.04214413]\n",
      "187: action: 2, reward: 0.22461943243054358, max_logit: 0.04365722835063934\n",
      "   [-0.01417414  0.01227366  0.04365723 -0.0081334   0.00336905 -0.04065151]\n",
      "188: action: 2, reward: 0.22501758738345362, max_logit: 0.04443372040987015\n",
      "   [-0.0122309   0.01311385  0.04443372 -0.00653364  0.00112402 -0.04179117]\n",
      "189: action: 2, reward: 0.22542305524449577, max_logit: 0.04379798471927643\n",
      "   [-0.01364682  0.01325472  0.04379798 -0.00727736  0.00324134 -0.04139194]\n",
      "190: action: 2, reward: 0.22583597032978225, max_logit: 0.0442238487303257\n",
      "   [-0.01361023  0.01230921  0.04422385 -0.0085147   0.00276555 -0.03967096]\n",
      "191: action: 2, reward: 0.226256469422408, max_logit: 0.044710878282785416\n",
      "   [-0.01172518  0.01324748  0.04471088 -0.00655445  0.00182    -0.04116431]\n",
      "192: action: 2, reward: 0.22668469181776185, max_logit: 0.04393358528614044\n",
      "   [-0.01366897  0.01240671  0.04393359 -0.00815321  0.00406486 -0.04002357]\n",
      "193: action: 2, reward: 0.22712077936966948, max_logit: 0.04457021877169609\n",
      "   [-0.01225359  0.01226619  0.04457022 -0.0074104   0.00194785 -0.04042217]\n",
      "194: action: 2, reward: 0.22756487653738458, max_logit: 0.044145617634058\n",
      "   [-0.01228882  0.01321269  0.04414562 -0.00617328  0.0024239  -0.04214413]\n",
      "195: action: 2, reward: 0.22801713043344243, max_logit: 0.04365722835063934\n",
      "   [-0.01417414  0.01227366  0.04365723 -0.0081334   0.00336905 -0.04065151]\n",
      "196: action: 2, reward: 0.22847769087239286, max_logit: 0.04443372040987015\n",
      "   [-0.0122309   0.01311385  0.04443372 -0.00653364  0.00112402 -0.04179117]\n",
      "197: action: 2, reward: 0.2289467104204281, max_logit: 0.04379798471927643\n",
      "   [-0.01364682  0.01325472  0.04379798 -0.00727736  0.00324134 -0.04139194]\n",
      "198: action: 2, reward: 0.22942434444592205, max_logit: 0.0442238487303257\n",
      "   [-0.01361023  0.01230921  0.04422385 -0.0085147   0.00276555 -0.03967096]\n",
      "199: action: 2, reward: 0.22991075117089813, max_logit: 0.044710878282785416\n",
      "   [-0.01172518  0.01324748  0.04471088 -0.00655445  0.00182    -0.04116431]\n",
      "200: action: 2, reward: 0.230406091723442, max_logit: 0.04393358528614044\n",
      "   [-0.01366897  0.01240671  0.04393359 -0.00815321  0.00406486 -0.04002357]\n",
      "201: action: 2, reward: 0.23091053019107743, max_logit: 0.04457021877169609\n",
      "   [-0.01225359  0.01226619  0.04457022 -0.0074104   0.00194785 -0.04042217]\n",
      "202: action: 2, reward: 0.23142423367512197, max_logit: 0.044145617634058\n",
      "   [-0.01228882  0.01321269  0.04414562 -0.00617328  0.0024239  -0.04214413]\n",
      "203: action: 2, reward: 0.23194737234604162, max_logit: 0.04365722835063934\n",
      "   [-0.01417414  0.01227366  0.04365723 -0.0081334   0.00336905 -0.04065151]\n",
      "204: action: 2, reward: 0.23248011949982156, max_logit: 0.04443372040987015\n",
      "   [-0.0122309   0.01311385  0.04443372 -0.00653364  0.00112402 -0.04179117]\n",
      "205: action: 2, reward: 0.2330226516153726, max_logit: 0.04379798471927643\n",
      "   [-0.01364682  0.01325472  0.04379798 -0.00727736  0.00324134 -0.04139194]\n",
      "206: action: 2, reward: 0.23357514841299215, max_logit: 0.0442238487303257\n",
      "   [-0.01361023  0.01230921  0.04422385 -0.0085147   0.00276555 -0.03967096]\n",
      "207: action: 2, reward: 0.23413779291389838, max_logit: 0.044710878282785416\n",
      "   [-0.01172518  0.01324748  0.04471088 -0.00655445  0.00182    -0.04116431]\n",
      "208: action: 2, reward: 0.23471077150085842, max_logit: 0.04393358528614044\n",
      "   [-0.01366897  0.01240671  0.04393359 -0.00815321  0.00406486 -0.04002357]\n",
      "209: action: 2, reward: 0.23529427397992997, max_logit: 0.04457021877169609\n",
      "   [-0.01225359  0.01226619  0.04457022 -0.0074104   0.00194785 -0.04042217]\n",
      "210: action: 2, reward: 0.2358884936433367, max_logit: 0.044145617634058\n",
      "   [-0.01228882  0.01321269  0.04414562 -0.00617328  0.0024239  -0.04214413]\n",
      "211: action: 2, reward: 0.2364936273334986, max_logit: 0.04365722835063934\n",
      "   [-0.01417414  0.01227366  0.04365723 -0.0081334   0.00336905 -0.04065151]\n",
      "212: action: 2, reward: 0.23710987550823848, max_logit: 0.04443372040987015\n",
      "   [-0.0122309   0.01311385  0.04443372 -0.00653364  0.00112402 -0.04179117]\n",
      "213: action: 2, reward: 0.2377374423071861, max_logit: 0.04379798471927643\n",
      "   [-0.01364682  0.01325472  0.04379798 -0.00727736  0.00324134 -0.04139194]\n",
      "214: action: 2, reward: 0.23837653561940172, max_logit: 0.0442238487303257\n",
      "   [-0.01361023  0.01230921  0.04422385 -0.0085147   0.00276555 -0.03967096]\n",
      "215: action: 2, reward: 0.239027367152242, max_logit: 0.04279368370771408\n",
      "   [-0.00928198  0.015617    0.04279368 -0.01021601  0.00372767 -0.03892477]\n",
      "216: action: 2, reward: 0.2396901525014905, max_logit: 0.041156526654958725\n",
      "   [-0.01029873  0.01673565  0.04115653 -0.01336727  0.00421641 -0.0370857 ]\n",
      "217: action: 2, reward: 0.24036511122277648, max_logit: 0.043124258518218994\n",
      "   [-0.00705196  0.01763297  0.04312426 -0.00949285  0.00389284 -0.03550293]\n",
      "218: action: 2, reward: 0.24105246690430532, max_logit: 0.04448975995182991\n",
      "   [-0.00753845  0.01946064  0.04448976 -0.00685866  0.00289396 -0.0357764 ]\n",
      "219: action: 2, reward: 0.24175244724092468, max_logit: 0.044710658490657806\n",
      "   [-0.00682876  0.01952811  0.04471066 -0.00639919  0.00161963 -0.03800749]\n",
      "220: action: 2, reward: 0.24246528410955132, max_logit: 0.04486813396215439\n",
      "   [-0.0081553   0.01987375  0.04486813 -0.00748946  0.00248536 -0.0384938 ]\n",
      "221: action: 2, reward: 0.24319121364598315, max_logit: 0.044667623937129974\n",
      "   [-0.0089514   0.02055453  0.04466762 -0.01041026  0.0034929  -0.03890076]\n",
      "222: action: 2, reward: 0.24393047632312176, max_logit: 0.04444500803947449\n",
      "   [-0.00966135  0.02048591  0.04444501 -0.01086973  0.00476494 -0.03667026]\n",
      "223: action: 2, reward: 0.24468331703063245, max_logit: 0.04534391686320305\n",
      "   [-0.00864884  0.01988732  0.04534392 -0.00766389  0.00229443 -0.03614934]\n",
      "224: action: 2, reward: 0.24544998515606645, max_logit: 0.044710658490657806\n",
      "   [-0.00682876  0.01952811  0.04471066 -0.00639919  0.00161963 -0.03800749]\n",
      "225: action: 2, reward: 0.24623073466747367, max_logit: 0.04486813396215439\n",
      "   [-0.0081553   0.01987375  0.04486813 -0.00748946  0.00248536 -0.0384938 ]\n",
      "226: action: 2, reward: 0.2470258241975328, max_logit: 0.044667623937129974\n",
      "   [-0.0089514   0.02055453  0.04466762 -0.01041026  0.0034929  -0.03890076]\n",
      "227: action: 2, reward: 0.2478355171292264, max_logit: 0.04444500803947449\n",
      "   [-0.00966135  0.02048591  0.04444501 -0.01086973  0.00476494 -0.03667026]\n",
      "228: action: 2, reward: 0.24866008168308967, max_logit: 0.0442899689078331\n",
      "   [-0.00833593  0.02014031  0.04428997 -0.00978092  0.0038999  -0.03618243]\n",
      "229: action: 2, reward: 0.24949979100606182, max_logit: 0.04448975995182991\n",
      "   [-0.00753845  0.01946064  0.04448976 -0.00685866  0.00289396 -0.0357764 ]\n",
      "230: action: 2, reward: 0.2503549232619691, max_logit: 0.044710658490657806\n",
      "   [-0.00682876  0.01952811  0.04471066 -0.00639919  0.00161963 -0.03800749]\n",
      "231: action: 2, reward: 0.2512257617236702, max_logit: 0.04381345212459564\n",
      "   [-0.00784201  0.02012705  0.04381345 -0.00960572  0.00409195 -0.03852712]\n",
      "232: action: 2, reward: 0.2521125948668935, max_logit: 0.04444500803947449\n",
      "   [-0.00966135  0.02048591  0.04444501 -0.01086973  0.00476494 -0.03667026]\n",
      "233: action: 2, reward: 0.25301571646579846, max_logit: 0.0442899689078331\n",
      "   [-0.00833593  0.02014031  0.04428997 -0.00978092  0.0038999  -0.03618243]\n",
      "234: action: 2, reward: 0.25393542569029137, max_logit: 0.04448975995182991\n",
      "   [-0.00753845  0.01946064  0.04448976 -0.00685866  0.00289396 -0.0357764 ]\n",
      "235: action: 2, reward: 0.25487202720512947, max_logit: 0.044710658490657806\n",
      "   [-0.00682876  0.01952811  0.04471066 -0.00639919  0.00161963 -0.03800749]\n",
      "236: action: 2, reward: 0.25582583127084463, max_logit: 0.028140444308519363\n",
      "   [-0.00514584  0.01695853  0.02814044 -0.00958842  0.01182425 -0.0457101 ]\n",
      "237: action: 4, reward: 0.25679715384652074, max_logit: 0.020439621061086655\n",
      "   [-0.00097672  0.01864371  0.01808094 -0.00253215  0.02043962 -0.03810127]\n",
      "238: action: 1, reward: 0.2577863166944592, max_logit: 0.025006506592035294\n",
      "   [-0.00177467  0.02500651  0.02384139 -0.00470056  0.01636359 -0.05335874]\n",
      "239: action: 4, reward: 0.25879364748676653, max_logit: 0.024002844467759132\n",
      "   [-0.01133873  0.0216215   0.01340276 -0.00343185  0.02400284 -0.04941477]\n",
      "240: action: 4, reward: 0.2598194799138995, max_logit: 0.02668139338493347\n",
      "   [-0.01370222  0.02116721  0.01271118 -0.00526477  0.02668139 -0.04634484]\n",
      "241: action: 4, reward: 0.2608641537952042, max_logit: 0.025412490591406822\n",
      "   [-0.01183144  0.01725383  0.00836218 -0.0074251   0.02541249 -0.04939932]\n",
      "242: action: 4, reward: 0.2619280151914855, max_logit: 0.02360575459897518\n",
      "   [-0.0107609   0.02059016  0.01586172 -0.00684422  0.02360575 -0.04836595]\n",
      "243: action: 4, reward: 0.2630114165196436, max_logit: 0.02104351669549942\n",
      "   [-0.008592    0.01873544  0.01563084 -0.00682285  0.02104352 -0.04917156]\n",
      "244: action: 1, reward: 0.2641147166694164, max_logit: 0.022112799808382988\n",
      "   [-0.00866014  0.0221128   0.01637517 -0.0030867   0.01970953 -0.05167696]\n",
      "245: action: 4, reward: 0.2652382811222663, max_logit: 0.02236352488398552\n",
      "   [-0.01463896  0.02127882  0.01555063 -0.0085754   0.02236352 -0.04681278]\n",
      "246: action: 1, reward: -0.565483314076279, max_logit: 0.023566395044326782\n",
      "   [-0.01493189  0.0235664   0.01818309 -0.00715014  0.02318224 -0.04809107]\n",
      "247: action: 2, reward: -0.5795969685530237, max_logit: 0.023533495143055916\n",
      "   [-0.01512585  0.02074788  0.0235335   0.0020242   0.01624399 -0.03650329]\n",
      "248: action: 2, reward: -0.5939698483837214, max_logit: 0.021335292607545853\n",
      "   [-0.03374919  0.01754422  0.02133529  0.00135219  0.0173556  -0.01388111]\n",
      "249: action: 1, reward: -0.6086067147579167, max_logit: 0.02075633779168129\n",
      "   [-0.03544567  0.02075634  0.0163816  -0.00544692  0.0126667   0.0007415 ]\n",
      "250: action: 2, reward: -0.6235124163138764, max_logit: 0.024775441735982895\n",
      "   [-0.03909048  0.02332154  0.02477544 -0.00087508  0.00834279  0.00648767]\n",
      "251: action: 2, reward: -0.6386918907447586, max_logit: 0.025887126103043556\n",
      "   [-0.03892424  0.02261198  0.02588713  0.00066615  0.01047453  0.00919352]\n",
      "252: action: 1, reward: -0.6541501664342838, max_logit: 0.02800392545759678\n",
      "   [-0.03910556  0.02800393  0.0250499   0.00583835  0.01094736  0.00287973]\n",
      "253: action: 1, reward: -0.6698923641224468, max_logit: 0.025535503402352333\n",
      "   [-0.03665263  0.0255355   0.02361762  0.0052855   0.00983669  0.00228378]\n",
      "254: action: 1, reward: -0.6859236986018238, max_logit: 0.030811483040452003\n",
      "   [-0.03071077  0.03081148  0.02526914  0.0013504   0.0096672   0.00034647]\n",
      "255: action: 1, reward: -0.7022494804450361, max_logit: 0.025767523795366287\n",
      "   [-0.03242646  0.02576752  0.02374585  0.0011561   0.01152426 -0.00322699]\n",
      "256: action: 1, reward: -0.7188751177639398, max_logit: 0.02499948814511299\n",
      "   [-0.0333686   0.02499949  0.02067948  0.00056229  0.01169433 -0.00068479]\n",
      "257: action: 1, reward: -0.7358061180011285, max_logit: 0.019483881071209908\n",
      "   [-0.03574917  0.01948388  0.01795701  0.00129179  0.00958119 -0.00293407]\n",
      "258: action: 1, reward: -0.7530480897543409, max_logit: 0.024984441697597504\n",
      "   [-0.03207828  0.02498444  0.01899265  0.00591374  0.01117627 -0.00498226]\n",
      "259: action: 1, reward: -0.7706067446343747, max_logit: 0.035930510610342026\n",
      "   [-0.03499593  0.03593051  0.03264932 -0.00067741  0.01036102 -0.01036504]\n",
      "260: action: 1, reward: -0.7884878991571278, max_logit: 0.04076407477259636\n",
      "   [-0.01515276  0.04076407  0.03685698 -0.00760231  0.01486208 -0.01578292]\n",
      "261: action: 1, reward: -0.8066974766703894, max_logit: 0.03930889815092087\n",
      "   [-0.01077084  0.0393089   0.02774186 -0.00186227  0.02051769 -0.0319257 ]\n",
      "262: action: 1, reward: -0.8252415093160183, max_logit: 0.040408968925476074\n",
      "   [-0.00945472  0.04040897  0.02894887 -0.00148058  0.02006103 -0.03130509]\n",
      "263: action: 1, reward: -0.8441261400281652, max_logit: 0.03910810127854347\n",
      "   [-0.00783634  0.0391081   0.03039075 -0.00456506  0.02417069 -0.02928924]\n",
      "264: action: 1, reward: -0.8633576245681914, max_logit: 0.038801733404397964\n",
      "   [-0.00726894  0.03880173  0.02983791 -0.00352333  0.0203501  -0.03014307]\n",
      "265: action: 1, reward: -0.8829423335969672, max_logit: 0.036202628165483475\n",
      "   [-0.00755182  0.03620263  0.02945695 -0.00415374  0.02194203 -0.02996737]\n",
      "266: action: 1, reward: -0.9028867547852276, max_logit: 0.036429859697818756\n",
      "   [-0.0076284   0.03642986  0.02852954 -0.00227214  0.0231512  -0.03205449]\n",
      "267: action: 1, reward: -0.9231974949626933, max_logit: 0.03759177774190903\n",
      "   [-0.00337461  0.03759178  0.0286069  -0.00374806  0.02193162 -0.03053788]\n",
      "268: action: 4, reward: -0.9438812823066624, max_logit: 0.033773817121982574\n",
      "   [-0.00643099  0.0326215   0.03123101 -0.00926687  0.03377382 -0.03102158]\n",
      "269: action: 4, reward: -0.9649449685707985, max_logit: 0.028418926522135735\n",
      "   [ 0.00205154  0.02334804  0.02804846 -0.01122217  0.02841893 -0.03401376]\n",
      "270: action: 1, reward: -0.9863955313548588, max_logit: 0.027361590415239334\n",
      "   [ 0.00716077  0.02736159  0.02555475 -0.01308306  0.02066025 -0.02439311]\n",
      "271: action: 1, reward: -1.0082400764161072, max_logit: 0.029811130836606026\n",
      "   [-0.0060465   0.02981113  0.01245633 -0.00975408  0.01962307 -0.01699104]\n",
      "272: action: 1, reward: -1.030485840023181, max_logit: 0.026858804747462273\n",
      "   [-0.00642008  0.0268588   0.01780486 -0.00833711  0.02161475 -0.01625402]\n",
      "273: action: 1, reward: -1.053140191353194, max_logit: 0.030213015154004097\n",
      "   [-0.00732947  0.03021302  0.01493457 -0.00953404  0.01843609 -0.01898216]\n",
      "274: action: 1, reward: -1.076210634932863, max_logit: 0.029463991522789\n",
      "   [-0.00280907  0.02946399  0.01732692 -0.01008338  0.0190989  -0.01568142]\n",
      "275: action: 1, reward: -1.0997048131244747, max_logit: 0.031132632866501808\n",
      "   [-0.00462813  0.03113263  0.01701022 -0.0079062   0.01658425 -0.01582607]\n",
      "276: action: 1, reward: -1.1236305086575085, max_logit: 0.0283673033118248\n",
      "   [-0.0069567   0.0283673   0.0177019  -0.00753778  0.01768201 -0.01648648]\n",
      "277: action: 1, reward: -1.1479956472067605, max_logit: 0.030915459617972374\n",
      "   [-0.004943    0.03091546  0.01758584 -0.00751181  0.02014761 -0.01589556]\n",
      "278: action: 1, reward: -1.1728083000178187, max_logit: 0.028566213324666023\n",
      "   [-0.00498145  0.02856621  0.01671679 -0.00778999  0.01813763 -0.0158317 ]\n",
      "279: action: 1, reward: -1.198076686580759, max_logit: 0.029838530346751213\n",
      "   [-0.01018474  0.02983853  0.02332672 -0.01256277  0.02173139 -0.01007721]\n",
      "280: action: 1, reward: -1.223809177352953, max_logit: 0.03661453723907471\n",
      "   [-0.02071869  0.03661454  0.01943229 -0.00614377  0.02793943 -0.00337526]\n",
      "281: action: 1, reward: -1.250014296531879, max_logit: 0.03291930630803108\n",
      "   [-0.03133627  0.03291931  0.0089416  -0.00645548  0.02809061 -0.00624119]\n",
      "282: action: 1, reward: -1.2767007248788687, max_logit: 0.03432949259877205\n",
      "   [-0.02477045  0.03432949  0.01127439 -0.00109596  0.03053075 -0.00508929]\n",
      "283: action: 1, reward: -2.1357430987434407, max_logit: 0.03426603600382805\n",
      "   [-0.02416533  0.03426604  0.01232895 -0.00532964  0.02817814 -0.00374209]\n",
      "284: action: 1, reward: -2.1786976993514156, max_logit: 0.03584212809801102\n",
      "   [-0.02951562  0.03584213  0.01111302  0.00188691  0.02868186 -0.00356067]\n",
      "285: action: 1, reward: -2.2224412466893004, max_logit: 0.03635338321328163\n",
      "   [-2.5320036e-02  3.6353383e-02  1.2700082e-02  6.7219582e-05\n",
      "  3.1026516e-02 -8.7189693e-03]\n",
      "286: action: 1, reward: -2.2669882313339804, max_logit: 0.03309269994497299\n",
      "   [-0.02185652  0.0330927   0.01002337  0.00014976  0.0272774  -0.00507328]\n",
      "287: action: 1, reward: -2.3123534100106236, max_logit: 0.037803295999765396\n",
      "   [-0.02934696  0.0378033   0.00763322  0.00279618  0.02035801 -0.00598169]\n",
      "288: action: 1, reward: -2.3585518104810244, max_logit: 0.03309813514351845\n",
      "   [-0.02789845  0.03309814  0.01137613  0.00362476  0.02328073 -0.01173602]\n",
      "289: action: 1, reward: -2.405598736521733, max_logit: 0.035859521478414536\n",
      "   [-0.02839237  0.03585952  0.00582618  0.00127244  0.02478157 -0.0092359 ]\n",
      "290: action: 1, reward: 1.1660923394322251, max_logit: 0.03569807857275009\n",
      "   [-0.02374342  0.03569808  0.00637438 -0.00115391  0.02715843 -0.00689777]\n",
      "291: action: 1, reward: 1.1837825180744534, max_logit: 0.03212002292275429\n",
      "   [-2.9356729e-02  3.2120023e-02  5.2089482e-03  9.4730502e-05\n",
      "  2.7437655e-02 -3.0117428e-03]\n",
      "292: action: 1, reward: 1.201797612055057, max_logit: 0.03234401345252991\n",
      "   [-0.02579527  0.03234401  0.00586703  0.00297927  0.02478912 -0.00773238]\n",
      "293: action: 1, reward: 1.2201435890908834, max_logit: 0.03710697963833809\n",
      "   [-0.02477895  0.03710698  0.00389896  0.00037638  0.02304018 -0.00357345]\n",
      "294: action: 4, reward: 0.4069607303590472, max_logit: 0.02904350869357586\n",
      "   [-0.01835126  0.02808885  0.0082082   0.00027003  0.02904351 -0.00347076]\n",
      "295: action: 4, reward: 0.41070794615042827, max_logit: 0.029406465590000153\n",
      "   [-0.01662963  0.02802021  0.00264155 -0.00298218  0.02940647 -0.0074193 ]\n",
      "296: action: 4, reward: 0.4145239870176576, max_logit: 0.032453857362270355\n",
      "   [-0.01518962  0.03089064  0.0080474   0.00054599  0.03245386 -0.00811084]\n",
      "297: action: 4, reward: 0.4184101170702313, max_logit: 0.0346628837287426\n",
      "   [-0.01996254  0.02924683  0.00858189  0.00079833  0.03466288 -0.00920341]\n",
      "298: action: 1, reward: 0.42236762363553215, max_logit: 0.033717989921569824\n",
      "   [-0.0199808   0.03371799  0.00996863  0.00247121  0.03039159 -0.0078926 ]\n",
      "299: action: 4, reward: 0.42639781768527246, max_logit: 0.03358879312872887\n",
      "   [-0.02032896  0.03121596  0.0101713   0.00287741  0.03358879 -0.00858867]\n",
      "300: action: 1, reward: 0.4305020342697691, max_logit: 0.030030271038413048\n",
      "   [-0.02204623  0.03003027  0.00703434  0.00037638  0.0278842  -0.00819003]\n",
      "301: action: 4, reward: 0.43468163296019496, max_logit: 0.0307838786393404\n",
      "   [-0.02053269  0.0301128   0.00541787 -0.00010722  0.03078388 -0.0120436 ]\n",
      "302: action: 1, reward: 0.43893799829895375, max_logit: 0.030713511630892754\n",
      "   [-0.01808141  0.03071351  0.00548571 -0.00189687  0.02865728 -0.01166596]\n",
      "303: action: 1, reward: 0.4432725402583256, max_logit: 0.032323479652404785\n",
      "   [-0.01828256  0.03232348  0.0040982   0.00168744  0.02892931 -0.00646437]\n",
      "304: action: 1, reward: 0.4476866947075381, max_logit: 0.030850673094391823\n",
      "   [-0.01551556  0.03085067  0.00774253 -0.00135986  0.02878909 -0.00688849]\n",
      "305: action: 4, reward: 0.45218192388841455, max_logit: 0.030598871409893036\n",
      "   [-0.01884652  0.02992457  0.00838144  0.00110946  0.03059887 -0.00583245]\n",
      "306: action: 1, reward: 0.45675971689975975, max_logit: 0.030655764043331146\n",
      "   [-0.01671183  0.03065576  0.00711742 -0.00131017  0.02963549 -0.00690713]\n",
      "307: action: 1, reward: 0.4614215901906417, max_logit: 0.03212287649512291\n",
      "   [-0.01775811  0.03212288  0.00856927  0.00028823  0.03088347 -0.00665625]\n",
      "308: action: 4, reward: 0.46616908806273355, max_logit: 0.029978547245264053\n",
      "   [-0.01777492  0.02851409  0.00458045  0.00168531  0.02997855 -0.00390258]\n",
      "309: action: 1, reward: 0.47100378318188235, max_logit: 0.03208019584417343\n",
      "   [-0.01619019  0.0320802   0.00657501 -0.00110792  0.03052301 -0.00574006]\n",
      "310: action: 4, reward: 0.47592727709907323, max_logit: 0.030933069065213203\n",
      "   [-0.01799254  0.0292388   0.00877384 -0.00051798  0.03093307 -0.00474929]\n",
      "311: action: 4, reward: 0.48094120078096275, max_logit: 0.0306610818952322\n",
      "   [-0.01632589  0.02761155  0.00257763  0.0011263   0.03066108 -0.00509645]\n",
      "312: action: 1, reward: 0.4860472151501561, max_logit: 0.031417135149240494\n",
      "   [-0.01795349  0.03141714  0.00974204  0.00017504  0.02979477 -0.00606394]\n",
      "313: action: 4, reward: 0.4912470116354075, max_logit: 0.030935218557715416\n",
      "   [-0.01800794  0.02796431  0.00697609  0.00069469  0.03093522 -0.00533246]\n",
      "314: action: 4, reward: 0.4965423127319271, max_logit: 0.02997194044291973\n",
      "   [-0.01801842  0.02964794  0.00562431  0.0003263   0.02997194 -0.00513139]\n",
      "315: action: 4, reward: 0.5019348725719772, max_logit: 0.030200334265828133\n",
      "   [-0.01690099  0.02979666  0.00720731  0.00043305  0.03020033 -0.00515021]\n",
      "316: action: 4, reward: 0.5074264775059506, max_logit: 0.029722239822149277\n",
      "   [-0.01855318  0.0292198   0.00500618  0.00081195  0.02972224 -0.00439295]\n",
      "317: action: 1, reward: 0.5130189466941202, max_logit: 0.03029533475637436\n",
      "   [-1.7215123e-02  3.0295335e-02  6.3799033e-03  5.4261396e-05\n",
      "  3.0148940e-02 -6.2334598e-03]\n",
      "318: action: 4, reward: 0.5187141327092579, max_logit: 0.03086596541106701\n",
      "   [-0.01775465  0.02920885  0.00696198  0.00034459  0.03086597 -0.00511124]\n",
      "319: action: 4, reward: 0.5245139221503216, max_logit: 0.03025134466588497\n",
      "   [-1.8491004e-02  2.9206505e-02  4.8707644e-03 -9.8621960e-05\n",
      "  3.0251345e-02 -4.7084969e-03]\n",
      "320: action: 4, reward: 0.5304202362674136, max_logit: 0.03082517348229885\n",
      "   [-1.7295107e-02  2.9854700e-02  7.6474654e-03 -7.8390840e-05\n",
      "  3.0825173e-02 -5.8358749e-03]\n",
      "321: action: 4, reward: 0.5364350315982186, max_logit: 0.03039865382015705\n",
      "   [-0.01863358  0.0287791   0.00627383  0.00068088  0.03039865 -0.00399569]\n",
      "322: action: 1, reward: 0.5425603006161293, max_logit: 0.029866205528378487\n",
      "   [-0.01809429  0.02986621  0.00569091  0.00038893  0.02968195 -0.00511847]\n",
      "323: action: 4, reward: 0.5487980723902781, max_logit: 0.03029688075184822\n",
      "   [-0.01735748  0.02986834  0.00778256  0.000832    0.03029688 -0.00552182]\n",
      "324: action: 4, reward: 0.5551504132576902, max_logit: 0.029722239822149277\n",
      "   [-0.01855318  0.0292198   0.00500618  0.00081195  0.02972224 -0.00439295]\n",
      "325: action: 1, reward: 0.5616194275077828, max_logit: 0.03029533475637436\n",
      "   [-1.7215123e-02  3.0295335e-02  6.3799033e-03  5.4261396e-05\n",
      "  3.0148940e-02 -6.2334598e-03]\n",
      "326: action: 4, reward: 0.5682072580794363, max_logit: 0.03086596541106701\n",
      "   [-0.01775465  0.02920885  0.00696198  0.00034459  0.03086597 -0.00511124]\n",
      "327: action: 4, reward: 0.5749160872708684, max_logit: 0.03025134466588497\n",
      "   [-1.8491004e-02  2.9206505e-02  4.8707644e-03 -9.8621960e-05\n",
      "  3.0251345e-02 -4.7084969e-03]\n",
      "328: action: 4, reward: 0.581748137462547, max_logit: 0.03082517348229885\n",
      "   [-1.7295107e-02  2.9854700e-02  7.6474654e-03 -7.8390840e-05\n",
      "  3.0825173e-02 -5.8358749e-03]\n",
      "329: action: 4, reward: 0.5887056718533806, max_logit: 0.03039865382015705\n",
      "   [-0.01863358  0.0287791   0.00627383  0.00068088  0.03039865 -0.00399569]\n",
      "330: action: 1, reward: 0.5957909952104297, max_logit: 0.029866205528378487\n",
      "   [-0.01809429  0.02986621  0.00569091  0.00038893  0.02968195 -0.00511847]\n",
      "331: action: 4, reward: 0.6030064546323888, max_logit: 0.03029688075184822\n",
      "   [-0.01735748  0.02986834  0.00778256  0.000832    0.03029688 -0.00552182]\n",
      "332: action: 1, reward: 0.6103544403270912, max_logit: 0.03143813833594322\n",
      "   [-0.01736954  0.03143814  0.00128864 -0.00209335  0.03074283 -0.0064823 ]\n",
      "333: action: 1, reward: 0.6178373864032943, max_logit: 0.033121783286333084\n",
      "   [-0.01907851  0.03312178  0.00125149 -0.0044013   0.02880614 -0.00300299]\n",
      "334: action: 1, reward: 0.6254577716770073, max_logit: 0.034045036882162094\n",
      "   [-0.01783711  0.03404504  0.00263772 -0.00068577  0.02760341 -0.00214512]\n",
      "335: action: 1, reward: 0.6332181204926288, max_logit: 0.03518366441130638\n",
      "   [-0.01862137  0.03518366  0.00249208  0.0030791   0.02631364 -0.00404349]\n",
      "336: action: 1, reward: 0.6411210035591661, max_logit: 0.035261042416095734\n",
      "   [-0.01790319  0.03526104  0.00271811  0.00353714  0.02504866 -0.00627516]\n",
      "337: action: 1, reward: 0.6491690388018141, max_logit: 0.0358734093606472\n",
      "   [-0.0189061   0.03587341  0.00183575  0.0003552   0.02752445 -0.00679193]\n",
      "338: action: 1, reward: 0.6573648922291739, max_logit: 0.036231059581041336\n",
      "   [-0.02073251  0.03623106  0.00245714 -0.00091284  0.02819011 -0.00493607]\n",
      "339: action: 1, reward: 0.6657112788164006, max_logit: 0.03587578982114792\n",
      "   [-0.01943     0.03587579  0.00228782  0.0001612   0.02732149 -0.00444976]\n",
      "340: action: 1, reward: 0.6742109634045715, max_logit: 0.03518366441130638\n",
      "   [-0.01862137  0.03518366  0.00249208  0.0030791   0.02631364 -0.00404349]\n",
      "341: action: 1, reward: 0.6828667616165731, max_logit: 0.035261042416095734\n",
      "   [-0.01790319  0.03526104  0.00271811  0.00353714  0.02504866 -0.00627516]\n",
      "342: action: 1, reward: 0.6916815407898098, max_logit: 0.03561732545495033\n",
      "   [-0.01920668  0.03561733  0.00288875  0.00246284  0.02591762 -0.00676066]\n",
      "343: action: 1, reward: 0.700658220926044, max_logit: 0.03630997985601425\n",
      "   [-0.02001548  0.03630998  0.00268335 -0.00045509  0.02692623 -0.00716719]\n",
      "344: action: 1, reward: 0.7097997756586824, max_logit: 0.036231059581041336\n",
      "   [-0.02073251  0.03623106  0.00245714 -0.00091284  0.02819011 -0.00493607]\n",
      "345: action: 1, reward: 0.7191092332378266, max_logit: 0.03561917319893837\n",
      "   [-0.0197318   0.03561917  0.00333995  0.00226817  0.02571606 -0.00441864]\n",
      "346: action: 1, reward: 0.7285896775334193, max_logit: 0.035261042416095734\n",
      "   [-0.01790319  0.03526104  0.00271811  0.00353714  0.02504866 -0.00627516]\n",
      "347: action: 1, reward: 0.7382442490568115, max_logit: 0.03561732545495033\n",
      "   [-0.01920668  0.03561733  0.00288875  0.00246284  0.02591762 -0.00676066]\n",
      "348: action: 1, reward: 0.748076146001096, max_logit: 0.03630997985601425\n",
      "   [-0.02001548  0.03630998  0.00268335 -0.00045509  0.02692623 -0.00716719]\n",
      "349: action: 1, reward: 0.7580886253005467, max_logit: 0.036231059581041336\n",
      "   [-0.02073251  0.03623106  0.00245714 -0.00091284  0.02819011 -0.00493607]\n",
      "350: action: 1, reward: 0.7682850037095175, max_logit: 0.03587578982114792\n",
      "   [-0.01943     0.03587579  0.00228782  0.0001612   0.02732149 -0.00444976]\n",
      "351: action: 1, reward: 0.7786686589011571, max_logit: 0.03518366441130638\n",
      "   [-0.01862137  0.03518366  0.00249208  0.0030791   0.02631364 -0.00404349]\n",
      "352: action: 1, reward: 0.7892430305863043, max_logit: 0.035261042416095734\n",
      "   [-0.01790319  0.03526104  0.00271811  0.00353714  0.02504866 -0.00627516]\n",
      "353: action: 1, reward: 0.8000116216529326, max_logit: 0.034414924681186676\n",
      "   [-0.01647243  0.03441492  0.0073682   0.00519055  0.02635395 -0.00605926]\n",
      "354: action: 1, reward: 0.8109779993265253, max_logit: 0.04096294566988945\n",
      "   [-0.01082701  0.04096295  0.02356431  0.00759013  0.03431937  0.00102556]\n",
      "355: action: 1, reward: 0.8221457963517609, max_logit: 0.03682148456573486\n",
      "   [-0.01504425  0.03682148  0.03612187  0.01081839  0.03229463  0.0095638 ]\n",
      "356: action: 4, reward: 0.8335187121959042, max_logit: 0.03798709809780121\n",
      "   [-0.0231834   0.03288672  0.03785121  0.01545087  0.0379871   0.00981105]\n",
      "357: action: 4, reward: 0.8451005142742993, max_logit: 0.038917217403650284\n",
      "   [-0.02194252  0.03482826  0.0386097   0.01743654  0.03891722  0.00921233]\n",
      "358: action: 2, reward: 0.856895039198371, max_logit: 0.03779200464487076\n",
      "   [-0.0226298   0.03714735  0.037792    0.01794626  0.03389587  0.0095361 ]\n",
      "359: action: 2, reward: 0.8689061940465481, max_logit: 0.04028162732720375\n",
      "   [-0.02476644  0.03313929  0.04028163  0.01849715  0.03832889  0.00707845]\n",
      "360: action: 2, reward: 0.8811379576585315, max_logit: 0.03857613354921341\n",
      "   [-0.02787106  0.03422661  0.03857613  0.01969283  0.03774747  0.00829125]\n",
      "361: action: 2, reward: 0.8935943819533316, max_logit: 0.04406926780939102\n",
      "   [-0.02240691  0.03278922  0.04406927  0.01599046  0.03641706  0.00922658]\n",
      "362: action: 2, reward: 0.9062795932715162, max_logit: 0.0417364239692688\n",
      "   [-0.02399465  0.03506426  0.04173642  0.01667804  0.03163707  0.00392899]\n",
      "363: action: 2, reward: 0.9191977937421095, max_logit: 0.0391453318297863\n",
      "   [-0.02306187  0.03808777  0.03914533  0.0165196   0.03390126  0.00817508]\n",
      "364: action: 2, reward: 0.9323532626745986, max_logit: 0.04278651624917984\n",
      "   [-0.02984834  0.03512926  0.04278652  0.01522812  0.03102644  0.00813887]\n",
      "365: action: 2, reward: 0.945750357976506, max_logit: 0.040301546454429626\n",
      "   [-0.02735746  0.02908068  0.04030155  0.01839756  0.02856109  0.02328511]\n",
      "366: action: 2, reward: 0.9593935175969999, max_logit: 0.03788691386580467\n",
      "   [-0.02547885  0.02901356  0.03788691  0.0161083   0.02934275  0.01724512]\n",
      "367: action: 2, reward: 0.9732872609970161, max_logit: 0.034828249365091324\n",
      "   [-0.02017874  0.0287524   0.03482825  0.01350293  0.01767478  0.01678421]\n",
      "368: action: 2, reward: 0.9874361906463868, max_logit: 0.03523924574255943\n",
      "   [-0.01512608  0.03285953  0.03523925  0.0128614   0.01650335  0.02013679]\n",
      "369: action: 1, reward: 1.0018449935484617, max_logit: 0.03337244316935539\n",
      "   [-0.01732793  0.03337244  0.03032947  0.01742806  0.01268694  0.01768209]\n",
      "370: action: 1, reward: 1.0165184427927354, max_logit: 0.0313151553273201\n",
      "   [-0.01805566  0.03131516  0.02895083  0.01907283  0.01739203  0.01673369]\n",
      "371: action: 1, reward: 1.0314613991359909, max_logit: 0.030939051881432533\n",
      "   [-0.02344367  0.03093905  0.02876854  0.01938351  0.01743705  0.01477991]\n",
      "372: action: 1, reward: 1.0466788126124835, max_logit: 0.034116458147764206\n",
      "   [-0.01892167  0.03411646  0.02839072  0.01847496  0.02145038  0.01556337]\n",
      "373: action: 1, reward: 1.062175724173699, max_logit: 0.03258991241455078\n",
      "   [-0.02041141  0.03258991  0.0296385   0.0179426   0.01874612  0.01530464]\n",
      "374: action: 1, reward: 1.0779572673582307, max_logit: 0.03371533006429672\n",
      "   [-0.01287845  0.03371533  0.03212829  0.03240133  0.02982499  0.01898503]\n",
      "375: action: 4, reward: 1.0940286699923243, max_logit: 0.03793293237686157\n",
      "   [-0.00086878  0.03099792  0.03005335  0.02104678  0.03793293  0.00489114]\n",
      "376: action: 4, reward: 1.1103952559216592, max_logit: 0.050173837691545486\n",
      "   [0.00737181 0.02197975 0.03453903 0.01666915 0.05017384 0.00372681]\n",
      "377: action: 4, reward: 1.1270624467749368, max_logit: 0.05201695114374161\n",
      "   [0.00618119 0.02353192 0.02857185 0.02846511 0.05201695 0.00357225]\n",
      "378: action: 4, reward: 1.1440357637598595, max_logit: 0.04978041350841522\n",
      "   [ 0.01102757  0.02147637  0.03203476  0.03049993  0.04978041 -0.00341182]\n",
      "379: action: 4, reward: 1.1613208294920982, max_logit: 0.051310475915670395\n",
      "   [0.00677771 0.0209727  0.03368549 0.03373946 0.05131048 0.00198425]\n",
      "380: action: 4, reward: 1.1789233698578505, max_logit: 0.04816068708896637\n",
      "   [0.00616071 0.0206982  0.02824759 0.03310158 0.04816069 0.00585182]\n",
      "381: action: 4, reward: 1.1968492159106099, max_logit: 0.05257637798786163\n",
      "   [0.00823358 0.01678744 0.03197388 0.02822702 0.05257638 0.00601966]\n",
      "382: action: 4, reward: 1.2151043058027724, max_logit: 0.049084559082984924\n",
      "   [0.00418629 0.01892613 0.03230415 0.03142611 0.04908456 0.00341148]\n",
      "383: action: 4, reward: 1.2336946867527216, max_logit: 0.05346369743347168\n",
      "   [0.01094646 0.01754659 0.02740724 0.02899744 0.0534637  0.00642217]\n",
      "384: action: 4, reward: 1.2526265170480413, max_logit: 0.05456925556063652\n",
      "   [0.0107838  0.01940186 0.0274264  0.03326731 0.05456926 0.00267265]\n",
      "385: action: 4, reward: 1.271906068085524, max_logit: 0.04193313792347908\n",
      "   [0.01908051 0.02242467 0.03157317 0.02236645 0.04193314 0.00220744]\n",
      "386: action: 4, reward: 1.2915397264486455, max_logit: 0.040654245764017105\n",
      "   [ 0.0099087   0.01301683  0.03504702  0.01769291  0.04065425 -0.00106728]\n",
      "387: action: 4, reward: 1.3115339960231973, max_logit: 0.03165990114212036\n",
      "   [-0.00600589  0.01409541  0.02783321  0.01510641  0.0316599   0.00076366]\n",
      "388: action: 2, reward: 1.3318955001517792, max_logit: 0.03370600566267967\n",
      "   [-0.00316524  0.00914933  0.03370601  0.01226712  0.03347556  0.00354113]\n",
      "389: action: 4, reward: 1.352630983827858, max_logit: 0.03263905271887779\n",
      "   [-0.00338847  0.00380414  0.03121724  0.0118545   0.03263905  0.00344264]\n",
      "390: action: 2, reward: 1.3737473159301317, max_logit: 0.033657629042863846\n",
      "   [-0.00144472  0.00532729  0.03365763  0.01374305  0.03152573  0.00523173]\n",
      "391: action: 4, reward: 1.3952514914979244, max_logit: 0.032959915697574615\n",
      "   [-0.00106322  0.00191358  0.0316317   0.01475957  0.03295992  0.0047869 ]\n",
      "392: action: 2, reward: 1.4171506340483802, max_logit: 0.035547688603401184\n",
      "   [-0.00448415  0.00696666  0.03554769  0.01238496  0.03043856  0.00409528]\n",
      "393: action: 4, reward: 1.4394519979362128, max_logit: 0.034252457320690155\n",
      "   [-0.00192836  0.00480878  0.03340077  0.0111062   0.03425246  0.00233595]\n",
      "394: action: 4, reward: 1.4621629707567982, max_logit: 0.03599304333329201\n",
      "   [3.0291830e-03 8.0672735e-03 3.0343380e-02 1.1337222e-02 3.5993043e-02\n",
      " 4.5489884e-05]\n",
      "395: action: 4, reward: 0.6534252796446752, max_logit: 0.036428388208150864\n",
      "   [0.00041897 0.00709475 0.0346115  0.01164771 0.03642839 0.00305506]\n",
      "396: action: 4, reward: 0.6616993074060332, max_logit: 0.03925057873129845\n",
      "   [-0.00272713  0.00189742  0.03293267  0.01786419  0.03925058 -0.00442988]\n",
      "397: action: 4, reward: 0.6701253041544873, max_logit: 0.03905392065644264\n",
      "   [-0.00744649  0.00611695  0.03390609  0.0148451   0.03905392 -0.00358755]\n",
      "398: action: 4, reward: 0.6787060611029395, max_logit: 0.040390655398368835\n",
      "   [-0.01273226  0.00786586  0.03618543  0.01442555  0.04039066 -0.00536508]\n",
      "399: action: 4, reward: 0.6874444207304719, max_logit: 0.04876740649342537\n",
      "   [-0.00407264  0.00724435  0.03577493  0.01096498  0.04876741 -0.01404817]\n",
      "400: action: 4, reward: 0.6963432777239522, max_logit: 0.0481758788228035\n",
      "   [-0.00786545  0.00405353  0.04025415  0.01369703  0.04817588 -0.01538744]\n",
      "401: action: 4, reward: 0.7054055799369334, max_logit: 0.04968995600938797\n",
      "   [-0.01484573  0.00681403  0.03833007  0.01422333  0.04968996 -0.0180438 ]\n",
      "402: action: 4, reward: 0.7146343293661661, max_logit: 0.04781097546219826\n",
      "   [-0.01252222  0.00351345  0.03823048  0.01467322  0.04781098 -0.01865325]\n",
      "403: action: 4, reward: 0.7240325831460461, max_logit: 0.0492161400616169\n",
      "   [-0.01450284  0.00511476  0.03395919  0.0119424   0.04921614 -0.01848133]\n",
      "404: action: 4, reward: 0.733603454561326, max_logit: 0.049787674099206924\n",
      "   [-0.0093526   0.00575676  0.03620182  0.01419138  0.04978767 -0.02176694]\n",
      "405: action: 4, reward: 0.7433501140784298, max_logit: 0.04994689300656319\n",
      "   [-0.00788176  0.00745599  0.03467118  0.0176214   0.04994689 -0.01694766]\n",
      "406: action: 4, reward: 0.7532757903957069, max_logit: 0.04516368359327316\n",
      "   [ 0.00078671  0.00990644  0.03274294  0.00762108  0.04516368 -0.01672786]\n",
      "407: action: 2, reward: 0.7633837715129784, max_logit: 0.03362801671028137\n",
      "   [-0.00619263  0.01112997  0.03362802  0.00090983  0.03159289 -0.01191   ]\n",
      "408: action: 4, reward: 0.7736774058207253, max_logit: 0.028787609189748764\n",
      "   [-0.0046625   0.01235213  0.02440573 -0.00201807  0.02878761 -0.01982439]\n",
      "409: action: 2, reward: 0.7841601032092843, max_logit: 0.03563788905739784\n",
      "   [-0.02252006  0.01660024  0.03563789  0.00011976  0.02006923 -0.00618939]\n",
      "410: action: 2, reward: 0.7948353361984142, max_logit: 0.03566841408610344\n",
      "   [-0.02101682  0.02170439  0.03566841 -0.00041173  0.02413856 -0.0072865 ]\n",
      "411: action: 2, reward: 0.8057066410876106, max_logit: 0.03452225774526596\n",
      "   [-0.02688872  0.02332741  0.03452226  0.0027515   0.01994709 -0.00584227]\n",
      "412: action: 2, reward: 0.8167776191275473, max_logit: 0.0325959213078022\n",
      "   [-0.02523106  0.0219515   0.03259592  0.00336308  0.02094933 -0.00265508]\n",
      "413: action: 2, reward: 0.8280519377130345, max_logit: 0.03661711513996124\n",
      "   [-0.02781535  0.01925712  0.03661712  0.00405649  0.0241359  -0.00071133]\n",
      "414: action: 2, reward: 0.8395333315978866, max_logit: 0.04069379344582558\n",
      "   [-0.02084237  0.0206558   0.04069379 -0.00024165  0.02486342 -0.00130209]\n",
      "415: action: 2, reward: 0.8512256041321045, max_logit: 0.03791780024766922\n",
      "   [-0.02357925  0.01935402  0.0379178   0.00548555  0.02434789 -0.00298265]\n",
      "416: action: 2, reward: 0.8631326285217822, max_logit: 0.03862306848168373\n",
      "   [-0.02645491  0.01838243  0.03862307  0.00295149  0.0223323  -0.00050346]\n",
      "417: action: 2, reward: 0.8752583491121517, max_logit: 0.03330672159790993\n",
      "   [-0.01889017  0.02364142  0.03330672  0.00104753  0.01059818 -0.00617698]\n",
      "418: action: 2, reward: 0.8876067826941955, max_logit: 0.03480181843042374\n",
      "   [-0.03082794  0.03456329  0.03480182  0.00993972  0.01455005 -0.02133292]\n",
      "419: action: 2, reward: 0.900182019835257, max_logit: 0.04890165477991104\n",
      "   [-0.01971569  0.03101774  0.04890165  0.0099624   0.01362157 -0.01766442]\n",
      "420: action: 2, reward: 0.91298822623409, max_logit: 0.04219038784503937\n",
      "   [-0.01330498  0.02569935  0.04219039  0.01442969  0.01871569 -0.02291087]\n",
      "421: action: 2, reward: 0.9260296441007962, max_logit: 0.0453844852745533\n",
      "   [-0.01006321  0.02966437  0.04538449  0.01640003  0.01909094 -0.02060238]\n",
      "422: action: 2, reward: 0.9393105935621097, max_logit: 0.04001515358686447\n",
      "   [-0.01188985  0.02169643  0.04001515  0.01533371  0.02077513 -0.0197819 ]\n",
      "423: action: 2, reward: 0.952835474092489, max_logit: 0.04566415026783943\n",
      "   [-0.01356691  0.02600651  0.04566415  0.01685465  0.01682344 -0.021447  ]\n",
      "424: action: 2, reward: 0.9666087659714981, max_logit: 0.041926153004169464\n",
      "   [-0.01198093  0.02638824  0.04192615  0.01162262  0.01693126 -0.02099804]\n",
      "425: action: 2, reward: 0.9806350317679512, max_logit: 0.042143091559410095\n",
      "   [-0.01158128  0.02552508  0.04214309  0.01589838  0.01915002 -0.02029747]\n",
      "426: action: 2, reward: 0.9949189178513199, max_logit: 0.041494712233543396\n",
      "   [-0.01652963  0.0266397   0.04149471  0.01080503  0.01963957 -0.02336241]\n",
      "427: action: 2, reward: 1.009465155930898, max_logit: 0.04513157159090042\n",
      "   [-0.01393441  0.02563622  0.04513157  0.01574961  0.01992971 -0.02117911]\n",
      "428: action: 2, reward: 1.0242785646232384, max_logit: 0.04686432704329491\n",
      "   [-0.02181542  0.01977478  0.04686433  0.02848084  0.02258589 -0.01774736]\n",
      "429: action: 2, reward: 1.0393640510483764, max_logit: 0.0519358292222023\n",
      "   [-0.01236808  0.01447794  0.05193583  0.01861379  0.02606825 -0.01203666]\n",
      "430: action: 2, reward: 1.0547266124553736, max_logit: 0.045257650315761566\n",
      "   [0.00207776 0.00563485 0.04525765 0.02353625 0.02953089 0.00173615]\n",
      "431: action: 2, reward: 1.070371337877716, max_logit: 0.04716985300183296\n",
      "   [-0.00053434  0.00495838  0.04716985  0.03334191  0.02351675 -0.00500744]\n",
      "432: action: 2, reward: 1.0863034098191182, max_logit: 0.04756415635347366\n",
      "   [ 0.00080026  0.00517597  0.04756416  0.03318087  0.02311493 -0.00561696]\n",
      "433: action: 2, reward: 1.1025281059702896, max_logit: 0.047746118158102036\n",
      "   [ 0.00133579  0.00563449  0.04774612  0.03207359  0.02339249 -0.00501537]\n",
      "434: action: 2, reward: 1.1190508009572342, max_logit: 0.04805770888924599\n",
      "   [ 0.00104277  0.00637203  0.04805771  0.03141667  0.02285945 -0.00621795]\n",
      "435: action: 2, reward: 1.1358769681216578, max_logit: 0.049168750643730164\n",
      "   [-0.00015353  0.00497445  0.04916875  0.03165622  0.02409956 -0.00402757]\n",
      "436: action: 2, reward: 1.153012181334081, max_logit: 0.044968146830797195\n",
      "   [-0.0003602   0.00308405  0.04496815  0.03305865  0.02311108 -0.00558503]\n",
      "437: action: 2, reward: 1.17046211684025, max_logit: 0.04716489836573601\n",
      "   [ 0.00135115  0.00405746  0.0471649   0.02953499  0.02207913 -0.00588836]\n",
      "438: action: 2, reward: 1.18823255514146, max_logit: 0.03793411701917648\n",
      "   [-0.00820227  0.0164019   0.03793412  0.0224388   0.02473675 -0.01140075]\n",
      "439: action: 4, reward: 1.2063293829094182, max_logit: 0.02911554090678692\n",
      "   [ 0.00338624  0.00644239  0.02797619  0.01734548  0.02911554 -0.01796711]\n",
      "440: action: 2, reward: 1.2247585949362734, max_logit: 0.02578912116587162\n",
      "   [-0.00896652  0.01482418  0.02578912  0.02553759  0.01627    -0.01397931]\n",
      "441: action: 2, reward: 1.2435262961204623, max_logit: 0.018848618492484093\n",
      "   [-0.00509811  0.01610807  0.01884862 -0.00561102  0.01484617 -0.01197402]\n",
      "442: action: 2, reward: 1.2626387034890327, max_logit: 0.018807193264365196\n",
      "   [-0.00081242  0.01277161  0.01880719 -0.00690237  0.01534251 -0.01250659]\n",
      "443: action: 1, reward: 1.282102148257107, max_logit: 0.020480100065469742\n",
      "   [-0.00421225  0.0204801   0.01737628 -0.00522483  0.0170242  -0.01370003]\n",
      "444: action: 2, reward: 1.3019230779251738, max_logit: 0.020370418205857277\n",
      "   [-0.00301304  0.01754608  0.02037042 -0.00284141  0.01617618 -0.01123513]\n",
      "445: action: 2, reward: 1.3221080584149005, max_logit: 0.02204151824116707\n",
      "   [ 0.00119778  0.01699221  0.02204152 -0.00587972  0.01477685 -0.01087974]\n",
      "446: action: 2, reward: 0.510797980095445, max_logit: 0.023064929991960526\n",
      "   [ 0.00520148  0.0189018   0.02306493 -0.00188025  0.01627973 -0.01402007]\n",
      "447: action: 2, reward: 0.5164523736387528, max_logit: 0.01970263198018074\n",
      "   [-0.00225175  0.01744087  0.01970263  0.00011509  0.01166019 -0.01397792]\n",
      "448: action: 1, reward: 0.5222106213730547, max_logit: 0.0191968884319067\n",
      "   [ 0.00069435  0.01919689  0.01656701 -0.00065769  0.01067664 -0.01398203]\n",
      "449: action: 4, reward: 0.5280746307872628, max_logit: 0.014333182014524937\n",
      "   [ 0.00579587  0.01396477  0.00786353  0.00269051  0.01433318 -0.00916209]\n",
      "450: action: 4, reward: 0.5340463444051189, max_logit: 0.015414495952427387\n",
      "   [-0.00554729  0.01342125  0.00624954  0.00017802  0.0154145   0.0011548 ]\n",
      "451: action: 4, reward: 0.5401277404286797, max_logit: 0.02329217456281185\n",
      "   [-0.01134783  0.00752171  0.00947343 -0.00780709  0.02329217  0.00807687]\n",
      "452: action: 4, reward: 0.5463208333936198, max_logit: 0.019957896322011948\n",
      "   [-0.01139948  0.00932537  0.00367376 -0.00107243  0.0199579   0.00962244]\n",
      "453: action: 4, reward: 0.5526276748365708, max_logit: 0.02019198052585125\n",
      "   [-0.0118974   0.01379244  0.00936649  0.0025326   0.02019198  0.00663458]\n",
      "454: action: 1, reward: 0.5590503539747175, max_logit: 0.017318645492196083\n",
      "   [-0.01197575  0.01731865  0.006715    0.00397998  0.01693474  0.00904887]\n",
      "455: action: 4, reward: 0.5655909983978764, max_logit: 0.020176107063889503\n",
      "   [-0.01288517  0.01449305  0.00513924  0.00431766  0.02017611  0.00904587]\n",
      "456: action: 4, reward: 0.5722517747732854, max_logit: 0.019602671265602112\n",
      "   [-0.01101573  0.01412272  0.00025392  0.00181562  0.01960267  0.00845481]\n",
      "457: action: 4, reward: 0.5790348895633383, max_logit: 0.019724758341908455\n",
      "   [-0.01210677  0.01167379  0.00629695  0.00397469  0.01972476  0.00745516]\n",
      "458: action: 4, reward: 0.5859425897565023, max_logit: 0.01685444824397564\n",
      "   [-0.01175042  0.01116197  0.0008937   0.00055265  0.01685445  0.00843086]\n",
      "459: action: 4, reward: 0.5929771636116598, max_logit: 0.01991339959204197\n",
      "   [-0.01266937  0.00959305  0.00559358  0.00218679  0.0199134   0.00770247]\n",
      "460: action: 2, reward: 0.6001409414161215, max_logit: 0.02314879186451435\n",
      "   [-0.0136224   0.01150074  0.02314879  0.00777128  0.01521221  0.00856442]\n",
      "461: action: 2, reward: 0.6074362962575628, max_logit: 0.024850623682141304\n",
      "   [-0.01313214  0.00920649  0.02485062  0.00388066 -0.00079809  0.01453752]\n",
      "462: action: 2, reward: 0.6148656448101368, max_logit: 0.02882310375571251\n",
      "   [-0.0136501   0.01041312  0.0288231   0.015798    0.00141918  0.02324492]\n",
      "463: action: 2, reward: 0.6224314481350277, max_logit: 0.026195429265499115\n",
      "   [-0.01467073  0.01673225  0.02619543  0.02445828  0.00219088  0.02217719]\n",
      "464: action: 3, reward: 0.630136212495706, max_logit: 0.02939786948263645\n",
      "   [-0.01109582  0.01674808  0.02640102  0.02939787  0.00431336  0.01756193]\n",
      "465: action: 3, reward: 0.637982490188159, max_logit: 0.02892965078353882\n",
      "   [-0.0158729   0.01756992  0.02633183  0.02892965  0.0040396   0.01987952]\n",
      "466: action: 2, reward: 0.6459728803863696, max_logit: 0.028447767719626427\n",
      "   [-0.01416124  0.0164356   0.02844777  0.02632353  0.00373325  0.01814516]\n",
      "467: action: 3, reward: 0.6541100300033237, max_logit: 0.031620319932699203\n",
      "   [-0.01111553  0.01763261  0.02962244  0.03162032  0.00236972  0.02126366]\n",
      "468: action: 3, reward: 0.6623966345678323, max_logit: 0.030565237626433372\n",
      "   [-0.01238453  0.01826101  0.02666643  0.03056524  0.00560602  0.01976066]\n",
      "469: action: 3, reward: 0.6708354391174577, max_logit: 0.029300235211849213\n",
      "   [-0.01135122  0.01659753  0.02889286  0.02930024  0.00833623  0.02030497]\n",
      "470: action: 3, reward: 0.6794292391078401, max_logit: 0.030034411698579788\n",
      "   [-0.00826616  0.0130849   0.0246133   0.03003441  0.01588865  0.02283993]\n",
      "471: action: 3, reward: 0.6881808813387268, max_logit: 0.03998056799173355\n",
      "   [-0.00477487  0.01394153  0.02646409  0.03998057  0.02175688  0.01916015]\n",
      "472: action: 3, reward: 0.6970932648970072, max_logit: 0.04465088993310928\n",
      "   [-0.00334563  0.01155859  0.03354415  0.04465089  0.02703218  0.01061033]\n",
      "473: action: 3, reward: 0.7061693421170723, max_logit: 0.054399654269218445\n",
      "   [0.00119129 0.00541766 0.03189669 0.05439965 0.02510398 0.00656142]\n",
      "474: action: 3, reward: 0.7154121195588096, max_logit: 0.050882771611213684\n",
      "   [0.00011819 0.00623231 0.03165948 0.05088277 0.02506238 0.00876551]\n",
      "475: action: 3, reward: 0.7248246590035623, max_logit: 0.05414029583334923\n",
      "   [-0.00087219  0.00825786  0.02266284  0.0541403   0.02330159  0.00567532]\n",
      "476: action: 3, reward: 0.7344100784683827, max_logit: 0.04710770025849342\n",
      "   [0.0033848  0.00787171 0.02801491 0.0471077  0.01943883 0.00994866]\n",
      "477: action: 3, reward: 0.7441715532389105, max_logit: 0.05182509496808052\n",
      "   [0.00477212 0.0041231  0.02499545 0.05182509 0.02338557 0.00625946]\n",
      "478: action: 3, reward: 0.7541123169212269, max_logit: 0.04916835203766823\n",
      "   [0.00352496 0.00506835 0.02794306 0.04916835 0.0232072  0.00684456]\n",
      "479: action: 3, reward: 0.7642356625130239, max_logit: 0.04862290620803833\n",
      "   [0.0034957  0.0053877  0.0254965  0.04862291 0.02765442 0.00932221]\n",
      "480: action: 3, reward: 0.7745449434944497, max_logit: 0.05088352411985397\n",
      "   [-0.0005335   0.00200682  0.02748923  0.05088352  0.02377636  0.0103891 ]\n",
      "481: action: 3, reward: 0.7850435749389904, max_logit: 0.047546036541461945\n",
      "   [-0.00981577  0.00490961  0.01713052  0.04754604  0.02594549  0.00670018]\n",
      "482: action: 3, reward: 0.7957350346447525, max_logit: 0.053496215492486954\n",
      "   [-0.00370918  0.01271746  0.01780867  0.05349622  0.02881587  0.00692982]\n",
      "483: action: 3, reward: 0.8066228642865273, max_logit: 0.052827633917331696\n",
      "   [-0.00549092  0.02145801  0.01910212  0.05282763  0.02736007 -0.00303043]\n",
      "484: action: 3, reward: 0.8177106705890116, max_logit: 0.04591850936412811\n",
      "   [-0.00837031  0.01634757  0.02320214  0.04591851  0.03630184 -0.00022044]\n",
      "485: action: 3, reward: 0.8290021265215801, max_logit: 0.04933445528149605\n",
      "   [-0.00817261  0.01874381  0.02344843  0.04933446  0.03536505 -0.00056   ]\n",
      "486: action: 3, reward: 0.8405009725149999, max_logit: 0.046956662088632584\n",
      "   [-0.00920601  0.01957129  0.02480765  0.04695666  0.03644925 -0.00212528]\n",
      "487: action: 3, reward: 0.8522110177004932, max_logit: 0.0467456616461277\n",
      "   [-0.00839221  0.01600839  0.02273472  0.04674566  0.03434056 -0.00133582]\n",
      "488: action: 3, reward: 0.8641361411715589, max_logit: 0.04707184433937073\n",
      "   [-0.00667936  0.01349274  0.02355556  0.04707184  0.03820711  0.00116782]\n",
      "489: action: 3, reward: 0.8762802932689675, max_logit: 0.046590570360422134\n",
      "   [-0.00399857  0.01460241  0.02376685  0.04659057  0.03755176  0.00236423]\n",
      "490: action: 3, reward: 0.8886474968893604, max_logit: 0.049634553492069244\n",
      "   [-0.0021669   0.01512074  0.02183645  0.04963455  0.03676138  0.00075549]\n",
      "491: action: 3, reward: 0.9012418488178819, max_logit: 0.04910888522863388\n",
      "   [-0.0056199   0.01650849  0.02055583  0.04910889  0.033914   -0.00293086]\n",
      "492: action: 3, reward: 0.9140675210852892, max_logit: 0.05647243931889534\n",
      "   [-0.00069761  0.01711406  0.02851357  0.05647244  0.03597386  0.01101263]\n",
      "493: action: 3, reward: 0.9271287623499882, max_logit: 0.05373149737715721\n",
      "   [-0.00500431  0.0107111   0.0351438   0.0537315   0.03390064  0.01535497]\n",
      "494: action: 3, reward: 0.9404298993054514, max_logit: 0.054256465286016464\n",
      "   [-0.00680701  0.01062895  0.04347316  0.05425647  0.04995621  0.02153089]\n",
      "495: action: 3, reward: 0.9539753381134886, max_logit: 0.05659350007772446\n",
      "   [-0.00148488  0.01229277  0.04276045  0.0565935   0.04670979  0.01197571]\n",
      "496: action: 3, reward: 0.9677695658638404, max_logit: 0.05693832412362099\n",
      "   [-0.00372007  0.01394401  0.04191631  0.05693832  0.05015812  0.01036296]\n",
      "497: action: 3, reward: 0.9818171520605811, max_logit: 0.057570930570364\n",
      "   [-0.00142526  0.01144846  0.04371796  0.05757093  0.04993853  0.01375175]\n",
      "498: action: 3, reward: 0.9961227501358209, max_logit: 0.056632716208696365\n",
      "   [-0.00326824  0.01261442  0.04155061  0.05663272  0.04985928  0.01384503]\n",
      "499: action: 3, reward: 1.0106910989912128, max_logit: 0.05612561106681824\n",
      "   [-0.00181736  0.01211721  0.0425139   0.05612561  0.04877293  0.01716809]\n",
      "500: action: 3, reward: 1.0255270245677706, max_logit: 0.0559319444000721\n",
      "   [-0.00163897  0.01298121  0.04364609  0.05593194  0.0492827   0.01455132]\n",
      "501: action: 3, reward: 1.0406354414445185, max_logit: 0.05493504926562309\n",
      "   [-0.00115476  0.01278931  0.04224733  0.05493505  0.04883092  0.01376816]\n",
      "502: action: 3, reward: 1.0560213544665065, max_logit: 0.05730307474732399\n",
      "   [-0.00353837  0.00676801  0.04477744  0.05730307  0.05097055  0.00920331]\n",
      "503: action: 4, reward: 1.071689860402724, max_logit: 0.05830102041363716\n",
      "   [-0.00264725  0.00540015  0.03706549  0.05554529  0.05830102  0.00170172]\n",
      "504: action: 4, reward: 1.0876461496344676, max_logit: 0.06694778800010681\n",
      "   [ 0.00351058 -0.00420872  0.02955837  0.05399605  0.06694779  0.00972875]\n",
      "505: action: 4, reward: 1.1038955078747157, max_logit: 0.06744938343763351\n",
      "   [ 0.00063277 -0.01843688  0.03291127  0.06340937  0.06744938  0.01572965]\n",
      "506: action: 4, reward: 1.1204433179190858, max_logit: 0.06867566704750061\n",
      "   [ 0.0026563  -0.02103424  0.02967629  0.06454883  0.06867567  0.01575716]\n",
      "507: action: 4, reward: 1.1372950614289499, max_logit: 0.06538046896457672\n",
      "   [ 0.00537527 -0.01866116  0.03117211  0.06411258  0.06538047  0.0134533 ]\n",
      "508: action: 4, reward: 1.1544563207473004, max_logit: 0.06852952390909195\n",
      "   [ 0.00118521 -0.017538    0.02761447  0.06628864  0.06852952  0.01344284]\n",
      "509: action: 3, reward: 1.1719327807479698, max_logit: 0.06685972958803177\n",
      "   [-0.00118844 -0.0165702   0.02980761  0.06685973  0.06546634  0.0118776 ]\n",
      "510: action: 3, reward: 1.1897302307188118, max_logit: 0.06718622893095016\n",
      "   [-0.00223478 -0.01362105  0.02990659  0.06718623  0.06520063  0.0105349 ]\n",
      "511: action: 3, reward: 1.2078545662794742, max_logit: 0.06674151867628098\n",
      "   [-0.00199443 -0.01469405  0.02943205  0.06674152  0.06518961  0.01014954]\n",
      "512: action: 3, reward: 1.2263117913343935, max_logit: 0.06704052537679672\n",
      "   [ 0.00058167 -0.0153037   0.03161287  0.06704053  0.06614479  0.00987949]\n",
      "513: action: 4, reward: 1.2451080200616598, max_logit: 0.07205583900213242\n",
      "   [ 0.00463587 -0.00633762  0.03485804  0.06462154  0.07205584  0.015048  ]\n",
      "514: action: 4, reward: 1.2642494789384122, max_logit: 0.08185664564371109\n",
      "   [ 0.00788204 -0.01101231  0.02161008  0.06201325  0.08185665  0.01257693]\n",
      "515: action: 4, reward: 1.283742508803436, max_logit: 0.0858989730477333\n",
      "   [-0.00565547 -0.00021265  0.02829694  0.0584239   0.08589897  0.00409569]\n",
      "516: action: 4, reward: 1.303593566957639, max_logit: 0.08754503726959229\n",
      "   [-0.00564286  0.01241519  0.02709796  0.05621093  0.08754504  0.00316895]\n",
      "517: action: 4, reward: 1.3238092293031127, max_logit: 0.08929582685232162\n",
      "   [-0.00667595  0.01305914  0.02414193  0.05392043  0.08929583 -0.00228773]\n",
      "518: action: 4, reward: 1.3443961925214776, max_logit: 0.08721600472927094\n",
      "   [-7.5538089e-03  1.0417229e-02  2.6197147e-02  5.3958870e-02\n",
      "  8.7216005e-02  6.7561879e-05]\n",
      "519: action: 4, reward: 0.5334954801435114, max_logit: 0.09163108468055725\n",
      "   [-0.00297865  0.01085752  0.02715237  0.05648952  0.09163108 -0.00446006]\n",
      "520: action: 4, reward: 0.5395667584485586, max_logit: 0.08662622421979904\n",
      "   [-0.00217934  0.00646142  0.026159    0.05105856  0.08662622 -0.00239312]\n",
      "521: action: 4, reward: 0.5457495478629479, max_logit: 0.08792310953140259\n",
      "   [-0.0020291   0.00871554  0.02716282  0.05292163  0.08792311 -0.00466964]\n",
      "522: action: 4, reward: 0.5520458965101357, max_logit: 0.09197396785020828\n",
      "   [-0.00445536  0.00766545  0.02717161  0.05308104  0.09197397 -0.00441174]\n",
      "523: action: 4, reward: 0.5584578901314418, max_logit: 0.0870528519153595\n",
      "   [-0.00321175  0.01181213  0.02555819  0.04877516  0.08705285 -0.00077955]\n",
      "524: action: 4, reward: 0.5649876527769767, max_logit: 0.0902191698551178\n",
      "   [-0.00477262  0.00434693  0.02107248  0.05302951  0.09021917 -0.00086301]\n",
      "525: action: 4, reward: 0.5716373475092584, max_logit: 0.09479836374521255\n",
      "   [-0.01778296  0.01237802  0.02712036  0.0540033   0.09479836 -0.00472015]\n",
      "526: action: 4, reward: 0.5784091771197529, max_logit: 0.09475097060203552\n",
      "   [-0.0101299  -0.00181797  0.02149944  0.03997997  0.09475097 -0.00351288]\n",
      "527: action: 4, reward: 0.5853053848585758, max_logit: 0.09770908951759338\n",
      "   [-0.00466237  0.00192821  0.02046467  0.03950281  0.09770909 -0.01867492]\n",
      "528: action: 4, reward: 0.5923282551775954, max_logit: 0.09548366069793701\n",
      "   [-0.00309104  0.00393553  0.02303297  0.03603264  0.09548366 -0.01281875]\n",
      "529: action: 4, reward: 0.5994801144871853, max_logit: 0.09624864906072617\n",
      "   [-0.00754836  0.00691568  0.02252333  0.04174121  0.09624865 -0.01791668]\n",
      "530: action: 4, reward: 0.6067633319268758, max_logit: 0.09651196002960205\n",
      "   [-0.00407266  0.00710386  0.01582474  0.03887721  0.09651196 -0.01681659]\n",
      "531: action: 4, reward: 0.6141803201501598, max_logit: 0.0993015468120575\n",
      "   [-0.00462598  0.00861078  0.02250202  0.0384607   0.09930155 -0.01714605]\n",
      "532: action: 4, reward: 0.6217335361237131, max_logit: 0.09911739826202393\n",
      "   [-0.00663215  0.00660932  0.02227211  0.04027984  0.0991174  -0.01606664]\n",
      "533: action: 4, reward: 0.6294254819412948, max_logit: 0.09944392740726471\n",
      "   [-0.0054758   0.00563204  0.02469127  0.04049514  0.09944393 -0.02158297]\n",
      "534: action: 4, reward: 0.6372587056525952, max_logit: 0.08224811404943466\n",
      "   [-0.011872    0.00159298  0.0207322   0.03543075  0.08224811 -0.01559013]\n",
      "535: action: 4, reward: 0.6452358021073089, max_logit: 0.07952827960252762\n",
      "   [-0.00665866  0.00163152  0.02197691  0.03787747  0.07952828 -0.01093155]\n",
      "536: action: 4, reward: 0.6533594138147092, max_logit: 0.069647878408432\n",
      "   [-0.00976962  0.0026549   0.01294916  0.04485949  0.06964788 -0.00815253]\n",
      "537: action: 4, reward: 0.6616322318190114, max_logit: 0.06378938257694244\n",
      "   [-0.01089238 -0.00413409  0.02020487  0.03986458  0.06378938 -0.00586015]\n",
      "538: action: 4, reward: 0.6700569965908136, max_logit: 0.06595603376626968\n",
      "   [-0.011514   -0.00646347  0.02440111  0.03725661  0.06595603 -0.00529812]\n",
      "539: action: 4, reward: 0.6786364989349107, max_logit: 0.06563949584960938\n",
      "   [-0.0116038  -0.00697893  0.02148024  0.04122775  0.0656395  -0.00545119]\n",
      "540: action: 4, reward: 0.6873735809147824, max_logit: 0.06713086366653442\n",
      "   [-0.01251337 -0.01057263  0.02322408  0.03824946  0.06713086 -0.00647327]\n",
      "541: action: 4, reward: 0.6962711367940596, max_logit: 0.0630212053656578\n",
      "   [-0.01355324 -0.00942005  0.02499924  0.03916113  0.06302121 -0.00558349]\n",
      "542: action: 4, reward: 0.7053321139952861, max_logit: 0.06528759747743607\n",
      "   [-0.01493818 -0.00467541  0.02011129  0.04026137  0.0652876  -0.00755806]\n",
      "543: action: 4, reward: 0.714559514076286, max_logit: 0.06570259481668472\n",
      "   [-0.02031778 -0.00545829  0.02322516  0.04373326  0.06570259 -0.00675354]\n",
      "544: action: 4, reward: 0.7239563937244672, max_logit: 0.067469522356987\n",
      "   [-0.01744878 -0.00985136  0.02374712  0.04032693  0.06746952 -0.00666825]\n",
      "545: action: 4, reward: 0.733525865769385, max_logit: 0.07615134119987488\n",
      "   [-0.00842569 -0.00411591  0.02539779  0.03834477  0.07615134 -0.00749883]\n",
      "546: action: 4, reward: 0.743271100213905, max_logit: 0.07722575962543488\n",
      "   [-0.01488467 -0.00416548  0.02111397  0.02793459  0.07722576 -0.00635379]\n",
      "547: action: 4, reward: 0.753195325284304, max_logit: 0.08790348470211029\n",
      "   [-0.005507    0.00228963  0.02195398  0.02973508  0.08790348 -0.0086213 ]\n",
      "548: action: 4, reward: 0.7633018284996601, max_logit: 0.08308049291372299\n",
      "   [-0.00942836  0.00372587  0.02421093  0.02316649  0.08308049 -0.01087558]\n",
      "549: action: 4, reward: 0.7735939577608815, max_logit: 0.08166831731796265\n",
      "   [-0.0097005   0.00743641  0.02323364  0.02364681  0.08166832 -0.01054506]\n",
      "550: action: 4, reward: 0.7840751224597401, max_logit: 0.0823117271065712\n",
      "   [-0.01365651  0.00770637  0.02512191  0.02232419  0.08231173 -0.00897725]\n",
      "551: action: 4, reward: 0.7947487946082731, max_logit: 0.08012267202138901\n",
      "   [-0.01310976  0.00770294  0.02310854  0.02146765  0.08012267 -0.00602542]\n",
      "552: action: 4, reward: 0.8056185099889283, max_logit: 0.07773146778345108\n",
      "   [-0.01112527  0.00934623  0.02287047  0.02095841  0.07773147 -0.00926616]\n",
      "553: action: 4, reward: 0.8166878693258364, max_logit: 0.08109067380428314\n",
      "   [-0.01315904  0.00668747  0.02340898  0.01993975  0.08109067 -0.0114106 ]\n",
      "554: action: 4, reward: 0.8279605394775919, max_logit: 0.08121402561664581\n",
      "   [-0.00992709  0.00702434  0.01875066  0.01810529  0.08121403 -0.0089506 ]\n",
      "555: action: 4, reward: 0.839440254651946, max_logit: 0.07965528964996338\n",
      "   [-0.01007124  0.01129287  0.02302395  0.02103594  0.07965529 -0.01081011]\n",
      "556: action: 4, reward: 0.8511308176428067, max_logit: 0.08302431553602219\n",
      "   [-0.0177339  -0.00248123  0.01956914  0.01472902  0.08302432 -0.01044273]\n",
      "557: action: 4, reward: 0.863036101089961, max_logit: 0.08648471534252167\n",
      "   [-0.01863854 -0.01471644  0.01654269  0.00057661  0.08648472 -0.01107896]\n",
      "558: action: 4, reward: 0.8751600487619329, max_logit: 0.08586889505386353\n",
      "   [-0.02181335 -0.01877849  0.01637878  0.00132011  0.0858689  -0.00876506]\n",
      "559: action: 4, reward: 0.05564088071367547, max_logit: 0.08889488875865936\n",
      "   [-0.01948291 -0.01648866  0.02685902 -0.00447804  0.08889489 -0.00470915]\n",
      "560: action: 4, reward: 0.052935408257295105, max_logit: 0.08523580431938171\n",
      "   [-0.01833912 -0.01678346  0.0212271  -0.00252955  0.0852358  -0.00823198]\n",
      "561: action: 4, reward: 0.050180244414727626, max_logit: 0.08667655289173126\n",
      "   [-0.01978194 -0.01821947  0.02163616 -0.00034216  0.08667655 -0.01009146]\n",
      "562: action: 4, reward: 0.047374476504768184, max_logit: 0.08783604204654694\n",
      "   [-0.0171613  -0.02211658  0.01926819 -0.00627545  0.08783604 -0.00891915]\n",
      "563: action: 4, reward: 0.04451717508300513, max_logit: 0.08626201748847961\n",
      "   [-0.01588325 -0.01963257  0.02091637 -0.00335691  0.08626202 -0.01023577]\n",
      "564: action: 4, reward: 0.0416073936339304, max_logit: 0.08101588487625122\n",
      "   [-0.02318815 -0.01770747  0.02421152  0.00208999  0.08101588 -0.00463122]\n",
      "565: action: 4, reward: 0.03864416825739483, max_logit: 0.08477456867694855\n",
      "   [-0.01583569 -0.0203591   0.02430904  0.00110839  0.08477457 -0.00788187]\n",
      "566: action: 4, reward: 0.035626517349304644, max_logit: 0.08918742835521698\n",
      "   [-0.0147541  -0.01520718  0.02011222 -0.00492794  0.08918743 -0.00629483]\n",
      "567: action: 4, reward: 0.03255344127645324, max_logit: 0.07977177202701569\n",
      "   [-0.01806275 -0.00760584  0.02245464 -0.0014692   0.07977177 -0.00053904]\n",
      "568: action: 4, reward: 0.029423922045380687, max_logit: 0.0707044005393982\n",
      "   [-0.02471977  0.00383578  0.01253751 -0.00659772  0.0707044  -0.00558009]\n",
      "569: action: 4, reward: -0.8056288731835778, max_logit: 0.07279947400093079\n",
      "   [-0.02712503  0.00822076  0.01646092 -0.00840027  0.07279947 -0.0100448 ]\n",
      "570: action: 4, reward: -0.8241532787993995, max_logit: 0.07476861029863358\n",
      "   [-0.01742131  0.00204777  0.01653271 -0.01138736  0.07476861 -0.00734628]\n",
      "571: action: 4, reward: -0.8430179219922741, max_logit: 0.0705452486872673\n",
      "   [-0.01867756  0.00167773  0.01674663 -0.00940106  0.07054525 -0.00295776]\n",
      "572: action: 4, reward: -0.8622290519024574, max_logit: 0.07323195785284042\n",
      "   [-0.01443069  0.00359464  0.01601748 -0.01177677  0.07323196 -0.0060536 ]\n",
      "573: action: 4, reward: -0.8817930324481019, max_logit: 0.06922432780265808\n",
      "   [-0.02020251  0.0031786   0.01256321 -0.01204498  0.06922433 -0.00709311]\n",
      "574: action: 4, reward: -0.9017163444333843, max_logit: 0.0685557946562767\n",
      "   [-0.02367873 -0.00012133  0.01332278 -0.01096362  0.06855579 -0.0066599 ]\n",
      "575: action: 4, reward: -0.9220055876953468, max_logit: 0.07347675412893295\n",
      "   [-0.01782482  0.00075773  0.01064619 -0.00910833  0.07347675 -0.0090386 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576: action: 4, reward: -0.9426674832901754, max_logit: 0.07301337271928787\n",
      "   [-0.02043452  0.00378076  0.01128817 -0.01328233  0.07301337 -0.00899815]\n",
      "577: action: 4, reward: -0.9637088757196286, max_logit: 0.06661917269229889\n",
      "   [-0.0175443   0.00353653  0.01283051 -0.00826411  0.06661917 -0.00768019]\n",
      "578: action: 4, reward: -0.9851367351983621, max_logit: 0.05339335650205612\n",
      "   [-0.02908951  0.0084604   0.01948425 -0.0069064   0.05339336 -0.01281224]\n",
      "579: action: 4, reward: -1.0069581599628963, max_logit: 0.05009852722287178\n",
      "   [-0.02149172  0.00540314  0.02111889 -0.00067494  0.05009853 -0.0224221 ]\n",
      "580: action: 4, reward: -1.029180378622992, max_logit: 0.04859957471489906\n",
      "   [-0.0135272   0.01200491  0.02336386 -0.00425316  0.04859957 -0.02283926]\n",
      "581: action: 4, reward: -1.051810752556216, max_logit: 0.04695628583431244\n",
      "   [-0.01423758  0.01299849  0.02659884 -0.00252908  0.04695629 -0.02559054]\n",
      "582: action: 4, reward: -1.0748567783464829, max_logit: 0.04665195941925049\n",
      "   [-0.01225215  0.01142436  0.02190275 -0.00317685  0.04665196 -0.02309227]\n",
      "583: action: 4, reward: -1.9301918864161218, max_logit: 0.047008659690618515\n",
      "   [-0.01614075  0.01226876  0.02834482 -0.00566363  0.04700866 -0.02271047]\n",
      "584: action: 4, reward: -1.9693711299145102, max_logit: 0.04961083084344864\n",
      "   [-0.01346745  0.01099124  0.02747413 -0.00842622  0.04961083 -0.0206586 ]\n",
      "585: action: 4, reward: -2.009269978195644, max_logit: 0.04705621302127838\n",
      "   [-0.01540628  0.01212585  0.02560052 -0.00566337  0.04705621 -0.02196454]\n",
      "586: action: 4, reward: -2.0499016482335404, max_logit: 0.045993342995643616\n",
      "   [-0.01220764  0.01279817  0.02323635 -0.00764576  0.04599334 -0.02545436]\n",
      "587: action: 4, reward: -2.0912795997582503, max_logit: 0.04381090775132179\n",
      "   [-0.01085424  0.01696352  0.0226544  -0.00302103  0.04381091 -0.02427237]\n",
      "588: action: 4, reward: -2.133417539714555, max_logit: 0.029862424358725548\n",
      "   [-0.00630122  0.01412429  0.02501661 -0.0022245   0.02986242 -0.01755276]\n",
      "589: action: 4, reward: -2.176329426802556, max_logit: 0.031017297878861427\n",
      "   [-0.00738688 -0.00141137  0.02124895 -0.01310183  0.0310173  -0.00997804]\n",
      "590: action: 4, reward: -2.220029476101663, max_logit: 0.028108322992920876\n",
      "   [-0.0166342  -0.00856111  0.01827961 -0.01588846  0.02810832 -0.00792255]\n",
      "591: action: 4, reward: -2.264532163779511, max_logit: 0.02250101789832115\n",
      "   [-0.01715231 -0.01856137  0.01620089 -0.02467464  0.02250102 -0.0131973 ]\n",
      "592: action: 4, reward: -2.3098522318873647, max_logit: 0.020803237333893776\n",
      "   [-0.01928052 -0.02121779  0.01636613 -0.02186053  0.02080324 -0.01777263]\n",
      "593: action: 4, reward: -2.3560046932436, max_logit: 0.021861877292394638\n",
      "   [-0.02157285 -0.01733539  0.01901427 -0.02343896  0.02186188 -0.01625121]\n",
      "594: action: 4, reward: -2.4030048364068817, max_logit: 0.025161471217870712\n",
      "   [-0.01854626 -0.01789217  0.02361537 -0.02301119  0.02516147 -0.012589  ]\n",
      "595: action: 4, reward: -2.450868230740682, max_logit: 0.025638502091169357\n",
      "   [-0.01971474 -0.01901131  0.02115811 -0.02418425  0.0256385  -0.01069532]\n",
      "596: action: 4, reward: -2.49961073157082, max_logit: 0.022880306467413902\n",
      "   [-0.01974077 -0.01905755  0.01916564 -0.02436157  0.02288031 -0.01018121]\n",
      "597: action: 4, reward: -2.54924848543773, max_logit: 0.02444283291697502\n",
      "   [-0.02140801 -0.02062149  0.01688895 -0.02542408  0.02444283 -0.01138163]\n",
      "598: action: 4, reward: 1.0198041769806432, max_logit: 0.02609233930706978\n",
      "   [-0.02066441 -0.02107242  0.01746204 -0.02362507  0.02609234 -0.01274589]\n",
      "599: action: 4, reward: 0.20294168622291348, max_logit: 0.026290051639080048\n",
      "   [-0.02277671 -0.0208651   0.01324457 -0.02195198  0.02629005 -0.01332951]\n",
      "600: action: 4, reward: 0.20294168622291348, max_logit: 0.025561049580574036\n",
      "   [-0.02488631 -0.01704027  0.02036818 -0.02127818  0.02556105 -0.018443  ]\n",
      "601: action: 4, reward: 0.20294168622291348, max_logit: 0.025761092081665993\n",
      "   [-0.02443545 -0.01943411  0.01819072 -0.0203313   0.02576109 -0.01369524]\n",
      "602: action: 4, reward: 0.20294168622291348, max_logit: 0.024876097217202187\n",
      "   [-0.02069045 -0.01567761  0.0206537  -0.01450375  0.0248761  -0.01567698]\n",
      "603: action: 4, reward: 0.20294168622291348, max_logit: 0.029436776414513588\n",
      "   [-0.01759207 -0.01846933  0.01928174 -0.01527151  0.02943678 -0.01581491]\n",
      "604: action: 4, reward: 0.20294168622291348, max_logit: 0.027887051925063133\n",
      "   [-0.0163326  -0.02021823  0.01901009 -0.01605342  0.02788705 -0.0117842 ]\n",
      "605: action: 4, reward: 0.20294168622291348, max_logit: 0.024224158376455307\n",
      "   [-0.01962056 -0.0148832   0.02002328 -0.01362095  0.02422416 -0.01175163]\n",
      "606: action: 4, reward: 0.20294168622291348, max_logit: 0.024767491966485977\n",
      "   [-0.02163477 -0.01467081  0.02135293 -0.01590177  0.02476749 -0.00910707]\n",
      "607: action: 4, reward: 0.20294168622291348, max_logit: 0.023897597566246986\n",
      "   [-0.02100773 -0.01495206  0.02238375 -0.01494268  0.0238976  -0.01170473]\n",
      "608: action: 4, reward: 0.20294168622291348, max_logit: 0.02498888038098812\n",
      "   [-0.02117241 -0.01480568  0.01886827 -0.01516083  0.02498888 -0.01341958]\n",
      "609: action: 4, reward: 0.20294168622291348, max_logit: 0.02649683691561222\n",
      "   [-0.02365984 -0.01522286  0.01890158 -0.01729131  0.02649684 -0.01467936]\n",
      "610: action: 4, reward: 0.20294168622291348, max_logit: 0.024791982024908066\n",
      "   [-0.01990513 -0.01466756  0.02039065 -0.01657216  0.02479198 -0.01512557]\n",
      "611: action: 4, reward: 0.20294168622291348, max_logit: 0.02711101807653904\n",
      "   [-0.02063596 -0.01434262  0.02107248 -0.01730317  0.02711102 -0.01446081]\n",
      "612: action: 4, reward: 0.20294168622291348, max_logit: 0.026622436940670013\n",
      "   [-0.02061591 -0.01528042  0.02150337 -0.01855809  0.02662244 -0.01269615]\n",
      "613: action: 4, reward: 0.20294168622291348, max_logit: 0.025704406201839447\n",
      "   [-0.01869555 -0.01435865  0.0219733  -0.01658877  0.02570441 -0.01423733]\n",
      "614: action: 4, reward: 0.20294168622291348, max_logit: 0.02792721800506115\n",
      "   [-0.02067512 -0.01517949  0.02121674 -0.01818147  0.02792722 -0.01306933]\n",
      "615: action: 4, reward: 0.20294168622291348, max_logit: 0.02581675350666046\n",
      "   [-0.01924201 -0.01532525  0.0218365  -0.01745173  0.02581675 -0.01345391]\n",
      "616: action: 4, reward: 0.20294168622291348, max_logit: 0.026304669678211212\n",
      "   [-0.01926135 -0.01438728  0.02140667 -0.01619695  0.02630467 -0.01521947]\n",
      "617: action: 4, reward: 0.20294168622291348, max_logit: 0.02722298726439476\n",
      "   [-0.02118287 -0.01530956  0.02093565 -0.01816554  0.02722299 -0.01367866]\n",
      "618: action: 4, reward: 0.20294168622291348, max_logit: 0.02500053495168686\n",
      "   [-0.01920293 -0.01448893  0.02169159 -0.01657193  0.02500053 -0.01484616]\n",
      "619: action: 4, reward: 0.20294168622291348, max_logit: 0.02711101807653904\n",
      "   [-0.02063596 -0.01434262  0.02107248 -0.01730317  0.02711102 -0.01446081]\n",
      "620: action: 4, reward: 0.20294168622291348, max_logit: 0.026622436940670013\n",
      "   [-0.02061591 -0.01528042  0.02150337 -0.01855809  0.02662244 -0.01269615]\n",
      "621: action: 4, reward: 0.20294168622291348, max_logit: 0.025704406201839447\n",
      "   [-0.01869555 -0.01435865  0.0219733  -0.01658877  0.02570441 -0.01423733]\n",
      "622: action: 4, reward: 0.20294168622291348, max_logit: 0.02792721800506115\n",
      "   [-0.02067512 -0.01517949  0.02121674 -0.01818147  0.02792722 -0.01306933]\n",
      "623: action: 4, reward: 0.20294168622291348, max_logit: 0.02581675350666046\n",
      "   [-0.01924201 -0.01532525  0.0218365  -0.01745173  0.02581675 -0.01345391]\n",
      "624: action: 4, reward: 0.20294168622291348, max_logit: 0.026304669678211212\n",
      "   [-0.01926135 -0.01438728  0.02140667 -0.01619695  0.02630467 -0.01521947]\n",
      "625: action: 4, reward: 0.20294168622291348, max_logit: 0.02722298726439476\n",
      "   [-0.02118287 -0.01530956  0.02093565 -0.01816554  0.02722299 -0.01367866]\n",
      "626: action: 4, reward: 0.20294168622291348, max_logit: 0.02500053495168686\n",
      "   [-0.01920293 -0.01448893  0.02169159 -0.01657193  0.02500053 -0.01484616]\n",
      "627: action: 4, reward: 0.20294168622291348, max_logit: 0.02711101807653904\n",
      "   [-0.02063596 -0.01434262  0.02107248 -0.01730317  0.02711102 -0.01446081]\n",
      "628: action: 4, reward: 0.20294168622291348, max_logit: 0.026622436940670013\n",
      "   [-0.02061591 -0.01528042  0.02150337 -0.01855809  0.02662244 -0.01269615]\n",
      "629: action: 4, reward: 0.20294168622291348, max_logit: 0.025704406201839447\n",
      "   [-0.01869555 -0.01435865  0.0219733  -0.01658877  0.02570441 -0.01423733]\n",
      "630: action: 4, reward: 0.20294168622291348, max_logit: 0.02792721800506115\n",
      "   [-0.02067512 -0.01517949  0.02121674 -0.01818147  0.02792722 -0.01306933]\n",
      "631: action: 4, reward: 0.20294168622291348, max_logit: 0.02581675350666046\n",
      "   [-0.01924201 -0.01532525  0.0218365  -0.01745173  0.02581675 -0.01345391]\n",
      "632: action: 4, reward: 0.20294168622291348, max_logit: 0.026304669678211212\n",
      "   [-0.01926135 -0.01438728  0.02140667 -0.01619695  0.02630467 -0.01521947]\n",
      "633: action: 4, reward: 0.20294168622291348, max_logit: 0.02722298726439476\n",
      "   [-0.02118287 -0.01530956  0.02093565 -0.01816554  0.02722299 -0.01367866]\n",
      "634: action: 4, reward: 0.20294168622291348, max_logit: 0.02500053495168686\n",
      "   [-0.01920293 -0.01448893  0.02169159 -0.01657193  0.02500053 -0.01484616]\n",
      "635: action: 4, reward: 0.20294168622291348, max_logit: 0.02711101807653904\n",
      "   [-0.02063596 -0.01434262  0.02107248 -0.01730317  0.02711102 -0.01446081]\n",
      "636: action: 4, reward: 0.20294168622291348, max_logit: 0.026622436940670013\n",
      "   [-0.02061591 -0.01528042  0.02150337 -0.01855809  0.02662244 -0.01269615]\n",
      "637: action: 4, reward: 0.20294168622291348, max_logit: 0.025704406201839447\n",
      "   [-0.01869555 -0.01435865  0.0219733  -0.01658877  0.02570441 -0.01423733]\n",
      "638: action: 4, reward: 0.20294168622291348, max_logit: 0.02792721800506115\n",
      "   [-0.02067512 -0.01517949  0.02121674 -0.01818147  0.02792722 -0.01306933]\n",
      "639: action: 4, reward: 0.20294168622291348, max_logit: 0.02581675350666046\n",
      "   [-0.01924201 -0.01532525  0.0218365  -0.01745173  0.02581675 -0.01345391]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "counter = 0\n",
    "for this_reward in discounted_rewards:\n",
    "    #print(\"{}: action: {}-{}, {}, {}\".format(counter, np.argmax(all_logits[counter]), actions[counter], this_reward, all_logits[counter]))\n",
    "    #frame: action-action, reward, logits\n",
    "    \n",
    "    print(\"{}: action: {}, reward: {}, max_logit: {}\".format(counter, np.argmax(all_logits[counter]), this_reward, all_logits[counter][np.argmax(all_logits[counter])]  ))\n",
    "    print(\"   {}\".format(all_logits[counter]))\n",
    "          \n",
    "    counter += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 832\n",
      "batch_index: 24\n",
      "len(all_logits): 888\n",
      "len(all_training_logits): 52\n",
      "len(frames_to_train): 855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(0, len(all_logits)):\n",
    "#     print(\"{}: {}  {}\".format(i, np.argmax(all_logits[i]), np.argmax(all_training_logits[i])))\n",
    "\n",
    "print(\"i: {}\".format(i))\n",
    "print(\"batch_index: {}\".format(batch_index))\n",
    "\n",
    "print(\"len(all_logits): {}\".format(len(all_logits)))\n",
    "print(\"len(all_training_logits): {}\".format(len(all_training_logits)))\n",
    "print(\"len(frames_to_train): {}\".format(len(frames_to_train)))\n",
    "\n",
    "all_training_logits\n",
    "batch_index\n",
    "input_q_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len(rewards)\n",
    "#len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_logits\n",
    "\n",
    "# discounted_rewards_median = np.median(discounted_rewards)\n",
    "# discounted_rewards_mean = np.mean(discounted_rewards)\n",
    "# #average_logits = get_average_logits(all_logits, discounted_rewards)\n",
    "# max_reward = np.argmax(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len(all_gradients)\n",
    "np.shape(all_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.getsizeof(all_variables))\n",
    "#np.shape(all_gradients[1])\n",
    "#all_gradients\n",
    "#all_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "def get_size(obj, seen=None):\n",
    "    \"\"\"Recursively finds size of objects\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    # Important mark as seen *before* entering recursion to gracefully handle\n",
    "    # self-referential objects\n",
    "    seen.add(obj_id)\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum([get_size(v, seen) for v in obj.values()])\n",
    "        size += sum([get_size(k, seen) for k in obj.keys()])\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        size += get_size(obj.__dict__, seen)\n",
    "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum([get_size(i, seen) for i in obj])\n",
    "    return size\n",
    "\n",
    "get_size(all_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[261 260 259 258 257 256 255 254 253 252 251 250 249 248 247 246 245 244\n",
      " 243 242 241 240 239 238 237 236 235 230 229 228 227 226 225 224 223 222\n",
      " 221 220 132 131 130 126 127 128 286 295 125 123 555 554 529 528 527 526\n",
      " 525 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156\n",
      " 157 158 159 160 161 162 163 164 165 166 167 168 169 524 523 522 521 520\n",
      " 449 448 447 446 445 444 443 442 441 440 439 438 437 436 435 434 433 192\n",
      " 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 432 431\n",
      " 430 429 428 427 426 425 424 423 422 122 121 120 119 118 117 116 115 114\n",
      " 421 420 231 232 233 234 419 393 392 391 390 389 388 387 386 385 384 383\n",
      " 382 381 380 379 378 377 376 375 374 373 372 371 370 124 350 349 348 347\n",
      " 317 316 315 314 313 312 311 310 309 308 307 306 305 304 303 302 301 300\n",
      " 299 298 297 296 287 288 289 290 291 292 293 294 351 352   0  31 170 171\n",
      " 172 173 174 454 453 452 451 450 209 210 211 212 213 399 398 397 396 318\n",
      " 319 320 321 322 395 394 356 355 354 353   1 175 330 332 333 334 335 336\n",
      " 337   2   3   4   5   6   7   8   9  10  11  12  13  14  15 329 328 327\n",
      " 326 325 357 358 359 360 361 362 363 364 365 366 367 368 369  16 133 134\n",
      "  32  33  34  35  36  37  38  39  40  41  42 135 136 103 104 105 106 107\n",
      " 108 109 110 324 323 137 138 139 517 400 516 515 514 513 512 469 468 467\n",
      " 466 465 464 463 462 461  46  45  44  43 111 112 113 219 218 217 216 215\n",
      " 214 460 459 458 457 456 455 331 189 188 187 186 185 184 183 182 181 180\n",
      " 179 178 177 176 190 470  19  18  17 519 191 338 339 340 341 518  47  48\n",
      "  49  50 473 472 471  20  51 342  21 474 475  23  52 476 477 478 346 345\n",
      " 344 343  24  22  54  53  55  25 479  56  26  96 482  98  57 481 480  27\n",
      "  28  58  97  59 101 504 505 506 100  99 485 484  61 483  30  29  60  62\n",
      " 510 509 508  67  66  65  64  63 507 511 493 102 492 491 490 489 488 487\n",
      " 486  68  69  70 494  71  90  91  92  93  94  95  81  80  79  78 503 502\n",
      " 501  89  88 500 499  87  86  85  84  83  82 498 497 496 495  77  76  75\n",
      "  74  73  72]\n",
      "-0.7816080678548915\n",
      "-0.790043477322384\n",
      "-0.7983499165625977\n",
      "-0.8065293574204782\n",
      "-0.8145837415931414\n",
      "-0.8225149810908078\n",
      "-0.8303249586906896\n",
      "-0.8380155283839392\n",
      "-0.8455885158157628\n",
      "-0.853045718718806\n",
      "-0.8603889073399135\n",
      "-0.867619824860363\n",
      "-0.874740187809675\n",
      "-0.8817516864730955\n",
      "-0.8886559852928485\n",
      "-0.8954547232632537\n",
      "-0.9021495143198034\n",
      "-0.908741947722291\n",
      "-0.9152335884320801\n",
      "-0.9216259774836091\n",
      "-0.9279206323502109\n",
      "-0.9341190473043441\n",
      "-0.940222693772314\n",
      "-0.9462330206835702\n",
      "-0.9521514548146652\n",
      "-0.9579794011279534\n",
      "-0.9637182431051105\n",
      "-1.3916554800487952\n",
      "-1.3907637840918567\n",
      "-1.3898857214067433\n",
      "-1.3890210835523396\n",
      "-1.3881696652744153\n",
      "-0.5558275606453214\n",
      "-0.5677149617964633\n",
      "-0.5794206147071522\n",
      "-0.5909472981532102\n",
      "-0.6022977484253436\n",
      "-0.613474659978704\n",
      "-1.0309911031977808\n",
      "-1.0356136584260547\n",
      "-1.0401655387213933\n",
      "-1.0576876754633135\n",
      "-1.053407853253596\n",
      "-1.049061580230583\n",
      "-0.5223633595308472\n",
      "-0.40174024103524125\n",
      "-0.23039835902449907\n",
      "-0.2638664121112175\n",
      "-0.5018296295217497\n",
      "-0.5145426130558731\n",
      "-0.16039322251941177\n",
      "-0.17832647795403733\n",
      "-0.19598554918478192\n",
      "-0.21337462825463147\n",
      "-0.23049784311380425\n",
      "-0.4983117743192363\n",
      "-0.48534678208436205\n",
      "-0.472180488431775\n",
      "-0.4588097678477811\n",
      "-0.4452314462902855\n",
      "-0.43144230043531506\n",
      "-0.41743905691184086\n",
      "-0.4032183915247212\n",
      "-0.38877692846557943\n",
      "-0.3741112395114283\n",
      "-0.35921784321085354\n",
      "-0.34409320405756016\n",
      "-0.32873373165108816\n",
      "-0.3131357798444952\n",
      "-0.29729564587880775\n",
      "-0.2812095695040322\n",
      "-0.2648737320865181\n",
      "-0.24828425570246243\n",
      "-0.231437202217339\n",
      "-0.2143285723510344\n",
      "-0.19695430472846895\n",
      "-0.17931027491547682\n",
      "-0.16139229443971675\n",
      "-0.14319610979638162\n",
      "-0.12471740143846866\n",
      "-0.10595178275137367\n",
      "-0.08689479901156306\n",
      "-0.06754192632907832\n",
      "-0.04788857057362094\n",
      "-0.027930066283963433\n",
      "-0.24735925859967542\n",
      "-0.2639628774017179\n",
      "-0.28031264101169134\n",
      "-0.29641243065930284\n",
      "-0.3122660682335625\n",
      "-0.026828689571571016\n",
      "-0.04680403297324378\n",
      "-0.06647397038503347\n",
      "-0.08584317120444604\n",
      "-0.10491623343787568\n",
      "-0.12369768479211454\n",
      "-0.1421919837491736\n",
      "-0.1604035206246706\n",
      "-0.17833661861003644\n",
      "-0.1959955347987864\n",
      "-0.2133844611971013\n",
      "-0.23050752571895738\n",
      "-0.24736879316604124\n",
      "-0.26397226619268355\n",
      "-0.2803218862560384\n",
      "-0.2964215345517369\n",
      "-0.31227503293523406\n",
      "-0.31718584284447077\n",
      "-0.3014085923274543\n",
      "-0.28538637576347464\n",
      "-0.269115389678403\n",
      "-0.2525917715433327\n",
      "-0.2358115988576635\n",
      "-0.2187708882179488\n",
      "-0.2014655943722849\n",
      "-0.18389160926001927\n",
      "-0.16604476103654803\n",
      "-0.14792081308297228\n",
      "-0.1295154630003774\n",
      "-0.11082434158849765\n",
      "-0.09184301180852242\n",
      "-0.07256696772979836\n",
      "-0.052991633460178135\n",
      "-0.033112362059760495\n",
      "-0.3278861448290694\n",
      "-0.34325857611625693\n",
      "-0.35839597602001505\n",
      "-0.3733019379700469\n",
      "-0.3879800004555756\n",
      "-0.4024336478653374\n",
      "-0.4166663113147319\n",
      "-0.43068136946032637\n",
      "-0.4444821493019061\n",
      "-0.4580719269722629\n",
      "-0.47145392851490836\n",
      "-0.28021765059333414\n",
      "-0.2963188925635497\n",
      "-0.3121739602556377\n",
      "-0.327786617464672\n",
      "-0.34316057044050496\n",
      "-0.35829946876758506\n",
      "-0.3732069062313223\n",
      "-0.38788642167120846\n",
      "-0.4023414998208929\n",
      "-0.4846313306498958\n",
      "-0.49760726152793433\n",
      "-0.19186461019087267\n",
      "-0.17414155505279097\n",
      "-0.15614332226239247\n",
      "-0.1378656392639724\n",
      "-0.5103848014729726\n",
      "-0.03552656239441259\n",
      "-0.05536892272761327\n",
      "-0.0749079102688014\n",
      "-0.0941481633296188\n",
      "-0.11309424930587202\n",
      "-0.13175066576177535\n",
      "-0.1501218414976164\n",
      "-0.16821213760109796\n",
      "-0.18602584848260542\n",
      "-0.2035672028946466\n",
      "-0.22084036493570458\n",
      "-0.23784943503874278\n",
      "-0.25459845094459654\n",
      "-0.27109138866048216\n",
      "-0.28733216340385154\n",
      "-0.3033246305318159\n",
      "-0.31907258645635944\n",
      "-0.33457976954556007\n",
      "-0.3498498610110314\n",
      "-0.3648864857817963\n",
      "-0.37969321336479966\n",
      "-0.3942735586922652\n",
      "-0.40863098295609607\n",
      "-0.4227688944295186\n",
      "-0.24726129553737644\n",
      "-0.043759292793953075\n",
      "-0.06347578169022519\n",
      "-0.08289082226156498\n",
      "-0.10200902339615138\n",
      "-0.025855502817209365\n",
      "-0.04584572541560373\n",
      "-0.06553031453386814\n",
      "-0.08491394304764062\n",
      "-0.10400121238826987\n",
      "-0.12279665363513782\n",
      "-0.14130472859128124\n",
      "-0.15952983084256817\n",
      "-0.17747628680068012\n",
      "-0.19514835673014838\n",
      "-0.21255023575968757\n",
      "-0.22968605487806676\n",
      "-0.24655988191475461\n",
      "-0.26317572250557125\n",
      "-0.27953752104357643\n",
      "-0.2956491616154189\n",
      "-0.31151446892337004\n",
      "-0.3271372091932609\n",
      "-0.34252109106853657\n",
      "-0.3576697664906422\n",
      "-0.37258683156594813\n",
      "-0.3872758274194207\n",
      "-0.5097718050978342\n",
      "-0.496984747442555\n",
      "-0.4839991510772054\n",
      "-0.470811933383371\n",
      "-0.45741996388025147\n",
      "-0.44382006348152414\n",
      "-0.43000900374066825\n",
      "-0.41598350608457224\n",
      "-0.023736675124501828\n",
      "-0.0034031755624766846\n",
      "0.06988345796509957\n",
      "0.08457413812896059\n",
      "-0.007661675560426688\n",
      "0.01292141305983773\n",
      "0.033824085745029216\n",
      "0.05505130452861331\n",
      "0.07660810848724595\n",
      "0.07779768469641861\n",
      "0.056222693130574326\n",
      "0.03497756481280487\n",
      "0.014057256414954169\n",
      "-0.0065431982829413935\n",
      "-0.01292443443776497\n",
      "0.0075769417677214795\n",
      "0.028396633327391244\n",
      "0.049539582576027155\n",
      "0.07101080858574982\n",
      "0.0901673901778657\n",
      "0.0684032763490819\n",
      "0.04697191728671907\n",
      "0.02586822545376827\n",
      "-0.005554901309475708\n",
      "0.015060898216883766\n",
      "0.035996789695228945\n",
      "0.05725774304475192\n",
      "0.07884880535027351\n",
      "0.005087191097328459\n",
      "-0.015376118940645245\n",
      "0.0811373111686922\n",
      "0.059511259558067214\n",
      "0.038215851860119505\n",
      "0.017246032810996147\n",
      "0.09167055388692126\n",
      "0.09849961493698839\n",
      "0.26409330737322645\n",
      "0.31408340856514716\n",
      "0.3396620837930461\n",
      "0.36563790724080625\n",
      "0.39201704524453107\n",
      "0.41880575988216306\n",
      "0.446010410460023\n",
      "0.11379592793629259\n",
      "0.13626483240071394\n",
      "0.15908260111751624\n",
      "0.1822546507400473\n",
      "0.2057864820235176\n",
      "0.22968368113081106\n",
      "0.25395192095857083\n",
      "0.27859696248387295\n",
      "0.30362465613181117\n",
      "0.3290409431643146\n",
      "0.35485185709052947\n",
      "0.3810635250990983\n",
      "0.40768216951267805\n",
      "0.434714109265042\n",
      "0.23967001438345248\n",
      "0.21562013274495065\n",
      "0.19193795331615196\n",
      "0.16861785424340006\n",
      "0.14565429962639395\n",
      "0.10309914044658355\n",
      "0.12540196085575495\n",
      "0.14805106680725663\n",
      "0.17105183491600226\n",
      "0.19440972527710992\n",
      "0.21813028276206106\n",
      "0.24221913833498296\n",
      "0.26668201038936984\n",
      "0.2915247061055582\n",
      "0.31675312282927826\n",
      "0.34237324947161096\n",
      "0.36839116793068033\n",
      "0.3948130545354198\n",
      "0.4621657614011158\n",
      "0.1743996350644861\n",
      "0.1978095051648717\n",
      "0.10658932942412136\n",
      "0.1289463403778405\n",
      "0.15165047826532665\n",
      "0.1747071327653878\n",
      "0.19812177723987381\n",
      "0.22189997003298315\n",
      "0.24604735579074605\n",
      "0.2705696668009918\n",
      "0.29547272435412264\n",
      "0.32076244012501487\n",
      "0.346444817576378\n",
      "0.22158284945439008\n",
      "0.24572531142809684\n",
      "0.16529391249041542\n",
      "0.18856240226212423\n",
      "0.21219217107621324\n",
      "0.23618882834471314\n",
      "0.26055807057439234\n",
      "0.28530568271903595\n",
      "0.3104375395527217\n",
      "0.3359596070644185\n",
      "0.1230418382040334\n",
      "0.10077510206035864\n",
      "0.27024262220497625\n",
      "0.2951406018884376\n",
      "0.3204251609479347\n",
      "0.4478846911837389\n",
      "0.11226942530190591\n",
      "0.42065138444972494\n",
      "0.3938344517841635\n",
      "0.3674275271821261\n",
      "0.3414243419694791\n",
      "0.31581872331477734\n",
      "0.44468600271673275\n",
      "0.4175016012054203\n",
      "0.3907328260433521\n",
      "0.36437332265758976\n",
      "0.3384168336312041\n",
      "0.31285719721784155\n",
      "0.2876883458790034\n",
      "0.2629043048436872\n",
      "0.2384991906900515\n",
      "0.45322430644541556\n",
      "0.4259093615411937\n",
      "0.39901203888352477\n",
      "0.37252595338390043\n",
      "0.3618779438742373\n",
      "0.38819870267167117\n",
      "0.41492813167616854\n",
      "0.20702301773906567\n",
      "0.18347228087752146\n",
      "0.16028161472710573\n",
      "0.13744551411327646\n",
      "0.11495855803092238\n",
      "0.092815408357484\n",
      "0.21446720994876417\n",
      "0.19080265772770577\n",
      "0.16749991635769926\n",
      "0.14455345405894504\n",
      "0.12195782362784588\n",
      "0.09970766114390926\n",
      "0.2888958094990333\n",
      "0.4431871415375865\n",
      "0.41602565633729327\n",
      "0.3892794471153642\n",
      "0.3629421646557334\n",
      "0.3370075568164416\n",
      "0.311469467045456\n",
      "0.2863218329191816\n",
      "0.2615586847033175\n",
      "0.23717414393571642\n",
      "0.2131624220309112\n",
      "0.18951781890597744\n",
      "0.166234721627404\n",
      "0.1433076030786535\n",
      "0.1207310206480933\n",
      "0.47077035051364086\n",
      "0.4722924838147329\n",
      "0.5471046663839209\n",
      "0.518354370723467\n",
      "0.4900436426003038\n",
      "0.5036263866215314\n",
      "0.4987818311748114\n",
      "0.4736374550224298\n",
      "0.5016934518847594\n",
      "0.5301850611903068\n",
      "0.5591190464913215\n",
      "0.4755408368331374\n",
      "0.4809633578230046\n",
      "0.5091331005783563\n",
      "0.5377402218566202\n",
      "0.5667915126311457\n",
      "0.5577104493080114\n",
      "0.5287980002583874\n",
      "0.5003275979332868\n",
      "0.576301354542825\n",
      "0.5962938693155737\n",
      "0.5885022763545898\n",
      "0.6059513661293437\n",
      "0.5870718085365079\n",
      "0.616889047963897\n",
      "0.6666396230393467\n",
      "0.6262542954009591\n",
      "0.6471692458304643\n",
      "0.6779195902770481\n",
      "0.7091473810514135\n",
      "0.7106687802953957\n",
      "0.6794177286221926\n",
      "0.6486444789161055\n",
      "0.618341725991947\n",
      "0.6976922749971537\n",
      "0.6360617396859616\n",
      "0.6875779151269543\n",
      "0.6566799031183125\n",
      "0.7189556662290851\n",
      "0.7292270670711758\n",
      "0.7408600312411212\n",
      "0.750820605110975\n",
      "0.761251485227249\n",
      "0.7701593957806384\n",
      "0.8389830064217972\n",
      "0.8359864026085486\n",
      "0.7831802961111888\n",
      "0.8057701395017574\n",
      "0.7730650690333027\n",
      "0.793773131662326\n",
      "0.8267997266091444\n",
      "0.8160424210162662\n",
      "0.8028193512089467\n",
      "0.8494147808842812\n",
      "0.9386094802078958\n",
      "0.8710680860091826\n",
      "0.9052948038415529\n",
      "0.9400529440379707\n",
      "0.903873409344206\n",
      "0.8696684234232602\n",
      "0.9417478430714893\n",
      "0.906963789312202\n",
      "0.9177220172390906\n",
      "0.8727115541132706\n",
      "0.8943992441724512\n",
      "0.8603391101689123\n",
      "0.8833052978967169\n",
      "0.9526731090107833\n",
      "1.0845666850746218\n",
      "1.0475990528436745\n",
      "1.0111966242284096\n",
      "1.135739098678512\n",
      "1.0979890838212873\n",
      "1.0608162345438343\n",
      "1.0242117264759447\n",
      "0.9881668701645159\n",
      "0.975350757746863\n",
      "1.1221082965754958\n",
      "1.240184049025606\n",
      "0.9738848819237728\n",
      "1.200837159821462\n",
      "1.1620918510459781\n",
      "1.1239389250466973\n",
      "1.0863693247954367\n",
      "1.0493741317382614\n",
      "1.012944563678331\n",
      "0.9770719726911162\n",
      "1.1740752404976182\n",
      "1.2130066097999361\n",
      "1.2525424484063685\n",
      "1.2801418591185478\n",
      "1.2926921416312815\n",
      "2.1857794095947805\n",
      "1.396004964083623\n",
      "1.4383821332122082\n",
      "1.4814172729797037\n",
      "1.5251205993908725\n",
      "1.5695024870696421\n",
      "1.730123011002908\n",
      "1.6832853722954346\n",
      "1.637163841197508\n",
      "1.5917474690336049\n",
      "1.6688683693570494\n",
      "1.6229672619567281\n",
      "1.577767943399804\n",
      "2.1319751725835805\n",
      "2.0789935565373305\n",
      "1.5332596839324952\n",
      "1.4894319178498183\n",
      "2.02682198428201\n",
      "1.9754480709378779\n",
      "1.9248596209794573\n",
      "1.8750446253404704\n",
      "1.8259912585630362\n",
      "1.7776878759904537\n",
      "1.4462742409874203\n",
      "1.4037764082517623\n",
      "1.3619283311880612\n",
      "1.3207200755854152\n",
      "1.5470254745241274\n",
      "1.5029872412260628\n",
      "1.4596223150127694\n",
      "1.4169204015923007\n",
      "1.374871364063667\n",
      "1.333465220510462\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print (worst_frame_indexes)\n",
    "\n",
    "for i in range(0, len(worst_frame_indexes)):\n",
    "    print(discounted_rewards[worst_frame_indexes[i]])\n",
    "\n",
    "# print(frames_to_train)\n",
    "\n",
    "\n",
    "# for i in range(0, len(frames_to_train)):\n",
    "#     this_random_frame_index = frames_to_train[i]\n",
    "#     if this_random_frame_index not in worst_frame_indexes:\n",
    "#         print(\"the nubmer {} is not in there\".format(this_random_frame_index))\n",
    "#     else:\n",
    "#         print(\"the nubmer {} is in there\".format(this_random_frame_index))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[550 549]\n",
      "0: reward: -1.7458191165518884\n",
      "1: reward: -1.7395125601937154\n"
     ]
    }
   ],
   "source": [
    "worst_frame_indexes = np.argpartition(discounted_rewards, 2)[:2]\n",
    "print (worst_frame_indexes)\n",
    "\n",
    "for i in range(0, len(worst_frame_indexes)):\n",
    "    print(\"{}: reward: {}\".format(i, discounted_rewards[worst_frame_indexes[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
